{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sandbox.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN0PFtCt1vG201oid3FaRIU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTYg3rNWKMt7"
      },
      "source": [
        "# **CIFAR10 Classification**\n",
        "\n",
        "General info about the dataset:\n",
        "- 50K Train, 10K Test\n",
        "- 10 object classes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ncg-GVYwK1TG"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV1eLcgmDsyN"
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "\n",
        "from time import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnrIX5LiLGqz"
      },
      "source": [
        "# Data generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwetmhNHLGPv"
      },
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "(x_trn_full, y_trn_full), (x_tst, y_tst) = cifar10.load_data()\n",
        "\n",
        "# remove the last dimension\n",
        "y_trn_full = y_trn_full.reshape(y_trn_full.shape[0],)\n",
        "y_tst = y_tst.reshape(y_tst.shape[0],)\n",
        "\n",
        "# normalize data to 0..1\n",
        "x_trn_full, x_tst = x_trn_full / 255.0, x_tst / 255.0\n",
        "\n",
        "# create validation split\n",
        "split = 0.2\n",
        "x_trn, x_val, y_trn, y_val = train_test_split(\n",
        "    x_trn_full, y_trn_full, test_size=split, random_state=1969)\n",
        "\n",
        "print(f'x_trn.shape: {x_trn.shape}')\n",
        "print(f'y_trn.shape: {y_trn.shape}')\n",
        "print(f'x_val.shape: {x_val.shape}')\n",
        "print(f'y_val.shape: {y_val.shape}')\n",
        "print(f'x_tst shape: {x_tst.shape}')\n",
        "print(f'y_tst.shape: {y_tst.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JqdGbPROPRm"
      },
      "source": [
        "# pick 25 random images and plot\n",
        "idxs = np.random.randint(x_trn.shape[0], size=25)\n",
        "images = x_trn[idxs]\n",
        "labels = y_trn[idxs]\n",
        "classnames = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "              'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "fig, axes = plt.subplots(5,5, figsize=(8,9))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "  ax.imshow(images[i])\n",
        "  ax.axis('off')\n",
        "  idx = labels[i]\n",
        "  ax.set_title(classnames[idx])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHDdb2NJOVYU"
      },
      "source": [
        "def data_generator(split: str, batch_size: int, shuffle_buffer: int = 10000):\n",
        "  \"\"\"Creates a tf.data.Dataset instance.\n",
        "\n",
        "  Args:\n",
        "      split: The type of data to generate, ['train', 'val', 'test'].\n",
        "      batch_size: Batch size.\n",
        "      shuffle_buffer: Number of elements used for shuffling.\n",
        "\n",
        "  Returns:\n",
        "      A tf.data.Dataset instance.\n",
        "\n",
        "  Raises:\n",
        "      ValueError: If `split` is not ['train', 'val', 'test'].\n",
        "\n",
        "  \"\"\"\n",
        "  if split == 'train':\n",
        "    ds = tf.data.Dataset.from_tensor_slices((x_trn, y_trn))\n",
        "    ds = ds.shuffle(shuffle_buffer)\n",
        "  elif split == 'val':\n",
        "    ds = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "  elif split == 'test':\n",
        "    ds = tf.data.Dataset.from_tensor_slices((x_tst, y_tst))\n",
        "  else:\n",
        "    raise ValueError(f\"Unknown data split : {split}\")\n",
        "  return ds.batch(batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqkixwrjM7wE"
      },
      "source": [
        "# Model\n",
        "Alexnet implementation from https://github.com/tensorflow/models/blob/master/research/slim/nets/alexnet.py\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6cyPFGWM7d1"
      },
      "source": [
        "trunc_normal = lambda stddev: tf.truncated_normal_initializer(\n",
        "    0.0, stddev)\n",
        "\n",
        "\n",
        "def alexnet_v2_arg_scope(weight_decay=0.0005):\n",
        "  with slim.arg_scope([slim.conv2d, slim.fully_connected],\n",
        "                      activation_fn=tf.nn.relu,\n",
        "                      biases_initializer=tf.constant_initializer(0.1),\n",
        "                      weights_regularizer=slim.l2_regularizer(weight_decay)):\n",
        "    with slim.arg_scope([slim.conv2d], padding='SAME'):\n",
        "      with slim.arg_scope([slim.max_pool2d], padding='VALID') as arg_sc:\n",
        "        return arg_sc\n",
        "\n",
        "from tensorflow.keras.Conv2D\n",
        "\n",
        "class AlexNet(Model):\n",
        "  \"\"\"AlexNet implementation. \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.conv1 = Conv2D(32, 3, activation='relu')\n",
        "    self.flatten = Flatten()\n",
        "    self.d1 = Dense(128, activation='relu')\n",
        "    self.d2 = Dense(10)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.d1(x)\n",
        "    return self.d2(x)\n",
        "\n",
        "# Create an instance of the model\n",
        "model = MyModel()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}