{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sandbox.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/cheneeheng/Transformer-TF/blob/colab_dev/Cifar10_LAMBDA.ipynb",
      "authorship_tag": "ABX9TyOB7cDapRSiJt/2uhSSHuf4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cheneeheng/Transformer-TF/blob/colab_dev/Cifar10_LAMBDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTYg3rNWKMt7"
      },
      "source": [
        "# **CIFAR10 Classification**\n",
        "\n",
        "Based on [CIFAR10_Keras_GPU.ipynb](https://github.com/katnoria/cifar10-native-vs-colab/blob/master/CIFAR10_Keras_GPU.ipynb) from [katnoria/cifar10-native-vs-colab](https://github.com/katnoria/cifar10-native-vs-colab) .\n",
        "\n",
        "General info about the dataset:\n",
        "- 50K Train, 10K Test\n",
        "- 10 object classes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ncg-GVYwK1TG"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV1eLcgmDsyN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d6a7ef71-595a-4d26-f29f-e2b8ff175620"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount(\"/content/drive\")\n",
        "\n",
        "SAVE_PATH = \"/content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323\"\n",
        "\n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "\n",
        "from time import time\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnrIX5LiLGqz"
      },
      "source": [
        "# Data generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwetmhNHLGPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a545c66-fb0f-4250-914d-e14fa4b78b76"
      },
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "(x_trn_full, y_trn_full), (x_tst, y_tst) = cifar10.load_data()\n",
        "\n",
        "# remove the last dimension\n",
        "y_trn_full = y_trn_full.reshape(y_trn_full.shape[0],)\n",
        "y_tst = y_tst.reshape(y_tst.shape[0],)\n",
        "\n",
        "# perform in model.\n",
        "# # normalize data to 0..1\n",
        "# x_trn_full, x_tst = x_trn_full / 255.0, x_tst / 255.0\n",
        "\n",
        "# create validation split\n",
        "# split = 0.2\n",
        "# x_trn, x_val, y_trn, y_val = train_test_split(\n",
        "#     x_trn_full, y_trn_full, test_size=split, random_state=1969)\n",
        "x_trn, x_val, y_trn, y_val = x_trn_full, x_tst, y_trn_full, y_tst\n",
        "\n",
        "print(f'x_trn.shape: {x_trn.shape}')\n",
        "print(f'y_trn.shape: {y_trn.shape}')\n",
        "print(f'x_val.shape: {x_val.shape}')\n",
        "print(f'y_val.shape: {y_val.shape}')\n",
        "print(f'x_tst shape: {x_tst.shape}')\n",
        "print(f'y_tst.shape: {y_tst.shape}')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "x_trn.shape: (50000, 32, 32, 3)\n",
            "y_trn.shape: (50000,)\n",
            "x_val.shape: (10000, 32, 32, 3)\n",
            "y_val.shape: (10000,)\n",
            "x_tst shape: (10000, 32, 32, 3)\n",
            "y_tst.shape: (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JqdGbPROPRm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "6e185007-ee64-4ad4-9af5-e45313d44019"
      },
      "source": [
        "# pick 25 random images and plot\n",
        "idxs = np.random.randint(x_trn.shape[0], size=25)\n",
        "images = x_trn[idxs]\n",
        "labels = y_trn[idxs]\n",
        "classnames = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "              'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "fig, axes = plt.subplots(5,5, figsize=(8,9))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "  ax.imshow(images[i])\n",
        "  ax.axis('off')\n",
        "  idx = labels[i]\n",
        "  ax.set_title(classnames[idx])\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x648 with 25 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJ0WDLT4s00F"
      },
      "source": [
        "class Patches(tf.keras.layers.Layer):\n",
        "  \"\"\"Creates patches from an image. Implemented as a keras layer.\"\"\"\n",
        "  def __init__(self, patch_size: int):\n",
        "    super().__init__()\n",
        "    self.patch_size = patch_size\n",
        "\n",
        "  def call(self, x):\n",
        "    batch_size = tf.shape(x)[0]\n",
        "    patches = tf.image.extract_patches(\n",
        "        images=x,\n",
        "        sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "        strides=[1, self.patch_size, self.patch_size, 1],\n",
        "        rates=[1, 1, 1, 1],\n",
        "        padding=\"VALID\",\n",
        "    )\n",
        "    patch_dims = patches.shape[-1]\n",
        "    patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "    return patches\n",
        "\n",
        "  def get_config(self):\n",
        "    return {\"patch_size\": self.patch_size}\n",
        "\n",
        "  @classmethod\n",
        "  def from_config(cls, config):\n",
        "    return cls(**config)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "vRUfSiYstKud",
        "outputId": "7875f377-155e-4a6a-96bc-bfe7097b4b9a"
      },
      "source": [
        "plt.figure(figsize=(4, 4))\n",
        "image = x_trn[np.random.choice(range(x_trn.shape[0]))]\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "image_size = 32\n",
        "patch_size = 4\n",
        "\n",
        "resized_image = tf.image.resize(\n",
        "    tf.convert_to_tensor([image]), size=(image_size, image_size)\n",
        ")\n",
        "patches = Patches(patch_size)(resized_image)\n",
        "print(f\"Image size: {image_size} X {image_size}\")\n",
        "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
        "print(f\"Patches per image: {patches.shape[1]}\")\n",
        "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
        "\n",
        "n = int(np.sqrt(patches.shape[1]))\n",
        "plt.figure(figsize=(4, 4))\n",
        "for i, patch in enumerate(patches[0]):\n",
        "    ax = plt.subplot(n, n, i + 1)\n",
        "    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
        "    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image size: 32 X 32\n",
            "Patch size: 4 X 4\n",
            "Patches per image: 64\n",
            "Elements per patch: 48\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 64 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHDdb2NJOVYU"
      },
      "source": [
        "def data_generator(split: str, batch_size: int, shuffle_buffer: int = 10000):\n",
        "  \"\"\"Creates a tf.data.Dataset instance.\n",
        "\n",
        "  Args:\n",
        "      split: The type of data to generate, ['train', 'val', 'test'].\n",
        "      batch_size: Batch size.\n",
        "      shuffle_buffer: Number of elements used for shuffling.\n",
        "\n",
        "  Returns:\n",
        "      A tf.data.Dataset instance.\n",
        "\n",
        "  Raises:\n",
        "      ValueError: If `split` is not ['train', 'val', 'test'].\n",
        "\n",
        "  \"\"\"\n",
        "  if split == 'train':\n",
        "    ds = tf.data.Dataset.from_tensor_slices((x_trn, y_trn))\n",
        "    ds = ds.shuffle(shuffle_buffer)\n",
        "  elif split == 'val':\n",
        "    ds = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "  elif split == 'test':\n",
        "    ds = tf.data.Dataset.from_tensor_slices((x_tst, y_tst))\n",
        "  else:\n",
        "    raise ValueError(f\"Unknown data split : {split}\")\n",
        "  return ds.batch(batch_size)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqkixwrjM7wE"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mn9ZY763Jg7x"
      },
      "source": [
        "##CNN\n",
        "\n",
        "A simple CNN example from the keras [CNN benchmark](https://github.com/keras-team/keras/blob/master/keras/benchmarks/keras_examples_benchmarks/cifar10_cnn_benchmark_test.py) .  \n",
        "It is based on this [CNN example](https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py) but the example is no longer available.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McvCeeVJJf8j"
      },
      "source": [
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import (\n",
        "  Conv2D, \n",
        "  BatchNormalization, \n",
        "  MaxPool2D,\n",
        "  Dropout,\n",
        "  Flatten,\n",
        "  Dense\n",
        ")\n",
        "from tensorflow.keras.initializers import TruncatedNormal, Constant, Zeros\n",
        "from tensorflow.keras.regularizers import L2\n",
        "from tensorflow.keras.activations import relu\n",
        "from tensorflow.keras.layers.experimental.preprocessing import (\n",
        "  RandomFlip,\n",
        "  RandomTranslation,\n",
        "  RandomRotation,\n",
        "  RandomZoom,\n",
        "  Normalization,\n",
        "  Rescaling,\n",
        "  Resizing\n",
        ")\n",
        "\n",
        "def conv2d(filters, kernel_size, strides=(1, 1), padding='valid', **kwargs):\n",
        "  return Conv2D(filters, \n",
        "                kernel_size, \n",
        "                strides, \n",
        "                padding=padding, \n",
        "                activation=relu,\n",
        "                **kwargs)\n",
        "  \n",
        "def maxpool2d(**kwargs):\n",
        "  return MaxPool2D([3, 3], 2, padding='valid', **kwargs)\n",
        "\n",
        "class SmallCNN(Model):\n",
        "  \"\"\"SmallCNN implementation.\n",
        "  \n",
        "  Changes compared to the original model:\n",
        "  - maxpool2d uses a kernel_size=3, stride=2.\n",
        "  \n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, \n",
        "               num_classes: int, \n",
        "               image_height: int, \n",
        "               image_width: int,\n",
        "               preprocess: bool = False):\n",
        "    super().__init__()\n",
        "\n",
        "    self.num_classes = num_classes\n",
        "    self.image_height = image_height\n",
        "    self.image_width = image_width\n",
        "    self.preprocess = preprocess\n",
        "\n",
        "    self.rescale = Rescaling(1./255., name='rescale')\n",
        "    self.resize = Resizing(self.image_height, self.image_width, name='resize')\n",
        "\n",
        "    # Preprocessing\n",
        "    self.augs = [\n",
        "      RandomFlip(\"horizontal\", name='data_aug_flip'),\n",
        "      # RandomTranslation((-0.1, 0.1), (-0.1, 0.1), name='data_aug2'),\n",
        "      RandomRotation(0.02, name='data_aug_rot'),\n",
        "      RandomZoom(0.2, 0.2, name='data_aug_zoom'),\n",
        "    ]\n",
        "\n",
        "    # Model\n",
        "    self.conv1 = conv2d(32, 3, name='conv1', padding='same')\n",
        "    self.conv2 = conv2d(32, 3, name='conv2')\n",
        "    self.pool2 = maxpool2d(name='pool1')\n",
        "    self.drop2 = Dropout(0.5, name='drop2')\n",
        "    self.conv3 = conv2d(64, 3, name='conv3', padding='same')\n",
        "    self.conv4 = conv2d(64, 3, name='conv4')\n",
        "    self.pool4 = maxpool2d(name='pool4')\n",
        "    self.drop4 = Dropout(0.25, name='drop4')\n",
        "    self.flat5 = Flatten(name='flat5')\n",
        "    self.dens5 = Dense(512, activation=relu, name='dens5')\n",
        "    self.drop5 = Dropout(0.5, name='drop5')\n",
        "    self.dens6 = Dense(self.num_classes, name='logits')\n",
        "\n",
        "  def call(self, x, training: bool = None):\n",
        "    x = self.rescale(x)\n",
        "    x = self.resize(x)\n",
        "    if self.preprocess:\n",
        "      for aug_i in self.augs:\n",
        "        x = aug_i(x, training=training)\n",
        "    x = self.pool2(self.conv2(self.conv1(x)))\n",
        "    x = self.drop2(x, training=training)\n",
        "    x = self.pool4(self.conv4(self.conv3(x)))\n",
        "    x = self.drop4(x, training=training)\n",
        "    x = self.dens5(self.flat5(x))\n",
        "    x = self.drop5(x, training=training)\n",
        "    x = self.dens6(x)\n",
        "    return x\n",
        "  \n",
        "  # https://stackoverflow.com/questions/55235212\n",
        "  def model(self, input_shape=None):\n",
        "    if input_shape is None:\n",
        "      x = Input(shape=(self.image_height, self.image_width, 3))\n",
        "    else:\n",
        "      x = Input(shape=input_shape)\n",
        "    return Model(inputs=[x], outputs=self.call(x))\n",
        "  \n",
        "  def get_config(self):\n",
        "    return {\"num_classes\": self.num_classes,\n",
        "            \"image_height\": self.image_height,\n",
        "            \"image_width\": self.image_width,\n",
        "            \"preprocess\": self.preprocess}\n",
        "\n",
        "  @classmethod\n",
        "  def from_config(cls, config):\n",
        "    return cls(**config)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGHzfefDfO5z"
      },
      "source": [
        "##VIT\n",
        "\n",
        "[Vision Transformer](https://arxiv.org/abs/2010.11929) by Alexey Dosovitskiy et al.  \n",
        "Code taken from this [example](https://keras.io/examples/vision/image_classification_with_vision_transformer/) from the official keras website."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfUPza88W8GY"
      },
      "source": [
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import (\n",
        "  Layer,\n",
        "  Add,\n",
        "  BatchNormalization, \n",
        "  Conv2D, \n",
        "  Dense,\n",
        "  Dropout,\n",
        "  Embedding,\n",
        "  Flatten,\n",
        "  LayerNormalization,\n",
        "  MaxPool2D,\n",
        "  MultiHeadAttention\n",
        ")\n",
        "from tensorflow.keras.initializers import TruncatedNormal, Constant, Zeros\n",
        "from tensorflow.keras.regularizers import L2\n",
        "from tensorflow.keras.activations import relu, gelu\n",
        "from tensorflow.keras.layers.experimental.preprocessing import (\n",
        "  Normalization,\n",
        "  RandomFlip,\n",
        "  RandomRotation,\n",
        "  RandomZoom,\n",
        "  Rescaling,\n",
        "  Resizing,\n",
        ")\n",
        "\n",
        "def mlp(hidden_units: list, dropout_rate: float, name: str = ''):\n",
        "  \"\"\"Multilayer perceptron.\"\"\"\n",
        "  layers = []\n",
        "  for idx, units in enumerate(hidden_units):\n",
        "    layers.append(Dense(units, activation=gelu, name=f'{name}/dens{idx}'))\n",
        "    layers.append(Dropout(dropout_rate, name=f'{name}/drop{idx}'))\n",
        "  return layers\n",
        "\n",
        "class MLP(Layer):\n",
        "  \"\"\"Multilayer perceptron.\"\"\"\n",
        "  def __init__(self, hidden_units: list, dropout_rate: float):\n",
        "    super().__init__()\n",
        "    self.hidden_units = hidden_units\n",
        "    self.dropout_rate = dropout_rate\n",
        "    \n",
        "    self.layers = []\n",
        "    self.dropouts = []\n",
        "    for idx, units in enumerate(self.hidden_units):\n",
        "      self.layers.append(Dense(units, activation=gelu, name=f'dens{idx}'))\n",
        "      self.dropouts.append(Dropout(dropout_rate))\n",
        "\n",
        "  def call(self, x, training: bool = None):\n",
        "    for layer_i, dropout_i in zip(self.layers, self.dropouts):\n",
        "        x = layer_i(x)\n",
        "        x = dropout_i(x, training=training)\n",
        "    return x\n",
        "  \n",
        "  def get_config(self):\n",
        "    return {\"hidden_units\": self.hidden_units,\n",
        "            \"dropout_rate\": self.dropout_rate}\n",
        "\n",
        "  @classmethod\n",
        "  def from_config(cls, config):\n",
        "    return cls(**config)\n",
        "\n",
        "\n",
        "class PatchEncoder(Layer):\n",
        "  \"\"\"Encoder for the image patches.\"\"\"\n",
        "  def __init__(self, num_patches: int, projection_dim: int):\n",
        "    super().__init__()\n",
        "    self.num_patches = num_patches\n",
        "    self.projection_dim = projection_dim\n",
        "    self.projection = Dense(units=self.projection_dim)\n",
        "    self.position_embedding = Embedding(input_dim=num_patches,\n",
        "                                        output_dim=self.projection_dim)\n",
        "\n",
        "  def call(self, x):\n",
        "    positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "    encoded = self.projection(x) + self.position_embedding(positions)\n",
        "    return encoded\n",
        "  \n",
        "  def get_config(self):\n",
        "    return {\"num_patches\": self.num_patches,\n",
        "            \"projection_dim\": self.projection_dim}\n",
        "\n",
        "  @classmethod\n",
        "  def from_config(cls, config):\n",
        "    return cls(**config)\n",
        "\n",
        "\n",
        "class VIT(Model):\n",
        "  \"\"\"Vision Transformer implementation.\n",
        "  \n",
        "  Changes compared to the original model:\n",
        "  - maxpool2d uses a kernel_size=3, stride=2.\n",
        "  \n",
        "  \"\"\"\n",
        "  def __init__(self, \n",
        "               num_classes: int, \n",
        "               image_height: int, \n",
        "               image_width: int,\n",
        "               patch_size: int, \n",
        "               projection_dim: int,\n",
        "               num_layers: int,\n",
        "               num_heads: int,\n",
        "               mlp_dims: list,\n",
        "               classifier_mlp_dims: list,\n",
        "               preprocess: bool = False):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.num_classes = num_classes\n",
        "    self.image_height = image_height\n",
        "    self.image_width = image_width\n",
        "    self.patch_size = patch_size\n",
        "    self.projection_dim = projection_dim\n",
        "    self.num_layers = num_layers\n",
        "    self.num_heads = num_heads\n",
        "    self.mlp_dims = mlp_dims\n",
        "    self.classifier_mlp_dims = classifier_mlp_dims\n",
        "    self.preprocess = preprocess\n",
        "\n",
        "    self.rescale = Rescaling(1./255., name='rescale')\n",
        "    self.resize = Resizing(self.image_height, self.image_width, name='resize')\n",
        "\n",
        "    # Preprocessing\n",
        "    self.augs = [\n",
        "      RandomFlip(\"horizontal\", name='data_aug_flip'),\n",
        "      # RandomTranslation((-0.1, 0.1), (-0.1, 0.1), name='data_aug2'),\n",
        "      RandomRotation(0.02, name='data_aug_rot'),\n",
        "      RandomZoom(0.2, 0.2, name='data_aug_zoom'),\n",
        "    ]\n",
        "\n",
        "    # Patches\n",
        "    self.patch = Patches(self.patch_size)\n",
        "    num_patches = (self.image_height // self.patch_size) * \\\n",
        "                  (self.image_width // self.patch_size)\n",
        "    self.patch_enc = PatchEncoder(num_patches, self.projection_dim)\n",
        "\n",
        "    # Model\n",
        "    self.transformer_blocks = []\n",
        "    for idx in range(self.num_layers):\n",
        "      block = []\n",
        "      block += [LayerNormalization(epsilon=1e-6, name=f'ln{idx + 1}_1')]\n",
        "      block += [MultiHeadAttention(self.num_heads, \n",
        "                                   self.projection_dim, \n",
        "                                   dropout=0.1, \n",
        "                                   name=f'mha{idx + 1}')]\n",
        "      block += [Add(name=f'skip{idx + 1}_1')]\n",
        "      block += [LayerNormalization(epsilon=1e-6, name=f'ln{idx + 1}_2')]\n",
        "      block += [mlp(mlp_dims, dropout_rate=0.1, name=f'mlp{idx + 1}')]\n",
        "      block += [Add(name=f'skip{idx + 1}_2')]\n",
        "      self.transformer_blocks.append(block)\n",
        "\n",
        "    self.lnorm = LayerNormalization(epsilon=1e-6, name='classifier_ln')\n",
        "    self.flat = Flatten(name='classifier_flat')\n",
        "    self.drop = Dropout(0.5, name='classifier_drop')\n",
        "    self.mlp = mlp(self.classifier_mlp_dims, dropout_rate=0.5, \n",
        "                   name='classifier_mlp')\n",
        "    self.logits = Dense(self.num_classes, name='logits')\n",
        "\n",
        "  def call(self, x, training: bool = None):\n",
        "    x = self.rescale(x)\n",
        "    x = self.resize(x)\n",
        "\n",
        "    if self.preprocess:\n",
        "      for aug_i in self.augs:\n",
        "        x = aug_i(x, training=training)\n",
        "\n",
        "    x = self.patch(x)\n",
        "    x = self.patch_enc(x)\n",
        "    \n",
        "    for block in self.transformer_blocks:\n",
        "      x_layer_norm_1 = block[0](x)\n",
        "      x_attention    = block[1](x_layer_norm_1, x_layer_norm_1)\n",
        "      x_skip         = block[2]([x_attention, x])\n",
        "      x_layer_norm_2 = block[3](x_skip)\n",
        "      x_mlp          = self._iterate_mlp(block[4], x_layer_norm_2)\n",
        "      x              = block[5]([x_mlp, x_skip])\n",
        "    \n",
        "    x = self.lnorm(x)\n",
        "    x = self.flat(x)\n",
        "    x = self.drop(x, training=training)\n",
        "    x = self._iterate_mlp(self.mlp, x)\n",
        "    x = self.logits(x)\n",
        "    return x\n",
        "  \n",
        "  @staticmethod\n",
        "  def _iterate_mlp(mlp_layers: list, x: tf.Tensor):\n",
        "    _x = x\n",
        "    for mlp_i in mlp_layers:\n",
        "      _x = mlp_i(_x)\n",
        "    return _x\n",
        "\n",
        "  # https://stackoverflow.com/questions/55235212\n",
        "  def model(self, input_shape=None):\n",
        "    if input_shape is None:\n",
        "      x = Input(shape=(self.image_height, self.image_width, 3))\n",
        "    else:\n",
        "      x = Input(shape=input_shape)\n",
        "    return Model(inputs=[x], outputs=self.call(x))\n",
        "  \n",
        "  def get_config(self):\n",
        "      return {\"num_classes\": self.num_classes,\n",
        "              \"image_height\": self.image_height,\n",
        "              \"image_width\": self.image_width,\n",
        "              \"patch_size\": self.patch_size,\n",
        "              \"projection_dim\": self.projection_dim,\n",
        "              \"num_layers\": self.num_layers,\n",
        "              \"num_heads\": self.num_heads,\n",
        "              \"mlp_dims\": self.mlp_dims,\n",
        "              \"classifier_mlp_dims\": self.classifier_mlp_dims,\n",
        "              \"preprocess\": self.preprocess}\n",
        "\n",
        "  @classmethod\n",
        "  def from_config(cls, config):\n",
        "      return cls(**config)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWcTLWi9KTFh"
      },
      "source": [
        "##LambdaNetworks\n",
        "\n",
        "[LambdaNetworks](https://arxiv.org/abs/2102.08602) from Irwan Bello.  \n",
        "\n",
        "The LambdaNets is based on [tfkeras.py](https://github.com/lucidrains/lambda-networks/blob/main/lambda_networks/tfkeras.py) from [lucidrains/lambda-networks](https://github.com/lucidrains/lambda-networks) and [lambda2d.py](https://github.com/g0lemXIV/LambdaNetworks/blob/main/lambda_layers/lambda2d.py) from [g0lemXIV/LambdaNetworks](https://github.com/g0lemXIV/LambdaNetworks) .  \n",
        "\n",
        "**Good to know points from the paper**\n",
        "*   The paper main introduces lambdalayer and uses it to replace the convs in ResNet to create LambdaResNet.\n",
        "*   LambdaResNet achieves high accuracy but is very slow (~7x slower).\n",
        "*   The main conclusion is that a hybrid model of conv + lambda has the best speed-accuracy tradeoff.\n",
        "*   The best hybrid model replaces only some blocks in C4 and all the blocks in C5.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-_CmWcIKSxv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70e81671-6d3b-45e3-9159-271f373e9a70"
      },
      "source": [
        "! pip install einops\n",
        "from einops.layers.tensorflow import Rearrange\n",
        "\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import (\n",
        "  BatchNormalization, \n",
        "  Conv2D,\n",
        "  Conv3D\n",
        ")\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.activations import relu\n",
        "from tensorflow.keras.layers.experimental.preprocessing import (\n",
        "  Normalization,\n",
        "  RandomFlip,\n",
        "  RandomRotation,\n",
        "  RandomZoom,\n",
        "  Rescaling,\n",
        "  Resizing,\n",
        ")\n",
        "from tensorflow import einsum, meshgrid\n",
        "\n",
        "\n",
        "def conv2d(filters, kernel_size, strides=(1, 1), padding='valid', **kwargs):\n",
        "  return Conv2D(filters, \n",
        "                kernel_size, \n",
        "                strides, \n",
        "                padding=padding, \n",
        "                activation=relu,\n",
        "                **kwargs)\n",
        "  \n",
        "\n",
        "def maxpool2d(**kwargs):\n",
        "  return MaxPool2D([3, 3], 2, padding='valid', **kwargs)\n",
        "\n",
        "\n",
        "def calc_rel_pos(n: int):\n",
        "  \"\"\"Generates a relative position meshgrid.\n",
        "  \n",
        "  Args:\n",
        "    n: Size of the original meshgrid. Size = Height = Width.\n",
        "\n",
        "  Returns: \n",
        "    rel_pos: An array of [n*n, n*n, 2] with value range from [-n+1, n-1] to \n",
        "             [0, 2n-2].\n",
        "  \"\"\"\n",
        "  # [2, n, n]\n",
        "  pos = tf.stack(meshgrid(tf.range(n), tf.range(n), indexing = 'ij'))\n",
        "  # [n*n, 2], pos[n] = (i, j)\n",
        "  pos = Rearrange('n i j -> (i j) n')(pos)             \n",
        "  # [n*n, n*n, 2], rel_pos[n, m] = (rel_i, rel_j)\n",
        "  rel_pos = pos[None, :] - pos[:, None]                \n",
        "  # shift value range from [-n+1, n-1] to [0, 2n-2]\n",
        "  rel_pos += n - 1\n",
        "  # [n*n, n*n, 2]                      \n",
        "  return rel_pos\n",
        "\n",
        "\n",
        "class Lambda(Layer):\n",
        "  \"\"\"Lambda Networks implementation.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               output_dim: int,\n",
        "               k_dim: int = 16,\n",
        "               u_dim: int = 1,\n",
        "               num_heads: int = 4,\n",
        "               n_r_size: int = None,\n",
        "               local_contexts: bool = False,\n",
        "               batch_norm: bool = True,\n",
        "               **kwargs):\n",
        "    \"\"\"Constructor\n",
        "\n",
        "    Args:\n",
        "      output_dim: Output dimension of the layer or v_dim * `num_heads`.\n",
        "      k_dim: Dimension of key.\n",
        "      u_dim: Intra depth for multiquery heads.\n",
        "      num_heads: Number of heads for multiquery.\n",
        "      n_r_size: If `local_contexts=True` n = height*width of query,\n",
        "                else r = receptive field.\n",
        "      local_contexts: If True lambdaconv is used, \n",
        "                      else relative position embeddings are used.\n",
        "      batch_norm: Whether to apply batch norm to query and value after\n",
        "                  the linear projection.\n",
        "\n",
        "    \"\"\"\n",
        "    super().__init__(**kwargs)\n",
        "\n",
        "    self.output_dim = output_dim\n",
        "    self.u_dim = u_dim  # intra-depth dimension\n",
        "    self.num_heads = num_heads\n",
        "    self.n_r_size = n_r_size\n",
        "    self.local_contexts = local_contexts\n",
        "    self.batch_norm = batch_norm\n",
        "\n",
        "    assert (self.output_dim % self.num_heads) == 0, \\\n",
        "      '`output_dim` must be divisible by `num_heads` for multi-head query.'\n",
        "    self.v_dim = self.output_dim // self.num_heads\n",
        "    self.k_dim = k_dim\n",
        "    self.num_heads = num_heads\n",
        "\n",
        "    self.to_q = Conv2D(self.k_dim * self.num_heads, 1, use_bias=self.batch_norm)\n",
        "    self.to_k = Conv2D(self.k_dim * self.u_dim, 1, use_bias=self.batch_norm)\n",
        "    self.to_v = Conv2D(self.v_dim * self.u_dim, 1, use_bias=self.batch_norm)\n",
        "\n",
        "    self.norm_q = BatchNormalization() if self.batch_norm else None\n",
        "    self.norm_v = BatchNormalization() if self.batch_norm else None\n",
        "\n",
        "    if self.local_contexts:\n",
        "      assert (self.n_r_size % 2) == 1, 'Receptive kernel size should be odd'\n",
        "      self.pos_conv = Conv3D(self.k_dim, \n",
        "                             (1, self.n_r_size, self.n_r_size), \n",
        "                             padding='same')\n",
        "    else:\n",
        "      assert n is not None, 'You must specify the window length (n = h = w)'\n",
        "      rel_length = 2 * self.n_r_size - 1\n",
        "      self.rel_pos_emb = self.add_weight(name='pos_emb',\n",
        "                                         shape=(rel_length, rel_length, \n",
        "                                                self.k_dim, self.u_dim),\n",
        "                                         initializer=RandomNormal,\n",
        "                                         trainable=True)\n",
        "      self.rel_pos = calc_rel_pos(self.n_r_size)\n",
        "\n",
        "  def call(self, x):\n",
        "    \"\"\"\n",
        "    Info on the notations for reference:\n",
        "    x = 2D Image data (Assumption)\n",
        "    q = query\n",
        "    k = key\n",
        "    v = value\n",
        "    h = number of heads for multiquery\n",
        "    u = intradepth\n",
        "    b = batch size\n",
        "    hh = height of input data\n",
        "    ww = width of input data\n",
        "    m = height * width of key / value.\n",
        "    n = height * width of query.\n",
        "    \"\"\"\n",
        "    b, hh, ww, c, u, h = *x.get_shape().as_list(), self.u_dim, self.num_heads\n",
        "\n",
        "    q = self.to_q(x)\n",
        "    k = self.to_k(x)\n",
        "    v = self.to_v(x)\n",
        "\n",
        "    if self.batch_norm:\n",
        "      q = self.norm_q(q)\n",
        "      v = self.norm_v(v)\n",
        "\n",
        "    q = Rearrange('b hh ww (h k) -> b h k (hh ww)', h=h)(q)\n",
        "    k = Rearrange('b hh ww (u k) -> b u k (hh ww)', u=u)(k)\n",
        "    v = Rearrange('b hh ww (u v) -> b u v (hh ww)', u=u)(v)\n",
        "\n",
        "    k = tf.nn.softmax(k)\n",
        "\n",
        "    Lc = einsum('b u k m, b u v m -> b k v', k, v)\n",
        "    Yc = einsum('b h k n, b k v -> b n h v', q, Lc)\n",
        "\n",
        "    if self.local_contexts:\n",
        "      # lambda convs, embedding is represented by the conv kernels.\n",
        "      v = Rearrange('b u v (hh ww) -> b v hh ww u', hh=hh, ww=ww)(v)\n",
        "      Lp = self.pos_conv(v)\n",
        "      Lp = Rearrange('b v h w k -> b v k (h w)')(Lp)\n",
        "      Yp = einsum('b h k n, b v k n -> b n h v', q, Lp)\n",
        "    else:\n",
        "      # relative position embedding.\n",
        "      rel_pos_emb = tf.gather_nd(self.rel_pos_emb, self.rel_pos)\n",
        "      Lp = einsum('n m k u, b u v m -> b n k v', rel_pos_emb, v)\n",
        "      Yp = einsum('b h k n, b n k v -> b n h v', q, Lp)\n",
        "\n",
        "    Y = Yc + Yp\n",
        "    out = Rearrange('b (hh ww) h v -> b hh ww (h v)', hh = hh, ww = ww)(Y)\n",
        "    return out\n",
        "\n",
        "  def get_config(self):\n",
        "    return {\"output_dim\": self.output_dim,\n",
        "            \"k_dim\": self.k_dim,\n",
        "            \"u_dim\": self.u_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"n_r_size\": self.n_r_size,\n",
        "            \"local_contexts\": self.local_contexts,\n",
        "            \"batch_norm\": self.batch_norm}\n",
        "\n",
        "  @classmethod\n",
        "  def from_config(cls, config):\n",
        "    return cls(**config)\n",
        "\n",
        "\n",
        "class LambdaNetwork(Model):\n",
        "  \"\"\"LambdaNetworks implementation. \"\"\"\n",
        "  \n",
        "  def __init__(self, \n",
        "               num_classes: int, \n",
        "               image_height: int, \n",
        "               image_width: int,\n",
        "               k_dim: int = 16,\n",
        "               u_dim: int = 1,\n",
        "               num_heads: int = 4,\n",
        "               n_r_size: int = None,\n",
        "               local_contexts: bool = False,\n",
        "               preprocess: bool = False,\n",
        "               **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    \n",
        "    self.num_classes = num_classes\n",
        "    self.image_height = image_height\n",
        "    self.image_width = image_width\n",
        "    self.k_dim = k_dim\n",
        "    self.u_dim = u_dim\n",
        "    self.num_heads = num_heads\n",
        "    self.n_r_size = n_r_size\n",
        "    self.local_contexts = local_contexts\n",
        "    self.preprocess = preprocess\n",
        "\n",
        "    self.rescale = Rescaling(1./255., name='rescale')\n",
        "    self.resize = Resizing(self.image_height, self.image_width, name='resize')\n",
        "\n",
        "    # Preprocessing\n",
        "    self.augs = [\n",
        "      RandomFlip(\"horizontal\", name='data_aug_flip'),\n",
        "      # RandomTranslation((-0.1, 0.1), (-0.1, 0.1), name='data_aug2'),\n",
        "      RandomRotation(0.02, name='data_aug_rot'),\n",
        "      RandomZoom(0.2, 0.2, name='data_aug_zoom'),\n",
        "    ]\n",
        "\n",
        "    # Model\n",
        "    self.conv1 = conv2d(32, 3, name='conv1', padding='same')\n",
        "    self.conv2 = conv2d(32, 3, name='conv2')\n",
        "    self.pool2 = maxpool2d(name='pool1')\n",
        "    self.drop2 = Dropout(0.5, name='drop2')\n",
        "\n",
        "    # self.lamb3 = Lambda(64, k_dim=8, u_dim=1, num_heads=2, n_r_size=14, \n",
        "    #                     local_contexts=False, batch_norm=False)\n",
        "    # self.lamb4 = Lambda(64, k_dim=8, u_dim=1, num_heads=2, n_r_size=14, \n",
        "    #                     local_contexts=False, batch_norm=False)\n",
        "    self.lamb3 = Lambda(64, k_dim=self.k_dim, u_dim=self.u_dim, \n",
        "                        num_heads=self.num_heads, n_r_size=self.n_r_size, \n",
        "                        local_contexts=self.local_contexts, batch_norm=False,\n",
        "                        name='lamb3')\n",
        "    self.lamb4 = Lambda(64, k_dim=self.k_dim, u_dim=self.u_dim, \n",
        "                        num_heads=self.num_heads, n_r_size=self.n_r_size, \n",
        "                        local_contexts=self.local_contexts, batch_norm=False,\n",
        "                        name='lamb4')\n",
        "    self.pool4 = maxpool2d(name='pool4')\n",
        "    self.drop4 = Dropout(0.25, name='drop4')\n",
        "\n",
        "    self.flat5 = Flatten(name='flat5')\n",
        "    self.dens5 = Dense(512, activation=relu, name='dens5')\n",
        "    self.drop5 = Dropout(0.5, name='drop5')\n",
        "    self.logits = Dense(self.num_classes, name='logits')\n",
        "\n",
        "  def call(self, x, training: bool = None):\n",
        "    x = self.rescale(x)\n",
        "    x = self.resize(x)\n",
        "\n",
        "    if self.preprocess:\n",
        "      for aug_i in self.augs:\n",
        "        x = aug_i(x, training=training)\n",
        "\n",
        "    x = self.pool2(self.conv2(self.conv1(x)))\n",
        "    x = self.drop2(x, training=training)\n",
        "\n",
        "    x = self.pool4(self.lamb4(self.lamb3(x)))\n",
        "    x = self.drop4(x, training=training)\n",
        "\n",
        "    x = self.dens5(self.flat5(x))\n",
        "    x = self.drop5(x, training=training)\n",
        "    x = self.logits(x)\n",
        "\n",
        "    return x\n",
        "  \n",
        "  # https://stackoverflow.com/questions/55235212\n",
        "  def model(self, input_shape=None):\n",
        "    if input_shape is None:\n",
        "      x = Input(shape=(self.image_height, self.image_width, 3))\n",
        "    else:\n",
        "      x = Input(shape=input_shape)\n",
        "    return Model(inputs=[x], outputs=self.call(x))\n",
        "  \n",
        "  def get_config(self):\n",
        "      return {\"num_classes\": self.num_classes,\n",
        "              \"image_height\": self.image_height,\n",
        "              \"image_width\": self.image_width,\n",
        "              \"patch_size\": self.patch_size,\n",
        "              \"projection_dim\": self.projection_dim,\n",
        "              \"num_layers\": self.num_layers,\n",
        "              \"num_heads\": self.num_heads,\n",
        "              \"mlp_dims\": self.mlp_dims,\n",
        "              \"classifier_mlp_dims\": self.classifier_mlp_dims,\n",
        "              \"preprocess\": self.preprocess}\n",
        "\n",
        "  @classmethod\n",
        "  def from_config(cls, config):\n",
        "      return cls(**config)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting einops\n",
            "  Downloading https://files.pythonhosted.org/packages/5d/a0/9935e030634bf60ecd572c775f64ace82ceddf2f504a5fd3902438f07090/einops-0.3.0-py2.py3-none-any.whl\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "470J_-chCJN-"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A3t5koq9X5x"
      },
      "source": [
        "Training configs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0rfLzW6CKvI"
      },
      "source": [
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "acc_metric_fn = tf.keras.metrics.SparseCategoricalAccuracy\n",
        "batch_size = 256\n",
        "shuffle_buffer = 50000\n",
        "epochs = 50\n",
        "learning_rate = 1e-3\n",
        "\n",
        "num_classes = 10 \n",
        "image_height = 32\n",
        "image_width = 32"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZK_xHPHD81nx"
      },
      "source": [
        "Keras model.compile(...) and model.fit(...) .\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x83Opo2GCQWY"
      },
      "source": [
        "def train_and_eval(_model, _checkpoint_filepath, verbose=1):\n",
        "  \"\"\"Wrapper code for training and evaluating.\n",
        "\n",
        "  Args:\n",
        "      _model: A keras Model.\n",
        "      _checkpoint_filepath: Path to save a checkpoint.\n",
        "      verbose: Option for logging output during train and eval.\n",
        "\n",
        "  Returns:\n",
        "      A history instance that contains logged values per epoch.\n",
        "\n",
        "  \"\"\"\n",
        "  _model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "    loss=loss_fn,\n",
        "    metrics=[acc_metric_fn(name='sparse_categorical_accuracy')]\n",
        "  )\n",
        "\n",
        "  checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    _checkpoint_filepath,\n",
        "    monitor=\"val_sparse_categorical_accuracy\",\n",
        "    save_best_only=True,\n",
        "  )\n",
        "\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "    log_dir=os.path.join(_checkpoint_filepath, 'logs'), \n",
        "    histogram_freq=epochs//10,\n",
        "    update_freq='epoch'\n",
        "  )\n",
        "\n",
        "  start = time()\n",
        "  history = _model.fit(\n",
        "      data_generator('train', batch_size, shuffle_buffer), \n",
        "      epochs=epochs, \n",
        "      steps_per_epoch=len(data_generator('train', batch_size, shuffle_buffer)),\n",
        "      validation_data=data_generator('val', batch_size),\n",
        "      callbacks=[tensorboard_callback, checkpoint_callback],\n",
        "      verbose=verbose\n",
        "  )\n",
        "  end = time()\n",
        "  print(f'Total training time {end - start} seconds')\n",
        "  \n",
        "  # Save history output, should be the same as the tensorboard logs.\n",
        "  np.save(os.path.join(_checkpoint_filepath, 'history.npy'), history.history)\n",
        "  \n",
        "  return history"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2n8bpH3YC3jZ"
      },
      "source": [
        "# Loss and accuracy plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYmEyrccDQBr"
      },
      "source": [
        "def plot(losses: list, \n",
        "         accuracies: list, \n",
        "         legend_labels: list, \n",
        "         subplot_title: list):\n",
        "  \n",
        "  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,5))\n",
        "  \n",
        "  for x, ll in zip(losses, legend_labels):\n",
        "    c = ax1.plot(x[0], label='Trn: ' + ll, linestyle='--')[0].get_c()\n",
        "    _ = ax1.plot(x[1], label='Val: ' + ll, linestyle='-', color=c)\n",
        "  ax1.set_xlabel('Epochs')\n",
        "  ax1.set_ylabel('Loss')\n",
        "  ax1.set_title(subplot_title[0])\n",
        "  ax1.legend()   \n",
        "\n",
        "  for x, ll in zip(accuracies, legend_labels):\n",
        "    c = ax2.plot(x[0], label='Trn: ' + ll, linestyle='--')[0].get_c()\n",
        "    _ = ax2.plot(x[1], label='Val: ' + ll, linestyle='-', color=c)\n",
        "  ax2.set_xlabel('Epochs')\n",
        "  ax2.set_ylabel('Accuracy')\n",
        "  ax2.set_title(subplot_title[1])\n",
        "  ax2.legend()   \n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6F1flqO1FDl1"
      },
      "source": [
        "#Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiQV1JV7Oqj2"
      },
      "source": [
        "history = dict()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBFk329fU0D1"
      },
      "source": [
        "##Exp 1\n",
        "Model : CNN  \n",
        "Preprocessing : False  \n",
        "Batch size : 256"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2h3TyCICccj"
      },
      "source": [
        "# model = SmallCNN(num_classes=num_classes, \n",
        "#                  image_height=image_height, \n",
        "#                  image_width=image_width,\n",
        "#                  preprocess=False).model()\n",
        "# model.summary()\n",
        "# history['CNN'] = train_and_eval(model, SAVE_PATH + '_CNN', verbose=2)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XKFICEKCZxE"
      },
      "source": [
        "##Exp 2\n",
        "Model : VIT  \n",
        "Preprocessing : False  \n",
        "Batch size : 256  \n",
        "Patch : 4x4  \n",
        "Heads : 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lyrU-_sXgkU"
      },
      "source": [
        "# # Saves a full copy of the model.\n",
        "# model = VIT(num_classes=num_classes, \n",
        "#             image_height=image_height, \n",
        "#             image_width=image_width,\n",
        "#             patch_size=4, \n",
        "#             projection_dim=32,\n",
        "#             num_layers=4,\n",
        "#             num_heads=2,\n",
        "#             mlp_dims=[64, 32],\n",
        "#             classifier_mlp_dims=[512],\n",
        "#             preprocess=False).model()\n",
        "# model.summary()\n",
        "# history['VIT'] = train_and_eval(model, SAVE_PATH + '_VIT_4x4_2hds', verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzOlQHR-GYWP"
      },
      "source": [
        "##Exp 3 - X Heads, Y Key dim\n",
        "Model : LAMBDA  \n",
        "Preprocessing : False  \n",
        "Batch size : 256  \n",
        "Key dim : 1,2,4,8  \n",
        "u dim : 1  \n",
        "Heads : 1,2,4,8  \n",
        "Pos. emb. size : 14  \n",
        "LambdaConv : False  \n",
        "\n",
        "---\n",
        "<pre>\n",
        "Q = k * hd       =  1, 2, 4, 8| 2, 4, 8,16| 4, 8,16,32| 8,16,32,64|\n",
        "K = k * u        =  1, 2, 4, 8| 1, 2, 4, 8| 1, 2, 4, 8| 1, 2, 4, 8|\n",
        "V = 64 // hd * u = 64,64,64,64|32,32,32,32|16,16,16,16| 8, 8, 8, 8|\n",
        "</pre>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8yHokOJbjoc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75cad7fd-3193-48a0-d29a-41c4f41e4add"
      },
      "source": [
        "u_dim = 1\n",
        "for hds in [1,2,4,8]:\n",
        "  for k_dim in [1,2,4,8]:\n",
        "    model = LambdaNetwork(num_classes=num_classes, \n",
        "                          image_height=image_height, \n",
        "                          image_width=image_width,\n",
        "                          k_dim=k_dim,\n",
        "                          u_dim=u_dim,\n",
        "                          num_heads=hds,\n",
        "                          n_r_size=14,\n",
        "                          local_contexts=False,\n",
        "                          preprocess=False).model()\n",
        "    model.summary()\n",
        "    if 'LAMBDA' not in history:\n",
        "      history['LAMBDA'] = dict()\n",
        "    if hds not in history['LAMBDA']:\n",
        "      history['LAMBDA'][hds] = dict()\n",
        "    if u_dim not in history['LAMBDA'][hds]:\n",
        "      history['LAMBDA'][hds][u_dim] = dict()\n",
        "    history['LAMBDA'][hds][u_dim][k_dim]= train_and_eval(model, SAVE_PATH + f'_LAMBDA_{k_dim}kdim_{u_dim}udim_{hds}hds', verbose=2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        2841      \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        4953      \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,203,228\n",
            "Trainable params: 1,203,228\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 41s - loss: 1.9517 - sparse_categorical_accuracy: 0.2852 - val_loss: 1.9414 - val_sparse_categorical_accuracy: 0.2532\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 6s - loss: 1.5868 - sparse_categorical_accuracy: 0.4172 - val_loss: 1.6689 - val_sparse_categorical_accuracy: 0.3974\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "196/196 - 6s - loss: 1.4221 - sparse_categorical_accuracy: 0.4868 - val_loss: 1.3686 - val_sparse_categorical_accuracy: 0.5020\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 6s - loss: 1.2993 - sparse_categorical_accuracy: 0.5353 - val_loss: 1.1767 - val_sparse_categorical_accuracy: 0.5772\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "196/196 - 6s - loss: 1.2333 - sparse_categorical_accuracy: 0.5603 - val_loss: 1.1457 - val_sparse_categorical_accuracy: 0.5905\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/50\n",
            "196/196 - 6s - loss: 1.1679 - sparse_categorical_accuracy: 0.5847 - val_loss: 1.0926 - val_sparse_categorical_accuracy: 0.6123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "196/196 - 6s - loss: 1.1320 - sparse_categorical_accuracy: 0.5989 - val_loss: 1.0642 - val_sparse_categorical_accuracy: 0.6249\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/50\n",
            "196/196 - 6s - loss: 1.0888 - sparse_categorical_accuracy: 0.6151 - val_loss: 1.0383 - val_sparse_categorical_accuracy: 0.6390\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/50\n",
            "196/196 - 6s - loss: 1.0526 - sparse_categorical_accuracy: 0.6280 - val_loss: 0.9456 - val_sparse_categorical_accuracy: 0.6592\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/50\n",
            "196/196 - 6s - loss: 1.0115 - sparse_categorical_accuracy: 0.6414 - val_loss: 0.9276 - val_sparse_categorical_accuracy: 0.6677\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/50\n",
            "196/196 - 6s - loss: 0.9867 - sparse_categorical_accuracy: 0.6507 - val_loss: 0.8893 - val_sparse_categorical_accuracy: 0.6886\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/50\n",
            "196/196 - 6s - loss: 0.9612 - sparse_categorical_accuracy: 0.6628 - val_loss: 0.8468 - val_sparse_categorical_accuracy: 0.7054\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13/50\n",
            "196/196 - 6s - loss: 0.9381 - sparse_categorical_accuracy: 0.6688 - val_loss: 0.8218 - val_sparse_categorical_accuracy: 0.7086\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/50\n",
            "196/196 - 6s - loss: 0.9224 - sparse_categorical_accuracy: 0.6757 - val_loss: 0.8330 - val_sparse_categorical_accuracy: 0.7104\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15/50\n",
            "196/196 - 6s - loss: 0.8946 - sparse_categorical_accuracy: 0.6873 - val_loss: 0.8208 - val_sparse_categorical_accuracy: 0.7170\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16/50\n",
            "196/196 - 6s - loss: 0.8794 - sparse_categorical_accuracy: 0.6926 - val_loss: 0.8367 - val_sparse_categorical_accuracy: 0.7128\n",
            "Epoch 17/50\n",
            "196/196 - 6s - loss: 0.8661 - sparse_categorical_accuracy: 0.6946 - val_loss: 0.8137 - val_sparse_categorical_accuracy: 0.7314\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18/50\n",
            "196/196 - 6s - loss: 0.8550 - sparse_categorical_accuracy: 0.7002 - val_loss: 0.8145 - val_sparse_categorical_accuracy: 0.7280\n",
            "Epoch 19/50\n",
            "196/196 - 6s - loss: 0.8353 - sparse_categorical_accuracy: 0.7060 - val_loss: 0.7635 - val_sparse_categorical_accuracy: 0.7369\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20/50\n",
            "196/196 - 6s - loss: 0.8219 - sparse_categorical_accuracy: 0.7113 - val_loss: 0.7813 - val_sparse_categorical_accuracy: 0.7304\n",
            "Epoch 21/50\n",
            "196/196 - 6s - loss: 0.8123 - sparse_categorical_accuracy: 0.7151 - val_loss: 0.7551 - val_sparse_categorical_accuracy: 0.7400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 22/50\n",
            "196/196 - 6s - loss: 0.8028 - sparse_categorical_accuracy: 0.7201 - val_loss: 0.7654 - val_sparse_categorical_accuracy: 0.7368\n",
            "Epoch 23/50\n",
            "196/196 - 6s - loss: 0.7880 - sparse_categorical_accuracy: 0.7219 - val_loss: 0.7892 - val_sparse_categorical_accuracy: 0.7368\n",
            "Epoch 24/50\n",
            "196/196 - 6s - loss: 0.7871 - sparse_categorical_accuracy: 0.7243 - val_loss: 0.7461 - val_sparse_categorical_accuracy: 0.7462\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 25/50\n",
            "196/196 - 6s - loss: 0.7725 - sparse_categorical_accuracy: 0.7281 - val_loss: 0.7650 - val_sparse_categorical_accuracy: 0.7475\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 26/50\n",
            "196/196 - 6s - loss: 0.7580 - sparse_categorical_accuracy: 0.7370 - val_loss: 0.7284 - val_sparse_categorical_accuracy: 0.7535\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 27/50\n",
            "196/196 - 6s - loss: 0.7561 - sparse_categorical_accuracy: 0.7361 - val_loss: 0.7414 - val_sparse_categorical_accuracy: 0.7491\n",
            "Epoch 28/50\n",
            "196/196 - 6s - loss: 0.7495 - sparse_categorical_accuracy: 0.7374 - val_loss: 0.8656 - val_sparse_categorical_accuracy: 0.7420\n",
            "Epoch 29/50\n",
            "196/196 - 6s - loss: 0.7409 - sparse_categorical_accuracy: 0.7407 - val_loss: 0.6980 - val_sparse_categorical_accuracy: 0.7606\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 30/50\n",
            "196/196 - 6s - loss: 0.7365 - sparse_categorical_accuracy: 0.7442 - val_loss: 0.6932 - val_sparse_categorical_accuracy: 0.7667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 31/50\n",
            "196/196 - 6s - loss: 0.7273 - sparse_categorical_accuracy: 0.7459 - val_loss: 0.6816 - val_sparse_categorical_accuracy: 0.7670\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 32/50\n",
            "196/196 - 6s - loss: 0.7275 - sparse_categorical_accuracy: 0.7450 - val_loss: 0.7325 - val_sparse_categorical_accuracy: 0.7582\n",
            "Epoch 33/50\n",
            "196/196 - 6s - loss: 0.7147 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.6857 - val_sparse_categorical_accuracy: 0.7645\n",
            "Epoch 34/50\n",
            "196/196 - 6s - loss: 0.7191 - sparse_categorical_accuracy: 0.7487 - val_loss: 0.7280 - val_sparse_categorical_accuracy: 0.7611\n",
            "Epoch 35/50\n",
            "196/196 - 6s - loss: 0.6990 - sparse_categorical_accuracy: 0.7548 - val_loss: 0.7056 - val_sparse_categorical_accuracy: 0.7697\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 36/50\n",
            "196/196 - 6s - loss: 0.6923 - sparse_categorical_accuracy: 0.7551 - val_loss: 0.6580 - val_sparse_categorical_accuracy: 0.7786\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 37/50\n",
            "196/196 - 6s - loss: 0.6805 - sparse_categorical_accuracy: 0.7616 - val_loss: 0.7548 - val_sparse_categorical_accuracy: 0.7690\n",
            "Epoch 38/50\n",
            "196/196 - 6s - loss: 0.6833 - sparse_categorical_accuracy: 0.7616 - val_loss: 0.7190 - val_sparse_categorical_accuracy: 0.7699\n",
            "Epoch 39/50\n",
            "196/196 - 6s - loss: 0.6757 - sparse_categorical_accuracy: 0.7631 - val_loss: 0.7097 - val_sparse_categorical_accuracy: 0.7669\n",
            "Epoch 40/50\n",
            "196/196 - 6s - loss: 0.6770 - sparse_categorical_accuracy: 0.7637 - val_loss: 0.6821 - val_sparse_categorical_accuracy: 0.7735\n",
            "Epoch 41/50\n",
            "196/196 - 6s - loss: 0.6701 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.6542 - val_sparse_categorical_accuracy: 0.7813\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 42/50\n",
            "196/196 - 6s - loss: 0.6608 - sparse_categorical_accuracy: 0.7704 - val_loss: 0.6881 - val_sparse_categorical_accuracy: 0.7738\n",
            "Epoch 43/50\n",
            "196/196 - 6s - loss: 0.6592 - sparse_categorical_accuracy: 0.7707 - val_loss: 0.6861 - val_sparse_categorical_accuracy: 0.7750\n",
            "Epoch 44/50\n",
            "196/196 - 6s - loss: 0.6532 - sparse_categorical_accuracy: 0.7696 - val_loss: 0.6734 - val_sparse_categorical_accuracy: 0.7751\n",
            "Epoch 45/50\n",
            "196/196 - 6s - loss: 0.6416 - sparse_categorical_accuracy: 0.7748 - val_loss: 0.6353 - val_sparse_categorical_accuracy: 0.7788\n",
            "Epoch 46/50\n",
            "196/196 - 6s - loss: 0.6421 - sparse_categorical_accuracy: 0.7745 - val_loss: 0.6745 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 47/50\n",
            "196/196 - 6s - loss: 0.6383 - sparse_categorical_accuracy: 0.7781 - val_loss: 0.7209 - val_sparse_categorical_accuracy: 0.7802\n",
            "Epoch 48/50\n",
            "196/196 - 6s - loss: 0.6345 - sparse_categorical_accuracy: 0.7791 - val_loss: 0.6659 - val_sparse_categorical_accuracy: 0.7824\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 49/50\n",
            "196/196 - 6s - loss: 0.6348 - sparse_categorical_accuracy: 0.7790 - val_loss: 0.7137 - val_sparse_categorical_accuracy: 0.7796\n",
            "Epoch 50/50\n",
            "196/196 - 6s - loss: 0.6237 - sparse_categorical_accuracy: 0.7817 - val_loss: 0.6762 - val_sparse_categorical_accuracy: 0.7848\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total training time 422.78032183647156 seconds\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        3634      \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        5810      \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,204,878\n",
            "Trainable params: 1,204,878\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 10s - loss: 1.9922 - sparse_categorical_accuracy: 0.2654 - val_loss: 1.7679 - val_sparse_categorical_accuracy: 0.3696\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 7s - loss: 1.5289 - sparse_categorical_accuracy: 0.4455 - val_loss: 1.4613 - val_sparse_categorical_accuracy: 0.4542\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "196/196 - 7s - loss: 1.3615 - sparse_categorical_accuracy: 0.5120 - val_loss: 1.4300 - val_sparse_categorical_accuracy: 0.4951\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 7s - loss: 1.2337 - sparse_categorical_accuracy: 0.5588 - val_loss: 1.4381 - val_sparse_categorical_accuracy: 0.5237\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "196/196 - 7s - loss: 1.1641 - sparse_categorical_accuracy: 0.5885 - val_loss: 1.1083 - val_sparse_categorical_accuracy: 0.6191\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/50\n",
            "196/196 - 7s - loss: 1.0958 - sparse_categorical_accuracy: 0.6141 - val_loss: 1.0647 - val_sparse_categorical_accuracy: 0.6282\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "196/196 - 7s - loss: 1.0590 - sparse_categorical_accuracy: 0.6269 - val_loss: 1.0518 - val_sparse_categorical_accuracy: 0.6397\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/50\n",
            "196/196 - 7s - loss: 1.0274 - sparse_categorical_accuracy: 0.6398 - val_loss: 0.9715 - val_sparse_categorical_accuracy: 0.6474\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/50\n",
            "196/196 - 7s - loss: 0.9925 - sparse_categorical_accuracy: 0.6496 - val_loss: 0.9529 - val_sparse_categorical_accuracy: 0.6819\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/50\n",
            "196/196 - 7s - loss: 0.9612 - sparse_categorical_accuracy: 0.6626 - val_loss: 0.9752 - val_sparse_categorical_accuracy: 0.6680\n",
            "Epoch 11/50\n",
            "196/196 - 7s - loss: 0.9479 - sparse_categorical_accuracy: 0.6684 - val_loss: 0.8578 - val_sparse_categorical_accuracy: 0.6940\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/50\n",
            "196/196 - 7s - loss: 0.9233 - sparse_categorical_accuracy: 0.6758 - val_loss: 1.0538 - val_sparse_categorical_accuracy: 0.6672\n",
            "Epoch 13/50\n",
            "196/196 - 7s - loss: 0.9150 - sparse_categorical_accuracy: 0.6806 - val_loss: 0.8921 - val_sparse_categorical_accuracy: 0.7047\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/50\n",
            "196/196 - 7s - loss: 0.8838 - sparse_categorical_accuracy: 0.6896 - val_loss: 0.8225 - val_sparse_categorical_accuracy: 0.7112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15/50\n",
            "196/196 - 7s - loss: 0.8771 - sparse_categorical_accuracy: 0.6905 - val_loss: 0.8568 - val_sparse_categorical_accuracy: 0.6993\n",
            "Epoch 16/50\n",
            "196/196 - 7s - loss: 0.8557 - sparse_categorical_accuracy: 0.6988 - val_loss: 0.8457 - val_sparse_categorical_accuracy: 0.7130\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 17/50\n",
            "196/196 - 7s - loss: 0.8420 - sparse_categorical_accuracy: 0.7036 - val_loss: 0.8033 - val_sparse_categorical_accuracy: 0.7230\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18/50\n",
            "196/196 - 7s - loss: 0.8309 - sparse_categorical_accuracy: 0.7081 - val_loss: 0.8007 - val_sparse_categorical_accuracy: 0.7278\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 19/50\n",
            "196/196 - 7s - loss: 0.8199 - sparse_categorical_accuracy: 0.7128 - val_loss: 0.7983 - val_sparse_categorical_accuracy: 0.7338\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20/50\n",
            "196/196 - 7s - loss: 0.8040 - sparse_categorical_accuracy: 0.7193 - val_loss: 0.8010 - val_sparse_categorical_accuracy: 0.7265\n",
            "Epoch 21/50\n",
            "196/196 - 7s - loss: 0.7916 - sparse_categorical_accuracy: 0.7191 - val_loss: 0.8152 - val_sparse_categorical_accuracy: 0.7330\n",
            "Epoch 22/50\n",
            "196/196 - 7s - loss: 0.7954 - sparse_categorical_accuracy: 0.7219 - val_loss: 0.7463 - val_sparse_categorical_accuracy: 0.7363\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 23/50\n",
            "196/196 - 7s - loss: 0.7793 - sparse_categorical_accuracy: 0.7274 - val_loss: 0.7258 - val_sparse_categorical_accuracy: 0.7495\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 24/50\n",
            "196/196 - 7s - loss: 0.7678 - sparse_categorical_accuracy: 0.7316 - val_loss: 0.7396 - val_sparse_categorical_accuracy: 0.7470\n",
            "Epoch 25/50\n",
            "196/196 - 7s - loss: 0.7480 - sparse_categorical_accuracy: 0.7385 - val_loss: 0.8092 - val_sparse_categorical_accuracy: 0.7304\n",
            "Epoch 26/50\n",
            "196/196 - 7s - loss: 0.7394 - sparse_categorical_accuracy: 0.7425 - val_loss: 0.8421 - val_sparse_categorical_accuracy: 0.7547\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 27/50\n",
            "196/196 - 7s - loss: 0.7444 - sparse_categorical_accuracy: 0.7404 - val_loss: 0.7463 - val_sparse_categorical_accuracy: 0.7554\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 28/50\n",
            "196/196 - 7s - loss: 0.7343 - sparse_categorical_accuracy: 0.7426 - val_loss: 0.7773 - val_sparse_categorical_accuracy: 0.7414\n",
            "Epoch 29/50\n",
            "196/196 - 7s - loss: 0.7259 - sparse_categorical_accuracy: 0.7459 - val_loss: 0.7567 - val_sparse_categorical_accuracy: 0.7559\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 30/50\n",
            "196/196 - 7s - loss: 0.7160 - sparse_categorical_accuracy: 0.7502 - val_loss: 0.6982 - val_sparse_categorical_accuracy: 0.7573\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 31/50\n",
            "196/196 - 7s - loss: 0.7158 - sparse_categorical_accuracy: 0.7482 - val_loss: 0.7136 - val_sparse_categorical_accuracy: 0.7634\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 32/50\n",
            "196/196 - 7s - loss: 0.7067 - sparse_categorical_accuracy: 0.7540 - val_loss: 0.7497 - val_sparse_categorical_accuracy: 0.7474\n",
            "Epoch 33/50\n",
            "196/196 - 7s - loss: 0.6963 - sparse_categorical_accuracy: 0.7553 - val_loss: 0.6942 - val_sparse_categorical_accuracy: 0.7592\n",
            "Epoch 34/50\n",
            "196/196 - 7s - loss: 0.6886 - sparse_categorical_accuracy: 0.7560 - val_loss: 0.6882 - val_sparse_categorical_accuracy: 0.7695\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 35/50\n",
            "196/196 - 7s - loss: 0.6846 - sparse_categorical_accuracy: 0.7614 - val_loss: 0.6944 - val_sparse_categorical_accuracy: 0.7624\n",
            "Epoch 36/50\n",
            "196/196 - 7s - loss: 0.6737 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.7044 - val_sparse_categorical_accuracy: 0.7579\n",
            "Epoch 37/50\n",
            "196/196 - 7s - loss: 0.6672 - sparse_categorical_accuracy: 0.7656 - val_loss: 0.6986 - val_sparse_categorical_accuracy: 0.7724\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 38/50\n",
            "196/196 - 7s - loss: 0.6642 - sparse_categorical_accuracy: 0.7662 - val_loss: 0.6731 - val_sparse_categorical_accuracy: 0.7757\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 39/50\n",
            "196/196 - 7s - loss: 0.6577 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.7577 - val_sparse_categorical_accuracy: 0.7710\n",
            "Epoch 40/50\n",
            "196/196 - 7s - loss: 0.6533 - sparse_categorical_accuracy: 0.7695 - val_loss: 0.6608 - val_sparse_categorical_accuracy: 0.7697\n",
            "Epoch 41/50\n",
            "196/196 - 7s - loss: 0.6450 - sparse_categorical_accuracy: 0.7718 - val_loss: 0.7292 - val_sparse_categorical_accuracy: 0.7729\n",
            "Epoch 42/50\n",
            "196/196 - 7s - loss: 0.6411 - sparse_categorical_accuracy: 0.7759 - val_loss: 0.7134 - val_sparse_categorical_accuracy: 0.7776\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 43/50\n",
            "196/196 - 7s - loss: 0.6436 - sparse_categorical_accuracy: 0.7766 - val_loss: 0.6722 - val_sparse_categorical_accuracy: 0.7692\n",
            "Epoch 44/50\n",
            "196/196 - 7s - loss: 0.6320 - sparse_categorical_accuracy: 0.7787 - val_loss: 0.7431 - val_sparse_categorical_accuracy: 0.7784\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 45/50\n",
            "196/196 - 7s - loss: 0.6264 - sparse_categorical_accuracy: 0.7809 - val_loss: 0.6791 - val_sparse_categorical_accuracy: 0.7696\n",
            "Epoch 46/50\n",
            "196/196 - 7s - loss: 0.6293 - sparse_categorical_accuracy: 0.7780 - val_loss: 0.6952 - val_sparse_categorical_accuracy: 0.7759\n",
            "Epoch 47/50\n",
            "196/196 - 7s - loss: 0.6185 - sparse_categorical_accuracy: 0.7817 - val_loss: 0.6736 - val_sparse_categorical_accuracy: 0.7762\n",
            "Epoch 48/50\n",
            "196/196 - 7s - loss: 0.6176 - sparse_categorical_accuracy: 0.7825 - val_loss: 0.6875 - val_sparse_categorical_accuracy: 0.7786\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 49/50\n",
            "196/196 - 7s - loss: 0.6080 - sparse_categorical_accuracy: 0.7861 - val_loss: 0.7806 - val_sparse_categorical_accuracy: 0.7802\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_8_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 50/50\n",
            "196/196 - 7s - loss: 0.6087 - sparse_categorical_accuracy: 0.7856 - val_loss: 0.6901 - val_sparse_categorical_accuracy: 0.7722\n",
            "Total training time 453.823739528656 seconds\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        5220      \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        7524      \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,208,178\n",
            "Trainable params: 1,208,178\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 11s - loss: 1.9904 - sparse_categorical_accuracy: 0.2633 - val_loss: 1.8388 - val_sparse_categorical_accuracy: 0.3167\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 9s - loss: 1.6306 - sparse_categorical_accuracy: 0.3962 - val_loss: 1.6429 - val_sparse_categorical_accuracy: 0.3919\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "196/196 - 9s - loss: 1.4918 - sparse_categorical_accuracy: 0.4588 - val_loss: 1.5069 - val_sparse_categorical_accuracy: 0.4582\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 9s - loss: 1.3965 - sparse_categorical_accuracy: 0.4971 - val_loss: 1.3559 - val_sparse_categorical_accuracy: 0.5209\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "196/196 - 9s - loss: 1.3204 - sparse_categorical_accuracy: 0.5263 - val_loss: 1.2623 - val_sparse_categorical_accuracy: 0.5538\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/50\n",
            "196/196 - 9s - loss: 1.2538 - sparse_categorical_accuracy: 0.5507 - val_loss: 1.1396 - val_sparse_categorical_accuracy: 0.5957\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "196/196 - 9s - loss: 1.2056 - sparse_categorical_accuracy: 0.5702 - val_loss: 1.0935 - val_sparse_categorical_accuracy: 0.6107\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/50\n",
            "196/196 - 9s - loss: 1.1658 - sparse_categorical_accuracy: 0.5843 - val_loss: 1.1232 - val_sparse_categorical_accuracy: 0.5988\n",
            "Epoch 9/50\n",
            "196/196 - 9s - loss: 1.1264 - sparse_categorical_accuracy: 0.6002 - val_loss: 1.0188 - val_sparse_categorical_accuracy: 0.6351\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/50\n",
            "196/196 - 9s - loss: 1.1000 - sparse_categorical_accuracy: 0.6103 - val_loss: 1.0102 - val_sparse_categorical_accuracy: 0.6399\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/50\n",
            "196/196 - 9s - loss: 1.0627 - sparse_categorical_accuracy: 0.6231 - val_loss: 0.9443 - val_sparse_categorical_accuracy: 0.6645\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/50\n",
            "196/196 - 9s - loss: 1.0409 - sparse_categorical_accuracy: 0.6292 - val_loss: 0.9514 - val_sparse_categorical_accuracy: 0.6612\n",
            "Epoch 13/50\n",
            "196/196 - 9s - loss: 1.0138 - sparse_categorical_accuracy: 0.6392 - val_loss: 0.9127 - val_sparse_categorical_accuracy: 0.6816\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/50\n",
            "196/196 - 9s - loss: 0.9970 - sparse_categorical_accuracy: 0.6473 - val_loss: 0.9017 - val_sparse_categorical_accuracy: 0.6792\n",
            "Epoch 15/50\n",
            "196/196 - 9s - loss: 0.9774 - sparse_categorical_accuracy: 0.6549 - val_loss: 0.9261 - val_sparse_categorical_accuracy: 0.6684\n",
            "Epoch 16/50\n",
            "196/196 - 9s - loss: 0.9602 - sparse_categorical_accuracy: 0.6606 - val_loss: 0.8860 - val_sparse_categorical_accuracy: 0.6903\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 17/50\n",
            "196/196 - 9s - loss: 0.9534 - sparse_categorical_accuracy: 0.6631 - val_loss: 0.8511 - val_sparse_categorical_accuracy: 0.7053\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18/50\n",
            "196/196 - 9s - loss: 0.9321 - sparse_categorical_accuracy: 0.6675 - val_loss: 0.8554 - val_sparse_categorical_accuracy: 0.7052\n",
            "Epoch 19/50\n",
            "196/196 - 9s - loss: 0.9125 - sparse_categorical_accuracy: 0.6799 - val_loss: 0.8252 - val_sparse_categorical_accuracy: 0.7126\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20/50\n",
            "196/196 - 9s - loss: 0.8975 - sparse_categorical_accuracy: 0.6834 - val_loss: 0.8061 - val_sparse_categorical_accuracy: 0.7167\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 21/50\n",
            "196/196 - 9s - loss: 0.8919 - sparse_categorical_accuracy: 0.6847 - val_loss: 0.7913 - val_sparse_categorical_accuracy: 0.7275\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 22/50\n",
            "196/196 - 9s - loss: 0.8760 - sparse_categorical_accuracy: 0.6903 - val_loss: 0.8194 - val_sparse_categorical_accuracy: 0.7125\n",
            "Epoch 23/50\n",
            "196/196 - 9s - loss: 0.8696 - sparse_categorical_accuracy: 0.6947 - val_loss: 0.7995 - val_sparse_categorical_accuracy: 0.7178\n",
            "Epoch 24/50\n",
            "196/196 - 9s - loss: 0.8562 - sparse_categorical_accuracy: 0.6976 - val_loss: 0.8158 - val_sparse_categorical_accuracy: 0.7175\n",
            "Epoch 25/50\n",
            "196/196 - 9s - loss: 0.8582 - sparse_categorical_accuracy: 0.7000 - val_loss: 0.7918 - val_sparse_categorical_accuracy: 0.7314\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 26/50\n",
            "196/196 - 9s - loss: 0.8424 - sparse_categorical_accuracy: 0.7034 - val_loss: 0.7977 - val_sparse_categorical_accuracy: 0.7218\n",
            "Epoch 27/50\n",
            "196/196 - 9s - loss: 0.8245 - sparse_categorical_accuracy: 0.7128 - val_loss: 0.7780 - val_sparse_categorical_accuracy: 0.7328\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 28/50\n",
            "196/196 - 9s - loss: 0.8244 - sparse_categorical_accuracy: 0.7091 - val_loss: 0.7667 - val_sparse_categorical_accuracy: 0.7345\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 29/50\n",
            "196/196 - 9s - loss: 0.8129 - sparse_categorical_accuracy: 0.7128 - val_loss: 0.7727 - val_sparse_categorical_accuracy: 0.7381\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 30/50\n",
            "196/196 - 9s - loss: 0.8061 - sparse_categorical_accuracy: 0.7146 - val_loss: 0.7427 - val_sparse_categorical_accuracy: 0.7493\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 31/50\n",
            "196/196 - 9s - loss: 0.8018 - sparse_categorical_accuracy: 0.7183 - val_loss: 0.7518 - val_sparse_categorical_accuracy: 0.7478\n",
            "Epoch 32/50\n",
            "196/196 - 9s - loss: 0.7878 - sparse_categorical_accuracy: 0.7209 - val_loss: 0.7938 - val_sparse_categorical_accuracy: 0.7322\n",
            "Epoch 33/50\n",
            "196/196 - 9s - loss: 0.7843 - sparse_categorical_accuracy: 0.7238 - val_loss: 0.7286 - val_sparse_categorical_accuracy: 0.7511\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 34/50\n",
            "196/196 - 9s - loss: 0.7786 - sparse_categorical_accuracy: 0.7233 - val_loss: 0.7221 - val_sparse_categorical_accuracy: 0.7531\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 35/50\n",
            "196/196 - 9s - loss: 0.7735 - sparse_categorical_accuracy: 0.7285 - val_loss: 0.7132 - val_sparse_categorical_accuracy: 0.7536\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 36/50\n",
            "196/196 - 9s - loss: 0.7671 - sparse_categorical_accuracy: 0.7321 - val_loss: 0.7272 - val_sparse_categorical_accuracy: 0.7485\n",
            "Epoch 37/50\n",
            "196/196 - 9s - loss: 0.7600 - sparse_categorical_accuracy: 0.7301 - val_loss: 0.7214 - val_sparse_categorical_accuracy: 0.7482\n",
            "Epoch 38/50\n",
            "196/196 - 9s - loss: 0.7522 - sparse_categorical_accuracy: 0.7347 - val_loss: 0.7361 - val_sparse_categorical_accuracy: 0.7551\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 39/50\n",
            "196/196 - 9s - loss: 0.7472 - sparse_categorical_accuracy: 0.7367 - val_loss: 0.7006 - val_sparse_categorical_accuracy: 0.7584\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 40/50\n",
            "196/196 - 9s - loss: 0.7482 - sparse_categorical_accuracy: 0.7366 - val_loss: 0.7020 - val_sparse_categorical_accuracy: 0.7606\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 41/50\n",
            "196/196 - 9s - loss: 0.7469 - sparse_categorical_accuracy: 0.7393 - val_loss: 0.6829 - val_sparse_categorical_accuracy: 0.7578\n",
            "Epoch 42/50\n",
            "196/196 - 9s - loss: 0.7285 - sparse_categorical_accuracy: 0.7450 - val_loss: 0.7203 - val_sparse_categorical_accuracy: 0.7565\n",
            "Epoch 43/50\n",
            "196/196 - 9s - loss: 0.7275 - sparse_categorical_accuracy: 0.7423 - val_loss: 0.7289 - val_sparse_categorical_accuracy: 0.7548\n",
            "Epoch 44/50\n",
            "196/196 - 9s - loss: 0.7263 - sparse_categorical_accuracy: 0.7435 - val_loss: 0.7193 - val_sparse_categorical_accuracy: 0.7605\n",
            "Epoch 45/50\n",
            "196/196 - 9s - loss: 0.7216 - sparse_categorical_accuracy: 0.7477 - val_loss: 0.7067 - val_sparse_categorical_accuracy: 0.7627\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 46/50\n",
            "196/196 - 9s - loss: 0.7200 - sparse_categorical_accuracy: 0.7454 - val_loss: 0.6934 - val_sparse_categorical_accuracy: 0.7640\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 47/50\n",
            "196/196 - 9s - loss: 0.7112 - sparse_categorical_accuracy: 0.7491 - val_loss: 0.7511 - val_sparse_categorical_accuracy: 0.7565\n",
            "Epoch 48/50\n",
            "196/196 - 9s - loss: 0.7132 - sparse_categorical_accuracy: 0.7481 - val_loss: 0.7147 - val_sparse_categorical_accuracy: 0.7621\n",
            "Epoch 49/50\n",
            "196/196 - 9s - loss: 0.7095 - sparse_categorical_accuracy: 0.7488 - val_loss: 0.7001 - val_sparse_categorical_accuracy: 0.7712\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_12_layer_call_and_return_conditional_losses, conv2d_12_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 50/50\n",
            "196/196 - 9s - loss: 0.6977 - sparse_categorical_accuracy: 0.7544 - val_loss: 0.6865 - val_sparse_categorical_accuracy: 0.7666\n",
            "Total training time 532.0076651573181 seconds\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        8392      \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        10952     \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,214,778\n",
            "Trainable params: 1,214,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 15s - loss: 1.9523 - sparse_categorical_accuracy: 0.2882 - val_loss: 1.6864 - val_sparse_categorical_accuracy: 0.3954\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 12s - loss: 1.5610 - sparse_categorical_accuracy: 0.4347 - val_loss: 1.4166 - val_sparse_categorical_accuracy: 0.4862\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "196/196 - 12s - loss: 1.3839 - sparse_categorical_accuracy: 0.5066 - val_loss: 1.2452 - val_sparse_categorical_accuracy: 0.5584\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 12s - loss: 1.2668 - sparse_categorical_accuracy: 0.5491 - val_loss: 1.1081 - val_sparse_categorical_accuracy: 0.6044\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "196/196 - 12s - loss: 1.1922 - sparse_categorical_accuracy: 0.5757 - val_loss: 1.1114 - val_sparse_categorical_accuracy: 0.6141\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/50\n",
            "196/196 - 12s - loss: 1.1366 - sparse_categorical_accuracy: 0.5987 - val_loss: 1.0676 - val_sparse_categorical_accuracy: 0.6257\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "196/196 - 12s - loss: 1.0889 - sparse_categorical_accuracy: 0.6122 - val_loss: 1.0057 - val_sparse_categorical_accuracy: 0.6438\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/50\n",
            "196/196 - 12s - loss: 1.0611 - sparse_categorical_accuracy: 0.6246 - val_loss: 0.9536 - val_sparse_categorical_accuracy: 0.6679\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/50\n",
            "196/196 - 12s - loss: 1.0389 - sparse_categorical_accuracy: 0.6338 - val_loss: 0.9855 - val_sparse_categorical_accuracy: 0.6512\n",
            "Epoch 10/50\n",
            "196/196 - 12s - loss: 1.0130 - sparse_categorical_accuracy: 0.6415 - val_loss: 1.0033 - val_sparse_categorical_accuracy: 0.6505\n",
            "Epoch 11/50\n",
            "196/196 - 12s - loss: 0.9966 - sparse_categorical_accuracy: 0.6484 - val_loss: 0.9303 - val_sparse_categorical_accuracy: 0.6725\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/50\n",
            "196/196 - 12s - loss: 0.9730 - sparse_categorical_accuracy: 0.6565 - val_loss: 0.8736 - val_sparse_categorical_accuracy: 0.6951\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13/50\n",
            "196/196 - 12s - loss: 0.9585 - sparse_categorical_accuracy: 0.6617 - val_loss: 0.9164 - val_sparse_categorical_accuracy: 0.6814\n",
            "Epoch 14/50\n",
            "196/196 - 12s - loss: 0.9404 - sparse_categorical_accuracy: 0.6667 - val_loss: 0.8682 - val_sparse_categorical_accuracy: 0.7014\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15/50\n",
            "196/196 - 12s - loss: 0.9221 - sparse_categorical_accuracy: 0.6752 - val_loss: 0.8863 - val_sparse_categorical_accuracy: 0.6896\n",
            "Epoch 16/50\n",
            "196/196 - 12s - loss: 0.9132 - sparse_categorical_accuracy: 0.6774 - val_loss: 0.8425 - val_sparse_categorical_accuracy: 0.7055\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 17/50\n",
            "196/196 - 12s - loss: 0.8952 - sparse_categorical_accuracy: 0.6852 - val_loss: 0.8535 - val_sparse_categorical_accuracy: 0.7077\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18/50\n",
            "196/196 - 12s - loss: 0.8775 - sparse_categorical_accuracy: 0.6906 - val_loss: 0.8146 - val_sparse_categorical_accuracy: 0.7123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 19/50\n",
            "196/196 - 12s - loss: 0.8716 - sparse_categorical_accuracy: 0.6933 - val_loss: 0.7787 - val_sparse_categorical_accuracy: 0.7321\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20/50\n",
            "196/196 - 12s - loss: 0.8623 - sparse_categorical_accuracy: 0.6964 - val_loss: 0.7856 - val_sparse_categorical_accuracy: 0.7260\n",
            "Epoch 21/50\n",
            "196/196 - 12s - loss: 0.8515 - sparse_categorical_accuracy: 0.7000 - val_loss: 0.8019 - val_sparse_categorical_accuracy: 0.7227\n",
            "Epoch 22/50\n",
            "196/196 - 12s - loss: 0.8382 - sparse_categorical_accuracy: 0.7076 - val_loss: 0.7709 - val_sparse_categorical_accuracy: 0.7308\n",
            "Epoch 23/50\n",
            "196/196 - 12s - loss: 0.8263 - sparse_categorical_accuracy: 0.7099 - val_loss: 0.7604 - val_sparse_categorical_accuracy: 0.7384\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 24/50\n",
            "196/196 - 12s - loss: 0.8238 - sparse_categorical_accuracy: 0.7098 - val_loss: 0.7479 - val_sparse_categorical_accuracy: 0.7409\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 25/50\n",
            "196/196 - 12s - loss: 0.8139 - sparse_categorical_accuracy: 0.7131 - val_loss: 0.7480 - val_sparse_categorical_accuracy: 0.7412\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 26/50\n",
            "196/196 - 12s - loss: 0.8046 - sparse_categorical_accuracy: 0.7194 - val_loss: 0.7476 - val_sparse_categorical_accuracy: 0.7430\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 27/50\n",
            "196/196 - 12s - loss: 0.7948 - sparse_categorical_accuracy: 0.7219 - val_loss: 0.7418 - val_sparse_categorical_accuracy: 0.7477\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 28/50\n",
            "196/196 - 12s - loss: 0.7923 - sparse_categorical_accuracy: 0.7212 - val_loss: 0.7497 - val_sparse_categorical_accuracy: 0.7454\n",
            "Epoch 29/50\n",
            "196/196 - 12s - loss: 0.7785 - sparse_categorical_accuracy: 0.7262 - val_loss: 0.7477 - val_sparse_categorical_accuracy: 0.7423\n",
            "Epoch 30/50\n",
            "196/196 - 12s - loss: 0.7746 - sparse_categorical_accuracy: 0.7281 - val_loss: 0.7290 - val_sparse_categorical_accuracy: 0.7522\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 31/50\n",
            "196/196 - 12s - loss: 0.7632 - sparse_categorical_accuracy: 0.7305 - val_loss: 0.7306 - val_sparse_categorical_accuracy: 0.7475\n",
            "Epoch 32/50\n",
            "196/196 - 12s - loss: 0.7632 - sparse_categorical_accuracy: 0.7327 - val_loss: 0.7634 - val_sparse_categorical_accuracy: 0.7514\n",
            "Epoch 33/50\n",
            "196/196 - 12s - loss: 0.7551 - sparse_categorical_accuracy: 0.7351 - val_loss: 0.7331 - val_sparse_categorical_accuracy: 0.7483\n",
            "Epoch 34/50\n",
            "196/196 - 12s - loss: 0.7429 - sparse_categorical_accuracy: 0.7378 - val_loss: 0.7759 - val_sparse_categorical_accuracy: 0.7436\n",
            "Epoch 35/50\n",
            "196/196 - 12s - loss: 0.7435 - sparse_categorical_accuracy: 0.7379 - val_loss: 0.7278 - val_sparse_categorical_accuracy: 0.7542\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 36/50\n",
            "196/196 - 12s - loss: 0.7376 - sparse_categorical_accuracy: 0.7429 - val_loss: 0.7493 - val_sparse_categorical_accuracy: 0.7549\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 37/50\n",
            "196/196 - 12s - loss: 0.7296 - sparse_categorical_accuracy: 0.7460 - val_loss: 0.7302 - val_sparse_categorical_accuracy: 0.7583\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 38/50\n",
            "196/196 - 12s - loss: 0.7254 - sparse_categorical_accuracy: 0.7445 - val_loss: 0.7003 - val_sparse_categorical_accuracy: 0.7573\n",
            "Epoch 39/50\n",
            "196/196 - 12s - loss: 0.7257 - sparse_categorical_accuracy: 0.7443 - val_loss: 0.6964 - val_sparse_categorical_accuracy: 0.7591\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 40/50\n",
            "196/196 - 12s - loss: 0.7138 - sparse_categorical_accuracy: 0.7478 - val_loss: 0.7537 - val_sparse_categorical_accuracy: 0.7565\n",
            "Epoch 41/50\n",
            "196/196 - 12s - loss: 0.7145 - sparse_categorical_accuracy: 0.7475 - val_loss: 0.7140 - val_sparse_categorical_accuracy: 0.7630\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 42/50\n",
            "196/196 - 12s - loss: 0.7073 - sparse_categorical_accuracy: 0.7485 - val_loss: 0.6851 - val_sparse_categorical_accuracy: 0.7658\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 43/50\n",
            "196/196 - 12s - loss: 0.7120 - sparse_categorical_accuracy: 0.7510 - val_loss: 0.7303 - val_sparse_categorical_accuracy: 0.7569\n",
            "Epoch 44/50\n",
            "196/196 - 12s - loss: 0.6956 - sparse_categorical_accuracy: 0.7568 - val_loss: 0.6921 - val_sparse_categorical_accuracy: 0.7661\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 45/50\n",
            "196/196 - 12s - loss: 0.6963 - sparse_categorical_accuracy: 0.7534 - val_loss: 0.7135 - val_sparse_categorical_accuracy: 0.7700\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 46/50\n",
            "196/196 - 12s - loss: 0.6895 - sparse_categorical_accuracy: 0.7568 - val_loss: 0.7127 - val_sparse_categorical_accuracy: 0.7673\n",
            "Epoch 47/50\n",
            "196/196 - 12s - loss: 0.6820 - sparse_categorical_accuracy: 0.7601 - val_loss: 0.6858 - val_sparse_categorical_accuracy: 0.7707\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 48/50\n",
            "196/196 - 12s - loss: 0.6855 - sparse_categorical_accuracy: 0.7580 - val_loss: 0.7589 - val_sparse_categorical_accuracy: 0.7572\n",
            "Epoch 49/50\n",
            "196/196 - 12s - loss: 0.6846 - sparse_categorical_accuracy: 0.7592 - val_loss: 0.7247 - val_sparse_categorical_accuracy: 0.7692\n",
            "Epoch 50/50\n",
            "196/196 - 12s - loss: 0.6715 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.7261 - val_sparse_categorical_accuracy: 0.7735\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_18_layer_call_and_return_conditional_losses, conv2d_18_layer_call_fn, conv2d_19_layer_call_and_return_conditional_losses, conv2d_19_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total training time 700.6704387664795 seconds\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        1849      \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        2969      \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,200,252\n",
            "Trainable params: 1,200,252\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 8s - loss: 1.9118 - sparse_categorical_accuracy: 0.2989 - val_loss: 1.8679 - val_sparse_categorical_accuracy: 0.3444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 5s - loss: 1.5545 - sparse_categorical_accuracy: 0.4336 - val_loss: 1.5173 - val_sparse_categorical_accuracy: 0.4606\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "196/196 - 5s - loss: 1.4040 - sparse_categorical_accuracy: 0.4960 - val_loss: 1.5181 - val_sparse_categorical_accuracy: 0.4681\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 5s - loss: 1.3132 - sparse_categorical_accuracy: 0.5285 - val_loss: 1.2491 - val_sparse_categorical_accuracy: 0.5497\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "196/196 - 5s - loss: 1.2354 - sparse_categorical_accuracy: 0.5591 - val_loss: 1.2800 - val_sparse_categorical_accuracy: 0.5489\n",
            "Epoch 6/50\n",
            "196/196 - 5s - loss: 1.1821 - sparse_categorical_accuracy: 0.5804 - val_loss: 1.1105 - val_sparse_categorical_accuracy: 0.6087\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "196/196 - 5s - loss: 1.1332 - sparse_categorical_accuracy: 0.5973 - val_loss: 1.1108 - val_sparse_categorical_accuracy: 0.6141\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/50\n",
            "196/196 - 5s - loss: 1.0989 - sparse_categorical_accuracy: 0.6124 - val_loss: 1.0447 - val_sparse_categorical_accuracy: 0.6318\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/50\n",
            "196/196 - 5s - loss: 1.0656 - sparse_categorical_accuracy: 0.6234 - val_loss: 1.0577 - val_sparse_categorical_accuracy: 0.6361\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/50\n",
            "196/196 - 5s - loss: 1.0408 - sparse_categorical_accuracy: 0.6350 - val_loss: 1.0399 - val_sparse_categorical_accuracy: 0.6360\n",
            "Epoch 11/50\n",
            "196/196 - 5s - loss: 1.0247 - sparse_categorical_accuracy: 0.6408 - val_loss: 0.9941 - val_sparse_categorical_accuracy: 0.6586\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/50\n",
            "196/196 - 5s - loss: 0.9985 - sparse_categorical_accuracy: 0.6480 - val_loss: 0.9405 - val_sparse_categorical_accuracy: 0.6673\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13/50\n",
            "196/196 - 5s - loss: 0.9728 - sparse_categorical_accuracy: 0.6561 - val_loss: 0.9888 - val_sparse_categorical_accuracy: 0.6638\n",
            "Epoch 14/50\n",
            "196/196 - 5s - loss: 0.9572 - sparse_categorical_accuracy: 0.6625 - val_loss: 0.8834 - val_sparse_categorical_accuracy: 0.6949\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15/50\n",
            "196/196 - 5s - loss: 0.9426 - sparse_categorical_accuracy: 0.6670 - val_loss: 1.0106 - val_sparse_categorical_accuracy: 0.6664\n",
            "Epoch 16/50\n",
            "196/196 - 5s - loss: 0.9281 - sparse_categorical_accuracy: 0.6741 - val_loss: 0.8696 - val_sparse_categorical_accuracy: 0.6961\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 17/50\n",
            "196/196 - 5s - loss: 0.9085 - sparse_categorical_accuracy: 0.6796 - val_loss: 0.9098 - val_sparse_categorical_accuracy: 0.6883\n",
            "Epoch 18/50\n",
            "196/196 - 5s - loss: 0.9015 - sparse_categorical_accuracy: 0.6839 - val_loss: 0.8612 - val_sparse_categorical_accuracy: 0.7024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 19/50\n",
            "196/196 - 5s - loss: 0.8902 - sparse_categorical_accuracy: 0.6835 - val_loss: 0.8483 - val_sparse_categorical_accuracy: 0.7089\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20/50\n",
            "196/196 - 5s - loss: 0.8724 - sparse_categorical_accuracy: 0.6931 - val_loss: 0.8462 - val_sparse_categorical_accuracy: 0.7085\n",
            "Epoch 21/50\n",
            "196/196 - 5s - loss: 0.8621 - sparse_categorical_accuracy: 0.6949 - val_loss: 0.8579 - val_sparse_categorical_accuracy: 0.7058\n",
            "Epoch 22/50\n",
            "196/196 - 5s - loss: 0.8459 - sparse_categorical_accuracy: 0.7019 - val_loss: 0.7901 - val_sparse_categorical_accuracy: 0.7239\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 23/50\n",
            "196/196 - 5s - loss: 0.8470 - sparse_categorical_accuracy: 0.7018 - val_loss: 0.8293 - val_sparse_categorical_accuracy: 0.7111\n",
            "Epoch 24/50\n",
            "196/196 - 5s - loss: 0.8334 - sparse_categorical_accuracy: 0.7053 - val_loss: 0.8277 - val_sparse_categorical_accuracy: 0.7158\n",
            "Epoch 25/50\n",
            "196/196 - 5s - loss: 0.8189 - sparse_categorical_accuracy: 0.7110 - val_loss: 0.7818 - val_sparse_categorical_accuracy: 0.7294\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 26/50\n",
            "196/196 - 5s - loss: 0.8100 - sparse_categorical_accuracy: 0.7145 - val_loss: 0.7769 - val_sparse_categorical_accuracy: 0.7309\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 27/50\n",
            "196/196 - 5s - loss: 0.8022 - sparse_categorical_accuracy: 0.7134 - val_loss: 0.7737 - val_sparse_categorical_accuracy: 0.7310\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 28/50\n",
            "196/196 - 5s - loss: 0.8024 - sparse_categorical_accuracy: 0.7156 - val_loss: 0.8119 - val_sparse_categorical_accuracy: 0.7237\n",
            "Epoch 29/50\n",
            "196/196 - 5s - loss: 0.7834 - sparse_categorical_accuracy: 0.7249 - val_loss: 0.7744 - val_sparse_categorical_accuracy: 0.7352\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 30/50\n",
            "196/196 - 5s - loss: 0.7821 - sparse_categorical_accuracy: 0.7251 - val_loss: 0.7727 - val_sparse_categorical_accuracy: 0.7295\n",
            "Epoch 31/50\n",
            "196/196 - 5s - loss: 0.7636 - sparse_categorical_accuracy: 0.7284 - val_loss: 0.7556 - val_sparse_categorical_accuracy: 0.7365\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 32/50\n",
            "196/196 - 5s - loss: 0.7644 - sparse_categorical_accuracy: 0.7322 - val_loss: 0.7409 - val_sparse_categorical_accuracy: 0.7416\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 33/50\n",
            "196/196 - 5s - loss: 0.7575 - sparse_categorical_accuracy: 0.7351 - val_loss: 0.7718 - val_sparse_categorical_accuracy: 0.7369\n",
            "Epoch 34/50\n",
            "196/196 - 5s - loss: 0.7492 - sparse_categorical_accuracy: 0.7335 - val_loss: 0.7755 - val_sparse_categorical_accuracy: 0.7404\n",
            "Epoch 35/50\n",
            "196/196 - 5s - loss: 0.7436 - sparse_categorical_accuracy: 0.7391 - val_loss: 0.7726 - val_sparse_categorical_accuracy: 0.7362\n",
            "Epoch 36/50\n",
            "196/196 - 5s - loss: 0.7351 - sparse_categorical_accuracy: 0.7403 - val_loss: 0.7513 - val_sparse_categorical_accuracy: 0.7413\n",
            "Epoch 37/50\n",
            "196/196 - 5s - loss: 0.7362 - sparse_categorical_accuracy: 0.7409 - val_loss: 0.7556 - val_sparse_categorical_accuracy: 0.7419\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 38/50\n",
            "196/196 - 5s - loss: 0.7287 - sparse_categorical_accuracy: 0.7420 - val_loss: 0.7239 - val_sparse_categorical_accuracy: 0.7471\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 39/50\n",
            "196/196 - 5s - loss: 0.7178 - sparse_categorical_accuracy: 0.7468 - val_loss: 0.7332 - val_sparse_categorical_accuracy: 0.7481\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 40/50\n",
            "196/196 - 5s - loss: 0.7165 - sparse_categorical_accuracy: 0.7472 - val_loss: 0.7205 - val_sparse_categorical_accuracy: 0.7516\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 41/50\n",
            "196/196 - 5s - loss: 0.7122 - sparse_categorical_accuracy: 0.7475 - val_loss: 0.7449 - val_sparse_categorical_accuracy: 0.7495\n",
            "Epoch 42/50\n",
            "196/196 - 5s - loss: 0.7105 - sparse_categorical_accuracy: 0.7506 - val_loss: 0.7328 - val_sparse_categorical_accuracy: 0.7509\n",
            "Epoch 43/50\n",
            "196/196 - 5s - loss: 0.6995 - sparse_categorical_accuracy: 0.7514 - val_loss: 0.7253 - val_sparse_categorical_accuracy: 0.7483\n",
            "Epoch 44/50\n",
            "196/196 - 5s - loss: 0.6947 - sparse_categorical_accuracy: 0.7518 - val_loss: 0.7117 - val_sparse_categorical_accuracy: 0.7559\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 45/50\n",
            "196/196 - 5s - loss: 0.6974 - sparse_categorical_accuracy: 0.7539 - val_loss: 0.7447 - val_sparse_categorical_accuracy: 0.7477\n",
            "Epoch 46/50\n",
            "196/196 - 5s - loss: 0.6900 - sparse_categorical_accuracy: 0.7547 - val_loss: 0.7548 - val_sparse_categorical_accuracy: 0.7391\n",
            "Epoch 47/50\n",
            "196/196 - 5s - loss: 0.6806 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.7556 - val_sparse_categorical_accuracy: 0.7496\n",
            "Epoch 48/50\n",
            "196/196 - 5s - loss: 0.6761 - sparse_categorical_accuracy: 0.7600 - val_loss: 0.7621 - val_sparse_categorical_accuracy: 0.7449\n",
            "Epoch 49/50\n",
            "196/196 - 5s - loss: 0.6733 - sparse_categorical_accuracy: 0.7602 - val_loss: 0.7211 - val_sparse_categorical_accuracy: 0.7565\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 50/50\n",
            "196/196 - 5s - loss: 0.6647 - sparse_categorical_accuracy: 0.7641 - val_loss: 0.7306 - val_sparse_categorical_accuracy: 0.7566\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_24_layer_call_and_return_conditional_losses, conv2d_24_layer_call_fn, conv2d_25_layer_call_and_return_conditional_losses, conv2d_25_layer_call_fn, conv2d_26_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total training time 340.5862612724304 seconds\n",
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        2674      \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        3890      \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,201,998\n",
            "Trainable params: 1,201,998\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 9s - loss: 1.9327 - sparse_categorical_accuracy: 0.2886 - val_loss: 1.6771 - val_sparse_categorical_accuracy: 0.3732\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 7s - loss: 1.5735 - sparse_categorical_accuracy: 0.4310 - val_loss: 1.5155 - val_sparse_categorical_accuracy: 0.4496\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "196/196 - 6s - loss: 1.4286 - sparse_categorical_accuracy: 0.4872 - val_loss: 1.3944 - val_sparse_categorical_accuracy: 0.4950\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 6s - loss: 1.3221 - sparse_categorical_accuracy: 0.5296 - val_loss: 1.3497 - val_sparse_categorical_accuracy: 0.5154\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "196/196 - 7s - loss: 1.2448 - sparse_categorical_accuracy: 0.5602 - val_loss: 1.1931 - val_sparse_categorical_accuracy: 0.5789\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/50\n",
            "196/196 - 6s - loss: 1.1795 - sparse_categorical_accuracy: 0.5815 - val_loss: 1.1659 - val_sparse_categorical_accuracy: 0.5908\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "196/196 - 6s - loss: 1.1238 - sparse_categorical_accuracy: 0.6018 - val_loss: 1.0859 - val_sparse_categorical_accuracy: 0.6116\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/50\n",
            "196/196 - 6s - loss: 1.0814 - sparse_categorical_accuracy: 0.6183 - val_loss: 1.0746 - val_sparse_categorical_accuracy: 0.6318\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/50\n",
            "196/196 - 6s - loss: 1.0555 - sparse_categorical_accuracy: 0.6266 - val_loss: 0.9812 - val_sparse_categorical_accuracy: 0.6563\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/50\n",
            "196/196 - 6s - loss: 1.0129 - sparse_categorical_accuracy: 0.6421 - val_loss: 0.9438 - val_sparse_categorical_accuracy: 0.6704\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/50\n",
            "196/196 - 6s - loss: 0.9947 - sparse_categorical_accuracy: 0.6475 - val_loss: 0.9323 - val_sparse_categorical_accuracy: 0.6706\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/50\n",
            "196/196 - 6s - loss: 0.9837 - sparse_categorical_accuracy: 0.6517 - val_loss: 0.9043 - val_sparse_categorical_accuracy: 0.6774\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13/50\n",
            "196/196 - 6s - loss: 0.9530 - sparse_categorical_accuracy: 0.6616 - val_loss: 0.9193 - val_sparse_categorical_accuracy: 0.6730\n",
            "Epoch 14/50\n",
            "196/196 - 6s - loss: 0.9299 - sparse_categorical_accuracy: 0.6718 - val_loss: 0.8904 - val_sparse_categorical_accuracy: 0.6866\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15/50\n",
            "196/196 - 6s - loss: 0.9197 - sparse_categorical_accuracy: 0.6746 - val_loss: 0.8374 - val_sparse_categorical_accuracy: 0.7019\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16/50\n",
            "196/196 - 6s - loss: 0.9023 - sparse_categorical_accuracy: 0.6811 - val_loss: 0.8891 - val_sparse_categorical_accuracy: 0.7024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 17/50\n",
            "196/196 - 6s - loss: 0.8772 - sparse_categorical_accuracy: 0.6888 - val_loss: 0.8196 - val_sparse_categorical_accuracy: 0.7123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18/50\n",
            "196/196 - 6s - loss: 0.8664 - sparse_categorical_accuracy: 0.6932 - val_loss: 0.8140 - val_sparse_categorical_accuracy: 0.7082\n",
            "Epoch 19/50\n",
            "196/196 - 6s - loss: 0.8537 - sparse_categorical_accuracy: 0.6977 - val_loss: 0.8581 - val_sparse_categorical_accuracy: 0.7003\n",
            "Epoch 20/50\n",
            "196/196 - 6s - loss: 0.8384 - sparse_categorical_accuracy: 0.7040 - val_loss: 0.8267 - val_sparse_categorical_accuracy: 0.7141\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 21/50\n",
            "196/196 - 6s - loss: 0.8329 - sparse_categorical_accuracy: 0.7034 - val_loss: 0.7900 - val_sparse_categorical_accuracy: 0.7235\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 22/50\n",
            "196/196 - 6s - loss: 0.8204 - sparse_categorical_accuracy: 0.7111 - val_loss: 0.7670 - val_sparse_categorical_accuracy: 0.7286\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 23/50\n",
            "196/196 - 6s - loss: 0.8125 - sparse_categorical_accuracy: 0.7148 - val_loss: 0.7649 - val_sparse_categorical_accuracy: 0.7365\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 24/50\n",
            "196/196 - 7s - loss: 0.7948 - sparse_categorical_accuracy: 0.7215 - val_loss: 0.8128 - val_sparse_categorical_accuracy: 0.7232\n",
            "Epoch 25/50\n",
            "196/196 - 6s - loss: 0.7908 - sparse_categorical_accuracy: 0.7214 - val_loss: 0.8155 - val_sparse_categorical_accuracy: 0.7231\n",
            "Epoch 26/50\n",
            "196/196 - 6s - loss: 0.7778 - sparse_categorical_accuracy: 0.7276 - val_loss: 0.7483 - val_sparse_categorical_accuracy: 0.7377\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 27/50\n",
            "196/196 - 7s - loss: 0.7647 - sparse_categorical_accuracy: 0.7290 - val_loss: 0.7767 - val_sparse_categorical_accuracy: 0.7369\n",
            "Epoch 28/50\n",
            "196/196 - 6s - loss: 0.7679 - sparse_categorical_accuracy: 0.7312 - val_loss: 0.7449 - val_sparse_categorical_accuracy: 0.7442\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 29/50\n",
            "196/196 - 6s - loss: 0.7512 - sparse_categorical_accuracy: 0.7352 - val_loss: 0.7806 - val_sparse_categorical_accuracy: 0.7330\n",
            "Epoch 30/50\n",
            "196/196 - 6s - loss: 0.7450 - sparse_categorical_accuracy: 0.7365 - val_loss: 0.7643 - val_sparse_categorical_accuracy: 0.7425\n",
            "Epoch 31/50\n",
            "196/196 - 6s - loss: 0.7371 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.7432 - val_sparse_categorical_accuracy: 0.7501\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 32/50\n",
            "196/196 - 6s - loss: 0.7253 - sparse_categorical_accuracy: 0.7448 - val_loss: 0.7359 - val_sparse_categorical_accuracy: 0.7451\n",
            "Epoch 33/50\n",
            "196/196 - 6s - loss: 0.7207 - sparse_categorical_accuracy: 0.7445 - val_loss: 0.7110 - val_sparse_categorical_accuracy: 0.7517\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 34/50\n",
            "196/196 - 6s - loss: 0.7137 - sparse_categorical_accuracy: 0.7483 - val_loss: 0.8003 - val_sparse_categorical_accuracy: 0.7379\n",
            "Epoch 35/50\n",
            "196/196 - 6s - loss: 0.7124 - sparse_categorical_accuracy: 0.7489 - val_loss: 0.7414 - val_sparse_categorical_accuracy: 0.7535\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 36/50\n",
            "196/196 - 7s - loss: 0.7017 - sparse_categorical_accuracy: 0.7531 - val_loss: 0.7256 - val_sparse_categorical_accuracy: 0.7553\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 37/50\n",
            "196/196 - 6s - loss: 0.7025 - sparse_categorical_accuracy: 0.7515 - val_loss: 0.7299 - val_sparse_categorical_accuracy: 0.7558\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 38/50\n",
            "196/196 - 6s - loss: 0.6952 - sparse_categorical_accuracy: 0.7535 - val_loss: 0.7821 - val_sparse_categorical_accuracy: 0.7530\n",
            "Epoch 39/50\n",
            "196/196 - 6s - loss: 0.6867 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.7829 - val_sparse_categorical_accuracy: 0.7371\n",
            "Epoch 40/50\n",
            "196/196 - 6s - loss: 0.6803 - sparse_categorical_accuracy: 0.7585 - val_loss: 0.7131 - val_sparse_categorical_accuracy: 0.7607\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 41/50\n",
            "196/196 - 6s - loss: 0.6829 - sparse_categorical_accuracy: 0.7586 - val_loss: 0.7108 - val_sparse_categorical_accuracy: 0.7553\n",
            "Epoch 42/50\n",
            "196/196 - 6s - loss: 0.6831 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6900 - val_sparse_categorical_accuracy: 0.7638\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 43/50\n",
            "196/196 - 6s - loss: 0.6685 - sparse_categorical_accuracy: 0.7629 - val_loss: 0.7311 - val_sparse_categorical_accuracy: 0.7529\n",
            "Epoch 44/50\n",
            "196/196 - 6s - loss: 0.6638 - sparse_categorical_accuracy: 0.7659 - val_loss: 0.7322 - val_sparse_categorical_accuracy: 0.7631\n",
            "Epoch 45/50\n",
            "196/196 - 6s - loss: 0.6618 - sparse_categorical_accuracy: 0.7646 - val_loss: 0.7600 - val_sparse_categorical_accuracy: 0.7624\n",
            "Epoch 46/50\n",
            "196/196 - 6s - loss: 0.6532 - sparse_categorical_accuracy: 0.7691 - val_loss: 0.7493 - val_sparse_categorical_accuracy: 0.7562\n",
            "Epoch 47/50\n",
            "196/196 - 6s - loss: 0.6483 - sparse_categorical_accuracy: 0.7707 - val_loss: 0.7323 - val_sparse_categorical_accuracy: 0.7651\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, conv2d_32_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 48/50\n",
            "196/196 - 6s - loss: 0.6468 - sparse_categorical_accuracy: 0.7694 - val_loss: 0.7237 - val_sparse_categorical_accuracy: 0.7599\n",
            "Epoch 49/50\n",
            "196/196 - 6s - loss: 0.6397 - sparse_categorical_accuracy: 0.7725 - val_loss: 0.7442 - val_sparse_categorical_accuracy: 0.7606\n",
            "Epoch 50/50\n",
            "196/196 - 6s - loss: 0.6430 - sparse_categorical_accuracy: 0.7715 - val_loss: 0.7221 - val_sparse_categorical_accuracy: 0.7578\n",
            "Total training time 410.96551871299744 seconds\n",
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        4324      \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        5732      \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,205,490\n",
            "Trainable params: 1,205,490\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 9s - loss: 2.0805 - sparse_categorical_accuracy: 0.2297 - val_loss: 1.8544 - val_sparse_categorical_accuracy: 0.3158\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 7s - loss: 1.6734 - sparse_categorical_accuracy: 0.3863 - val_loss: 1.5832 - val_sparse_categorical_accuracy: 0.4295\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "196/196 - 7s - loss: 1.4839 - sparse_categorical_accuracy: 0.4635 - val_loss: 1.3634 - val_sparse_categorical_accuracy: 0.5053\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 7s - loss: 1.3540 - sparse_categorical_accuracy: 0.5154 - val_loss: 1.2204 - val_sparse_categorical_accuracy: 0.5625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "196/196 - 7s - loss: 1.2592 - sparse_categorical_accuracy: 0.5510 - val_loss: 1.1669 - val_sparse_categorical_accuracy: 0.5895\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/50\n",
            "196/196 - 7s - loss: 1.2002 - sparse_categorical_accuracy: 0.5735 - val_loss: 1.1012 - val_sparse_categorical_accuracy: 0.6063\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "196/196 - 7s - loss: 1.1436 - sparse_categorical_accuracy: 0.5932 - val_loss: 1.0811 - val_sparse_categorical_accuracy: 0.6195\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/50\n",
            "196/196 - 7s - loss: 1.1055 - sparse_categorical_accuracy: 0.6069 - val_loss: 1.0098 - val_sparse_categorical_accuracy: 0.6435\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/50\n",
            "196/196 - 7s - loss: 1.0674 - sparse_categorical_accuracy: 0.6203 - val_loss: 1.0455 - val_sparse_categorical_accuracy: 0.6323\n",
            "Epoch 10/50\n",
            "196/196 - 7s - loss: 1.0333 - sparse_categorical_accuracy: 0.6314 - val_loss: 0.9273 - val_sparse_categorical_accuracy: 0.6712\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/50\n",
            "196/196 - 7s - loss: 1.0071 - sparse_categorical_accuracy: 0.6431 - val_loss: 0.9073 - val_sparse_categorical_accuracy: 0.6760\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/50\n",
            "196/196 - 7s - loss: 0.9856 - sparse_categorical_accuracy: 0.6537 - val_loss: 0.9392 - val_sparse_categorical_accuracy: 0.6695\n",
            "Epoch 13/50\n",
            "196/196 - 7s - loss: 0.9636 - sparse_categorical_accuracy: 0.6595 - val_loss: 0.8697 - val_sparse_categorical_accuracy: 0.6916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/50\n",
            "196/196 - 7s - loss: 0.9467 - sparse_categorical_accuracy: 0.6645 - val_loss: 0.8399 - val_sparse_categorical_accuracy: 0.7040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15/50\n",
            "196/196 - 7s - loss: 0.9242 - sparse_categorical_accuracy: 0.6730 - val_loss: 0.8332 - val_sparse_categorical_accuracy: 0.7074\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16/50\n",
            "196/196 - 7s - loss: 0.9169 - sparse_categorical_accuracy: 0.6743 - val_loss: 0.8481 - val_sparse_categorical_accuracy: 0.7020\n",
            "Epoch 17/50\n",
            "196/196 - 7s - loss: 0.9048 - sparse_categorical_accuracy: 0.6822 - val_loss: 0.8213 - val_sparse_categorical_accuracy: 0.7143\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18/50\n",
            "196/196 - 7s - loss: 0.8840 - sparse_categorical_accuracy: 0.6890 - val_loss: 0.8131 - val_sparse_categorical_accuracy: 0.7141\n",
            "Epoch 19/50\n",
            "196/196 - 7s - loss: 0.8781 - sparse_categorical_accuracy: 0.6902 - val_loss: 0.7978 - val_sparse_categorical_accuracy: 0.7208\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20/50\n",
            "196/196 - 7s - loss: 0.8545 - sparse_categorical_accuracy: 0.6980 - val_loss: 0.8019 - val_sparse_categorical_accuracy: 0.7213\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 21/50\n",
            "196/196 - 7s - loss: 0.8559 - sparse_categorical_accuracy: 0.6987 - val_loss: 0.7873 - val_sparse_categorical_accuracy: 0.7234\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 22/50\n",
            "196/196 - 7s - loss: 0.8388 - sparse_categorical_accuracy: 0.7050 - val_loss: 0.7854 - val_sparse_categorical_accuracy: 0.7277\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 23/50\n",
            "196/196 - 7s - loss: 0.8274 - sparse_categorical_accuracy: 0.7067 - val_loss: 0.7910 - val_sparse_categorical_accuracy: 0.7263\n",
            "Epoch 24/50\n",
            "196/196 - 7s - loss: 0.8177 - sparse_categorical_accuracy: 0.7134 - val_loss: 0.7641 - val_sparse_categorical_accuracy: 0.7308\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 25/50\n",
            "196/196 - 7s - loss: 0.8089 - sparse_categorical_accuracy: 0.7135 - val_loss: 0.7467 - val_sparse_categorical_accuracy: 0.7355\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 26/50\n",
            "196/196 - 7s - loss: 0.8070 - sparse_categorical_accuracy: 0.7163 - val_loss: 0.7810 - val_sparse_categorical_accuracy: 0.7206\n",
            "Epoch 27/50\n",
            "196/196 - 7s - loss: 0.8056 - sparse_categorical_accuracy: 0.7167 - val_loss: 0.7539 - val_sparse_categorical_accuracy: 0.7377\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 28/50\n",
            "196/196 - 7s - loss: 0.7995 - sparse_categorical_accuracy: 0.7185 - val_loss: 0.7306 - val_sparse_categorical_accuracy: 0.7409\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 29/50\n",
            "196/196 - 7s - loss: 0.7801 - sparse_categorical_accuracy: 0.7255 - val_loss: 0.7571 - val_sparse_categorical_accuracy: 0.7431\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 30/50\n",
            "196/196 - 7s - loss: 0.7791 - sparse_categorical_accuracy: 0.7254 - val_loss: 0.7604 - val_sparse_categorical_accuracy: 0.7340\n",
            "Epoch 31/50\n",
            "196/196 - 7s - loss: 0.7786 - sparse_categorical_accuracy: 0.7254 - val_loss: 0.7437 - val_sparse_categorical_accuracy: 0.7417\n",
            "Epoch 32/50\n",
            "196/196 - 7s - loss: 0.7637 - sparse_categorical_accuracy: 0.7289 - val_loss: 0.7120 - val_sparse_categorical_accuracy: 0.7517\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 33/50\n",
            "196/196 - 7s - loss: 0.7600 - sparse_categorical_accuracy: 0.7327 - val_loss: 0.7661 - val_sparse_categorical_accuracy: 0.7325\n",
            "Epoch 34/50\n",
            "196/196 - 7s - loss: 0.7505 - sparse_categorical_accuracy: 0.7355 - val_loss: 0.7533 - val_sparse_categorical_accuracy: 0.7417\n",
            "Epoch 35/50\n",
            "196/196 - 7s - loss: 0.7478 - sparse_categorical_accuracy: 0.7344 - val_loss: 0.7079 - val_sparse_categorical_accuracy: 0.7530\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 36/50\n",
            "196/196 - 7s - loss: 0.7434 - sparse_categorical_accuracy: 0.7353 - val_loss: 0.7292 - val_sparse_categorical_accuracy: 0.7550\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 37/50\n",
            "196/196 - 7s - loss: 0.7386 - sparse_categorical_accuracy: 0.7370 - val_loss: 0.7386 - val_sparse_categorical_accuracy: 0.7525\n",
            "Epoch 38/50\n",
            "196/196 - 7s - loss: 0.7329 - sparse_categorical_accuracy: 0.7424 - val_loss: 0.7145 - val_sparse_categorical_accuracy: 0.7504\n",
            "Epoch 39/50\n",
            "196/196 - 7s - loss: 0.7235 - sparse_categorical_accuracy: 0.7427 - val_loss: 0.7024 - val_sparse_categorical_accuracy: 0.7641\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 40/50\n",
            "196/196 - 7s - loss: 0.7268 - sparse_categorical_accuracy: 0.7422 - val_loss: 0.7190 - val_sparse_categorical_accuracy: 0.7635\n",
            "Epoch 41/50\n",
            "196/196 - 7s - loss: 0.7148 - sparse_categorical_accuracy: 0.7478 - val_loss: 0.7211 - val_sparse_categorical_accuracy: 0.7490\n",
            "Epoch 42/50\n",
            "196/196 - 7s - loss: 0.7149 - sparse_categorical_accuracy: 0.7478 - val_loss: 0.7193 - val_sparse_categorical_accuracy: 0.7565\n",
            "Epoch 43/50\n",
            "196/196 - 7s - loss: 0.7077 - sparse_categorical_accuracy: 0.7478 - val_loss: 0.7010 - val_sparse_categorical_accuracy: 0.7610\n",
            "Epoch 44/50\n",
            "196/196 - 7s - loss: 0.7097 - sparse_categorical_accuracy: 0.7477 - val_loss: 0.7367 - val_sparse_categorical_accuracy: 0.7625\n",
            "Epoch 45/50\n",
            "196/196 - 7s - loss: 0.6955 - sparse_categorical_accuracy: 0.7525 - val_loss: 0.7158 - val_sparse_categorical_accuracy: 0.7566\n",
            "Epoch 46/50\n",
            "196/196 - 7s - loss: 0.6991 - sparse_categorical_accuracy: 0.7525 - val_loss: 0.7006 - val_sparse_categorical_accuracy: 0.7583\n",
            "Epoch 47/50\n",
            "196/196 - 7s - loss: 0.6952 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.6923 - val_sparse_categorical_accuracy: 0.7629\n",
            "Epoch 48/50\n",
            "196/196 - 7s - loss: 0.6892 - sparse_categorical_accuracy: 0.7541 - val_loss: 0.7003 - val_sparse_categorical_accuracy: 0.7655\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_36_layer_call_and_return_conditional_losses, conv2d_36_layer_call_fn, conv2d_37_layer_call_and_return_conditional_losses, conv2d_37_layer_call_fn, conv2d_38_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 49/50\n",
            "196/196 - 7s - loss: 0.6830 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.7408 - val_sparse_categorical_accuracy: 0.7602\n",
            "Epoch 50/50\n",
            "196/196 - 7s - loss: 0.6848 - sparse_categorical_accuracy: 0.7575 - val_loss: 0.6967 - val_sparse_categorical_accuracy: 0.7583\n",
            "Total training time 450.9121718406677 seconds\n",
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        7624      \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        9416      \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,212,474\n",
            "Trainable params: 1,212,474\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 11s - loss: 1.9253 - sparse_categorical_accuracy: 0.2907 - val_loss: 1.6684 - val_sparse_categorical_accuracy: 0.4043\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 9s - loss: 1.5207 - sparse_categorical_accuracy: 0.4481 - val_loss: 1.4589 - val_sparse_categorical_accuracy: 0.4689\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "196/196 - 9s - loss: 1.3669 - sparse_categorical_accuracy: 0.5095 - val_loss: 1.3190 - val_sparse_categorical_accuracy: 0.5348\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 9s - loss: 1.2580 - sparse_categorical_accuracy: 0.5526 - val_loss: 1.2189 - val_sparse_categorical_accuracy: 0.5721\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "196/196 - 9s - loss: 1.1932 - sparse_categorical_accuracy: 0.5774 - val_loss: 1.1889 - val_sparse_categorical_accuracy: 0.5927\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/50\n",
            "196/196 - 9s - loss: 1.1285 - sparse_categorical_accuracy: 0.5973 - val_loss: 1.0732 - val_sparse_categorical_accuracy: 0.6277\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "196/196 - 9s - loss: 1.0856 - sparse_categorical_accuracy: 0.6162 - val_loss: 1.0445 - val_sparse_categorical_accuracy: 0.6411\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/50\n",
            "196/196 - 9s - loss: 1.0536 - sparse_categorical_accuracy: 0.6256 - val_loss: 0.9892 - val_sparse_categorical_accuracy: 0.6501\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/50\n",
            "196/196 - 9s - loss: 1.0100 - sparse_categorical_accuracy: 0.6401 - val_loss: 0.9691 - val_sparse_categorical_accuracy: 0.6567\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/50\n",
            "196/196 - 9s - loss: 0.9942 - sparse_categorical_accuracy: 0.6478 - val_loss: 0.9191 - val_sparse_categorical_accuracy: 0.6806\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/50\n",
            "196/196 - 9s - loss: 0.9715 - sparse_categorical_accuracy: 0.6572 - val_loss: 0.9256 - val_sparse_categorical_accuracy: 0.6725\n",
            "Epoch 12/50\n",
            "196/196 - 9s - loss: 0.9461 - sparse_categorical_accuracy: 0.6646 - val_loss: 0.9368 - val_sparse_categorical_accuracy: 0.6711\n",
            "Epoch 13/50\n",
            "196/196 - 9s - loss: 0.9334 - sparse_categorical_accuracy: 0.6670 - val_loss: 0.8633 - val_sparse_categorical_accuracy: 0.6957\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/50\n",
            "196/196 - 9s - loss: 0.9230 - sparse_categorical_accuracy: 0.6741 - val_loss: 0.8572 - val_sparse_categorical_accuracy: 0.7072\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15/50\n",
            "196/196 - 9s - loss: 0.9065 - sparse_categorical_accuracy: 0.6794 - val_loss: 0.8406 - val_sparse_categorical_accuracy: 0.7069\n",
            "Epoch 16/50\n",
            "196/196 - 9s - loss: 0.8774 - sparse_categorical_accuracy: 0.6896 - val_loss: 0.8799 - val_sparse_categorical_accuracy: 0.6897\n",
            "Epoch 17/50\n",
            "196/196 - 9s - loss: 0.8746 - sparse_categorical_accuracy: 0.6906 - val_loss: 0.8428 - val_sparse_categorical_accuracy: 0.7036\n",
            "Epoch 18/50\n",
            "196/196 - 9s - loss: 0.8593 - sparse_categorical_accuracy: 0.6962 - val_loss: 0.8163 - val_sparse_categorical_accuracy: 0.7108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 19/50\n",
            "196/196 - 9s - loss: 0.8502 - sparse_categorical_accuracy: 0.7005 - val_loss: 0.8323 - val_sparse_categorical_accuracy: 0.7036\n",
            "Epoch 20/50\n",
            "196/196 - 9s - loss: 0.8337 - sparse_categorical_accuracy: 0.7072 - val_loss: 0.8030 - val_sparse_categorical_accuracy: 0.7185\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 21/50\n",
            "196/196 - 9s - loss: 0.8355 - sparse_categorical_accuracy: 0.7045 - val_loss: 0.7837 - val_sparse_categorical_accuracy: 0.7216\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 22/50\n",
            "196/196 - 9s - loss: 0.8109 - sparse_categorical_accuracy: 0.7136 - val_loss: 0.8058 - val_sparse_categorical_accuracy: 0.7185\n",
            "Epoch 23/50\n",
            "196/196 - 9s - loss: 0.8041 - sparse_categorical_accuracy: 0.7143 - val_loss: 0.7552 - val_sparse_categorical_accuracy: 0.7346\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 24/50\n",
            "196/196 - 9s - loss: 0.8025 - sparse_categorical_accuracy: 0.7147 - val_loss: 0.7929 - val_sparse_categorical_accuracy: 0.7255\n",
            "Epoch 25/50\n",
            "196/196 - 9s - loss: 0.7908 - sparse_categorical_accuracy: 0.7212 - val_loss: 0.7811 - val_sparse_categorical_accuracy: 0.7313\n",
            "Epoch 26/50\n",
            "196/196 - 9s - loss: 0.7795 - sparse_categorical_accuracy: 0.7234 - val_loss: 0.7631 - val_sparse_categorical_accuracy: 0.7336\n",
            "Epoch 27/50\n",
            "196/196 - 9s - loss: 0.7782 - sparse_categorical_accuracy: 0.7235 - val_loss: 0.7683 - val_sparse_categorical_accuracy: 0.7297\n",
            "Epoch 28/50\n",
            "196/196 - 9s - loss: 0.7740 - sparse_categorical_accuracy: 0.7282 - val_loss: 0.7633 - val_sparse_categorical_accuracy: 0.7329\n",
            "Epoch 29/50\n",
            "196/196 - 9s - loss: 0.7637 - sparse_categorical_accuracy: 0.7308 - val_loss: 0.7916 - val_sparse_categorical_accuracy: 0.7278\n",
            "Epoch 30/50\n",
            "196/196 - 9s - loss: 0.7619 - sparse_categorical_accuracy: 0.7296 - val_loss: 0.7565 - val_sparse_categorical_accuracy: 0.7358\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 31/50\n",
            "196/196 - 9s - loss: 0.7505 - sparse_categorical_accuracy: 0.7345 - val_loss: 0.7717 - val_sparse_categorical_accuracy: 0.7320\n",
            "Epoch 32/50\n",
            "196/196 - 9s - loss: 0.7472 - sparse_categorical_accuracy: 0.7356 - val_loss: 0.7246 - val_sparse_categorical_accuracy: 0.7461\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 33/50\n",
            "196/196 - 9s - loss: 0.7365 - sparse_categorical_accuracy: 0.7380 - val_loss: 0.7464 - val_sparse_categorical_accuracy: 0.7421\n",
            "Epoch 34/50\n",
            "196/196 - 9s - loss: 0.7361 - sparse_categorical_accuracy: 0.7403 - val_loss: 0.7758 - val_sparse_categorical_accuracy: 0.7325\n",
            "Epoch 35/50\n",
            "196/196 - 9s - loss: 0.7354 - sparse_categorical_accuracy: 0.7427 - val_loss: 0.7158 - val_sparse_categorical_accuracy: 0.7475\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 36/50\n",
            "196/196 - 9s - loss: 0.7231 - sparse_categorical_accuracy: 0.7450 - val_loss: 0.7369 - val_sparse_categorical_accuracy: 0.7427\n",
            "Epoch 37/50\n",
            "196/196 - 9s - loss: 0.7133 - sparse_categorical_accuracy: 0.7469 - val_loss: 0.7238 - val_sparse_categorical_accuracy: 0.7424\n",
            "Epoch 38/50\n",
            "196/196 - 9s - loss: 0.7200 - sparse_categorical_accuracy: 0.7451 - val_loss: 0.7336 - val_sparse_categorical_accuracy: 0.7476\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 39/50\n",
            "196/196 - 9s - loss: 0.7141 - sparse_categorical_accuracy: 0.7471 - val_loss: 0.7437 - val_sparse_categorical_accuracy: 0.7482\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 40/50\n",
            "196/196 - 9s - loss: 0.7084 - sparse_categorical_accuracy: 0.7499 - val_loss: 0.7172 - val_sparse_categorical_accuracy: 0.7506\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 41/50\n",
            "196/196 - 9s - loss: 0.7031 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.7407 - val_sparse_categorical_accuracy: 0.7479\n",
            "Epoch 42/50\n",
            "196/196 - 9s - loss: 0.6949 - sparse_categorical_accuracy: 0.7536 - val_loss: 0.7934 - val_sparse_categorical_accuracy: 0.7347\n",
            "Epoch 43/50\n",
            "196/196 - 9s - loss: 0.6926 - sparse_categorical_accuracy: 0.7549 - val_loss: 0.7160 - val_sparse_categorical_accuracy: 0.7582\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 44/50\n",
            "196/196 - 9s - loss: 0.6851 - sparse_categorical_accuracy: 0.7562 - val_loss: 0.6878 - val_sparse_categorical_accuracy: 0.7589\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 45/50\n",
            "196/196 - 9s - loss: 0.6893 - sparse_categorical_accuracy: 0.7573 - val_loss: 0.7631 - val_sparse_categorical_accuracy: 0.7466\n",
            "Epoch 46/50\n",
            "196/196 - 9s - loss: 0.6803 - sparse_categorical_accuracy: 0.7582 - val_loss: 0.7311 - val_sparse_categorical_accuracy: 0.7504\n",
            "Epoch 47/50\n",
            "196/196 - 9s - loss: 0.6805 - sparse_categorical_accuracy: 0.7577 - val_loss: 0.6974 - val_sparse_categorical_accuracy: 0.7586\n",
            "Epoch 48/50\n",
            "196/196 - 9s - loss: 0.6666 - sparse_categorical_accuracy: 0.7626 - val_loss: 0.7518 - val_sparse_categorical_accuracy: 0.7476\n",
            "Epoch 49/50\n",
            "196/196 - 9s - loss: 0.6680 - sparse_categorical_accuracy: 0.7616 - val_loss: 0.7161 - val_sparse_categorical_accuracy: 0.7509\n",
            "Epoch 50/50\n",
            "196/196 - 9s - loss: 0.6619 - sparse_categorical_accuracy: 0.7632 - val_loss: 0.6907 - val_sparse_categorical_accuracy: 0.7627\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_42_layer_call_and_return_conditional_losses, conv2d_42_layer_call_fn, conv2d_43_layer_call_and_return_conditional_losses, conv2d_43_layer_call_fn, conv2d_44_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total training time 524.1374092102051 seconds\n",
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        1401      \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        2073      \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,198,908\n",
            "Trainable params: 1,198,908\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 8s - loss: 2.0262 - sparse_categorical_accuracy: 0.2543 - val_loss: 1.7260 - val_sparse_categorical_accuracy: 0.3665\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 5s - loss: 1.5975 - sparse_categorical_accuracy: 0.4213 - val_loss: 1.4222 - val_sparse_categorical_accuracy: 0.4762\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "196/196 - 5s - loss: 1.4088 - sparse_categorical_accuracy: 0.4937 - val_loss: 1.2864 - val_sparse_categorical_accuracy: 0.5226\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 5s - loss: 1.3116 - sparse_categorical_accuracy: 0.5307 - val_loss: 1.1938 - val_sparse_categorical_accuracy: 0.5722\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "196/196 - 5s - loss: 1.2253 - sparse_categorical_accuracy: 0.5641 - val_loss: 1.1722 - val_sparse_categorical_accuracy: 0.5751\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/50\n",
            "196/196 - 5s - loss: 1.1692 - sparse_categorical_accuracy: 0.5828 - val_loss: 1.1277 - val_sparse_categorical_accuracy: 0.5993\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "196/196 - 5s - loss: 1.1313 - sparse_categorical_accuracy: 0.6003 - val_loss: 1.2320 - val_sparse_categorical_accuracy: 0.5730\n",
            "Epoch 8/50\n",
            "196/196 - 5s - loss: 1.0960 - sparse_categorical_accuracy: 0.6118 - val_loss: 0.9998 - val_sparse_categorical_accuracy: 0.6471\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/50\n",
            "196/196 - 5s - loss: 1.0673 - sparse_categorical_accuracy: 0.6234 - val_loss: 0.9745 - val_sparse_categorical_accuracy: 0.6624\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/50\n",
            "196/196 - 5s - loss: 1.0418 - sparse_categorical_accuracy: 0.6324 - val_loss: 1.0310 - val_sparse_categorical_accuracy: 0.6339\n",
            "Epoch 11/50\n",
            "196/196 - 5s - loss: 1.0092 - sparse_categorical_accuracy: 0.6415 - val_loss: 0.9685 - val_sparse_categorical_accuracy: 0.6588\n",
            "Epoch 12/50\n",
            "196/196 - 5s - loss: 0.9899 - sparse_categorical_accuracy: 0.6481 - val_loss: 0.9396 - val_sparse_categorical_accuracy: 0.6703\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13/50\n",
            "196/196 - 5s - loss: 0.9686 - sparse_categorical_accuracy: 0.6583 - val_loss: 0.9617 - val_sparse_categorical_accuracy: 0.6580\n",
            "Epoch 14/50\n",
            "196/196 - 5s - loss: 0.9515 - sparse_categorical_accuracy: 0.6630 - val_loss: 0.8802 - val_sparse_categorical_accuracy: 0.6892\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15/50\n",
            "196/196 - 5s - loss: 0.9357 - sparse_categorical_accuracy: 0.6690 - val_loss: 0.8907 - val_sparse_categorical_accuracy: 0.6883\n",
            "Epoch 16/50\n",
            "196/196 - 5s - loss: 0.9266 - sparse_categorical_accuracy: 0.6725 - val_loss: 0.9272 - val_sparse_categorical_accuracy: 0.6733\n",
            "Epoch 17/50\n",
            "196/196 - 5s - loss: 0.9042 - sparse_categorical_accuracy: 0.6811 - val_loss: 0.8962 - val_sparse_categorical_accuracy: 0.6870\n",
            "Epoch 18/50\n",
            "196/196 - 5s - loss: 0.8924 - sparse_categorical_accuracy: 0.6835 - val_loss: 0.8590 - val_sparse_categorical_accuracy: 0.6986\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 19/50\n",
            "196/196 - 5s - loss: 0.8808 - sparse_categorical_accuracy: 0.6878 - val_loss: 0.8548 - val_sparse_categorical_accuracy: 0.7002\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20/50\n",
            "196/196 - 5s - loss: 0.8695 - sparse_categorical_accuracy: 0.6938 - val_loss: 0.8294 - val_sparse_categorical_accuracy: 0.7129\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 21/50\n",
            "196/196 - 5s - loss: 0.8478 - sparse_categorical_accuracy: 0.7001 - val_loss: 0.8152 - val_sparse_categorical_accuracy: 0.7161\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 22/50\n",
            "196/196 - 5s - loss: 0.8458 - sparse_categorical_accuracy: 0.7027 - val_loss: 0.8215 - val_sparse_categorical_accuracy: 0.7152\n",
            "Epoch 23/50\n",
            "196/196 - 5s - loss: 0.8348 - sparse_categorical_accuracy: 0.7062 - val_loss: 0.8123 - val_sparse_categorical_accuracy: 0.7172\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 24/50\n",
            "196/196 - 5s - loss: 0.8203 - sparse_categorical_accuracy: 0.7086 - val_loss: 0.8377 - val_sparse_categorical_accuracy: 0.7098\n",
            "Epoch 25/50\n",
            "196/196 - 5s - loss: 0.8158 - sparse_categorical_accuracy: 0.7115 - val_loss: 0.8341 - val_sparse_categorical_accuracy: 0.7077\n",
            "Epoch 26/50\n",
            "196/196 - 5s - loss: 0.8008 - sparse_categorical_accuracy: 0.7155 - val_loss: 0.7830 - val_sparse_categorical_accuracy: 0.7234\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 27/50\n",
            "196/196 - 5s - loss: 0.7963 - sparse_categorical_accuracy: 0.7172 - val_loss: 0.7866 - val_sparse_categorical_accuracy: 0.7223\n",
            "Epoch 28/50\n",
            "196/196 - 5s - loss: 0.7862 - sparse_categorical_accuracy: 0.7230 - val_loss: 0.7838 - val_sparse_categorical_accuracy: 0.7280\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 29/50\n",
            "196/196 - 5s - loss: 0.7843 - sparse_categorical_accuracy: 0.7231 - val_loss: 0.7688 - val_sparse_categorical_accuracy: 0.7328\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 30/50\n",
            "196/196 - 5s - loss: 0.7678 - sparse_categorical_accuracy: 0.7285 - val_loss: 0.7675 - val_sparse_categorical_accuracy: 0.7341\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 31/50\n",
            "196/196 - 5s - loss: 0.7664 - sparse_categorical_accuracy: 0.7292 - val_loss: 0.7512 - val_sparse_categorical_accuracy: 0.7376\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 32/50\n",
            "196/196 - 5s - loss: 0.7630 - sparse_categorical_accuracy: 0.7298 - val_loss: 0.7871 - val_sparse_categorical_accuracy: 0.7356\n",
            "Epoch 33/50\n",
            "196/196 - 5s - loss: 0.7488 - sparse_categorical_accuracy: 0.7328 - val_loss: 0.7637 - val_sparse_categorical_accuracy: 0.7404\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 34/50\n",
            "196/196 - 5s - loss: 0.7527 - sparse_categorical_accuracy: 0.7338 - val_loss: 0.8107 - val_sparse_categorical_accuracy: 0.7237\n",
            "Epoch 35/50\n",
            "196/196 - 5s - loss: 0.7388 - sparse_categorical_accuracy: 0.7384 - val_loss: 0.7483 - val_sparse_categorical_accuracy: 0.7447\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 36/50\n",
            "196/196 - 5s - loss: 0.7296 - sparse_categorical_accuracy: 0.7417 - val_loss: 0.7334 - val_sparse_categorical_accuracy: 0.7474\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 37/50\n",
            "196/196 - 5s - loss: 0.7294 - sparse_categorical_accuracy: 0.7408 - val_loss: 0.7782 - val_sparse_categorical_accuracy: 0.7372\n",
            "Epoch 38/50\n",
            "196/196 - 5s - loss: 0.7166 - sparse_categorical_accuracy: 0.7469 - val_loss: 0.7493 - val_sparse_categorical_accuracy: 0.7425\n",
            "Epoch 39/50\n",
            "196/196 - 5s - loss: 0.7146 - sparse_categorical_accuracy: 0.7444 - val_loss: 0.7412 - val_sparse_categorical_accuracy: 0.7485\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 40/50\n",
            "196/196 - 5s - loss: 0.7078 - sparse_categorical_accuracy: 0.7479 - val_loss: 0.7856 - val_sparse_categorical_accuracy: 0.7364\n",
            "Epoch 41/50\n",
            "196/196 - 5s - loss: 0.7041 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.7410 - val_sparse_categorical_accuracy: 0.7487\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 42/50\n",
            "196/196 - 5s - loss: 0.6986 - sparse_categorical_accuracy: 0.7513 - val_loss: 0.7281 - val_sparse_categorical_accuracy: 0.7470\n",
            "Epoch 43/50\n",
            "196/196 - 5s - loss: 0.6929 - sparse_categorical_accuracy: 0.7548 - val_loss: 0.7322 - val_sparse_categorical_accuracy: 0.7471\n",
            "Epoch 44/50\n",
            "196/196 - 5s - loss: 0.6860 - sparse_categorical_accuracy: 0.7558 - val_loss: 0.7225 - val_sparse_categorical_accuracy: 0.7529\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 45/50\n",
            "196/196 - 5s - loss: 0.6840 - sparse_categorical_accuracy: 0.7566 - val_loss: 0.7174 - val_sparse_categorical_accuracy: 0.7566\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 46/50\n",
            "196/196 - 5s - loss: 0.6742 - sparse_categorical_accuracy: 0.7613 - val_loss: 0.7262 - val_sparse_categorical_accuracy: 0.7572\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 47/50\n",
            "196/196 - 5s - loss: 0.6740 - sparse_categorical_accuracy: 0.7606 - val_loss: 0.7174 - val_sparse_categorical_accuracy: 0.7556\n",
            "Epoch 48/50\n",
            "196/196 - 5s - loss: 0.6740 - sparse_categorical_accuracy: 0.7602 - val_loss: 0.7053 - val_sparse_categorical_accuracy: 0.7619\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_48_layer_call_and_return_conditional_losses, conv2d_48_layer_call_fn, conv2d_49_layer_call_and_return_conditional_losses, conv2d_49_layer_call_fn, conv2d_50_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 49/50\n",
            "196/196 - 5s - loss: 0.6742 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.7325 - val_sparse_categorical_accuracy: 0.7540\n",
            "Epoch 50/50\n",
            "196/196 - 5s - loss: 0.6655 - sparse_categorical_accuracy: 0.7607 - val_loss: 0.7349 - val_sparse_categorical_accuracy: 0.7583\n",
            "Total training time 319.4093186855316 seconds\n",
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        2290      \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        3122      \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,200,846\n",
            "Trainable params: 1,200,846\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 8s - loss: 1.9556 - sparse_categorical_accuracy: 0.2795 - val_loss: 1.8536 - val_sparse_categorical_accuracy: 0.3249\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 6s - loss: 1.5622 - sparse_categorical_accuracy: 0.4346 - val_loss: 1.6204 - val_sparse_categorical_accuracy: 0.4145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "196/196 - 6s - loss: 1.4114 - sparse_categorical_accuracy: 0.4916 - val_loss: 1.4651 - val_sparse_categorical_accuracy: 0.4727\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 6s - loss: 1.3297 - sparse_categorical_accuracy: 0.5228 - val_loss: 1.5072 - val_sparse_categorical_accuracy: 0.4866\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "196/196 - 6s - loss: 1.2490 - sparse_categorical_accuracy: 0.5546 - val_loss: 1.4935 - val_sparse_categorical_accuracy: 0.4902\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/50\n",
            "196/196 - 6s - loss: 1.1968 - sparse_categorical_accuracy: 0.5731 - val_loss: 1.4489 - val_sparse_categorical_accuracy: 0.5060\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "196/196 - 6s - loss: 1.1444 - sparse_categorical_accuracy: 0.5904 - val_loss: 1.3446 - val_sparse_categorical_accuracy: 0.5424\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/50\n",
            "196/196 - 6s - loss: 1.1161 - sparse_categorical_accuracy: 0.6042 - val_loss: 1.2627 - val_sparse_categorical_accuracy: 0.5647\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/50\n",
            "196/196 - 6s - loss: 1.0797 - sparse_categorical_accuracy: 0.6153 - val_loss: 1.1122 - val_sparse_categorical_accuracy: 0.6105\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/50\n",
            "196/196 - 6s - loss: 1.0414 - sparse_categorical_accuracy: 0.6301 - val_loss: 1.1800 - val_sparse_categorical_accuracy: 0.5924\n",
            "Epoch 11/50\n",
            "196/196 - 6s - loss: 1.0311 - sparse_categorical_accuracy: 0.6328 - val_loss: 1.2421 - val_sparse_categorical_accuracy: 0.5925\n",
            "Epoch 12/50\n",
            "196/196 - 6s - loss: 1.0117 - sparse_categorical_accuracy: 0.6412 - val_loss: 1.0211 - val_sparse_categorical_accuracy: 0.6490\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13/50\n",
            "196/196 - 6s - loss: 0.9860 - sparse_categorical_accuracy: 0.6497 - val_loss: 1.0310 - val_sparse_categorical_accuracy: 0.6422\n",
            "Epoch 14/50\n",
            "196/196 - 6s - loss: 0.9620 - sparse_categorical_accuracy: 0.6594 - val_loss: 1.0611 - val_sparse_categorical_accuracy: 0.6271\n",
            "Epoch 15/50\n",
            "196/196 - 6s - loss: 0.9466 - sparse_categorical_accuracy: 0.6625 - val_loss: 1.0184 - val_sparse_categorical_accuracy: 0.6555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16/50\n",
            "196/196 - 6s - loss: 0.9285 - sparse_categorical_accuracy: 0.6737 - val_loss: 1.0043 - val_sparse_categorical_accuracy: 0.6500\n",
            "Epoch 17/50\n",
            "196/196 - 6s - loss: 0.9223 - sparse_categorical_accuracy: 0.6719 - val_loss: 1.0913 - val_sparse_categorical_accuracy: 0.6327\n",
            "Epoch 18/50\n",
            "196/196 - 6s - loss: 0.9041 - sparse_categorical_accuracy: 0.6767 - val_loss: 1.0145 - val_sparse_categorical_accuracy: 0.6600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 19/50\n",
            "196/196 - 6s - loss: 0.8990 - sparse_categorical_accuracy: 0.6828 - val_loss: 0.9308 - val_sparse_categorical_accuracy: 0.6784\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20/50\n",
            "196/196 - 6s - loss: 0.8799 - sparse_categorical_accuracy: 0.6868 - val_loss: 1.0229 - val_sparse_categorical_accuracy: 0.6612\n",
            "Epoch 21/50\n",
            "196/196 - 6s - loss: 0.8666 - sparse_categorical_accuracy: 0.6886 - val_loss: 0.9309 - val_sparse_categorical_accuracy: 0.6806\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 22/50\n",
            "196/196 - 6s - loss: 0.8627 - sparse_categorical_accuracy: 0.6962 - val_loss: 1.0257 - val_sparse_categorical_accuracy: 0.6558\n",
            "Epoch 23/50\n",
            "196/196 - 6s - loss: 0.8505 - sparse_categorical_accuracy: 0.6995 - val_loss: 0.9787 - val_sparse_categorical_accuracy: 0.6696\n",
            "Epoch 24/50\n",
            "196/196 - 6s - loss: 0.8481 - sparse_categorical_accuracy: 0.6979 - val_loss: 0.9601 - val_sparse_categorical_accuracy: 0.6780\n",
            "Epoch 25/50\n",
            "196/196 - 6s - loss: 0.8301 - sparse_categorical_accuracy: 0.7036 - val_loss: 0.9838 - val_sparse_categorical_accuracy: 0.6831\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 26/50\n",
            "196/196 - 6s - loss: 0.8235 - sparse_categorical_accuracy: 0.7081 - val_loss: 0.9190 - val_sparse_categorical_accuracy: 0.6908\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 27/50\n",
            "196/196 - 6s - loss: 0.8117 - sparse_categorical_accuracy: 0.7108 - val_loss: 0.9208 - val_sparse_categorical_accuracy: 0.6874\n",
            "Epoch 28/50\n",
            "196/196 - 6s - loss: 0.8110 - sparse_categorical_accuracy: 0.7132 - val_loss: 0.9045 - val_sparse_categorical_accuracy: 0.6933\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 29/50\n",
            "196/196 - 6s - loss: 0.8024 - sparse_categorical_accuracy: 0.7161 - val_loss: 0.8155 - val_sparse_categorical_accuracy: 0.7220\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 30/50\n",
            "196/196 - 6s - loss: 0.7911 - sparse_categorical_accuracy: 0.7171 - val_loss: 0.9856 - val_sparse_categorical_accuracy: 0.6934\n",
            "Epoch 31/50\n",
            "196/196 - 6s - loss: 0.7914 - sparse_categorical_accuracy: 0.7176 - val_loss: 0.8060 - val_sparse_categorical_accuracy: 0.7246\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 32/50\n",
            "196/196 - 6s - loss: 0.7796 - sparse_categorical_accuracy: 0.7233 - val_loss: 0.8838 - val_sparse_categorical_accuracy: 0.6952\n",
            "Epoch 33/50\n",
            "196/196 - 6s - loss: 0.7708 - sparse_categorical_accuracy: 0.7279 - val_loss: 0.8558 - val_sparse_categorical_accuracy: 0.7093\n",
            "Epoch 34/50\n",
            "196/196 - 6s - loss: 0.7682 - sparse_categorical_accuracy: 0.7255 - val_loss: 0.8285 - val_sparse_categorical_accuracy: 0.7239\n",
            "Epoch 35/50\n",
            "196/196 - 6s - loss: 0.7610 - sparse_categorical_accuracy: 0.7281 - val_loss: 0.9126 - val_sparse_categorical_accuracy: 0.7053\n",
            "Epoch 36/50\n",
            "196/196 - 6s - loss: 0.7500 - sparse_categorical_accuracy: 0.7339 - val_loss: 0.8210 - val_sparse_categorical_accuracy: 0.7271\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 37/50\n",
            "196/196 - 6s - loss: 0.7441 - sparse_categorical_accuracy: 0.7366 - val_loss: 0.8713 - val_sparse_categorical_accuracy: 0.7165\n",
            "Epoch 38/50\n",
            "196/196 - 6s - loss: 0.7469 - sparse_categorical_accuracy: 0.7348 - val_loss: 0.8634 - val_sparse_categorical_accuracy: 0.7168\n",
            "Epoch 39/50\n",
            "196/196 - 6s - loss: 0.7349 - sparse_categorical_accuracy: 0.7402 - val_loss: 0.8125 - val_sparse_categorical_accuracy: 0.7276\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 40/50\n",
            "196/196 - 6s - loss: 0.7373 - sparse_categorical_accuracy: 0.7387 - val_loss: 0.8753 - val_sparse_categorical_accuracy: 0.7191\n",
            "Epoch 41/50\n",
            "196/196 - 6s - loss: 0.7299 - sparse_categorical_accuracy: 0.7410 - val_loss: 0.8009 - val_sparse_categorical_accuracy: 0.7296\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 42/50\n",
            "196/196 - 6s - loss: 0.7177 - sparse_categorical_accuracy: 0.7444 - val_loss: 0.8949 - val_sparse_categorical_accuracy: 0.7031\n",
            "Epoch 43/50\n",
            "196/196 - 6s - loss: 0.7165 - sparse_categorical_accuracy: 0.7440 - val_loss: 0.7805 - val_sparse_categorical_accuracy: 0.7371\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 44/50\n",
            "196/196 - 6s - loss: 0.7131 - sparse_categorical_accuracy: 0.7463 - val_loss: 0.7597 - val_sparse_categorical_accuracy: 0.7380\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 45/50\n",
            "196/196 - 6s - loss: 0.7080 - sparse_categorical_accuracy: 0.7468 - val_loss: 0.8182 - val_sparse_categorical_accuracy: 0.7422\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 46/50\n",
            "196/196 - 6s - loss: 0.7043 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.8603 - val_sparse_categorical_accuracy: 0.7314\n",
            "Epoch 47/50\n",
            "196/196 - 6s - loss: 0.6915 - sparse_categorical_accuracy: 0.7536 - val_loss: 0.7807 - val_sparse_categorical_accuracy: 0.7387\n",
            "Epoch 48/50\n",
            "196/196 - 6s - loss: 0.7023 - sparse_categorical_accuracy: 0.7478 - val_loss: 0.7744 - val_sparse_categorical_accuracy: 0.7398\n",
            "Epoch 49/50\n",
            "196/196 - 6s - loss: 0.6851 - sparse_categorical_accuracy: 0.7575 - val_loss: 0.7850 - val_sparse_categorical_accuracy: 0.7411\n",
            "Epoch 50/50\n",
            "196/196 - 6s - loss: 0.6849 - sparse_categorical_accuracy: 0.7558 - val_loss: 0.7627 - val_sparse_categorical_accuracy: 0.7459\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_54_layer_call_and_return_conditional_losses, conv2d_54_layer_call_fn, conv2d_55_layer_call_and_return_conditional_losses, conv2d_55_layer_call_fn, conv2d_56_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total training time 383.4678649902344 seconds\n",
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_11 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        4068      \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        5220      \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,204,722\n",
            "Trainable params: 1,204,722\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 9s - loss: 1.9623 - sparse_categorical_accuracy: 0.2756 - val_loss: 1.8371 - val_sparse_categorical_accuracy: 0.3333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 7s - loss: 1.6099 - sparse_categorical_accuracy: 0.4170 - val_loss: 1.9565 - val_sparse_categorical_accuracy: 0.2892\n",
            "Epoch 3/50\n",
            "196/196 - 7s - loss: 1.4504 - sparse_categorical_accuracy: 0.4757 - val_loss: 1.6502 - val_sparse_categorical_accuracy: 0.3983\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 7s - loss: 1.3350 - sparse_categorical_accuracy: 0.5218 - val_loss: 1.4074 - val_sparse_categorical_accuracy: 0.4871\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "196/196 - 7s - loss: 1.2593 - sparse_categorical_accuracy: 0.5525 - val_loss: 1.7325 - val_sparse_categorical_accuracy: 0.4565\n",
            "Epoch 6/50\n",
            "196/196 - 7s - loss: 1.1865 - sparse_categorical_accuracy: 0.5751 - val_loss: 1.3340 - val_sparse_categorical_accuracy: 0.5342\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "196/196 - 7s - loss: 1.1482 - sparse_categorical_accuracy: 0.5913 - val_loss: 1.4069 - val_sparse_categorical_accuracy: 0.5331\n",
            "Epoch 8/50\n",
            "196/196 - 7s - loss: 1.1040 - sparse_categorical_accuracy: 0.6100 - val_loss: 1.4089 - val_sparse_categorical_accuracy: 0.5577\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/50\n",
            "196/196 - 7s - loss: 1.0682 - sparse_categorical_accuracy: 0.6220 - val_loss: 1.2476 - val_sparse_categorical_accuracy: 0.5737\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/50\n",
            "196/196 - 7s - loss: 1.0474 - sparse_categorical_accuracy: 0.6273 - val_loss: 1.1512 - val_sparse_categorical_accuracy: 0.6066\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/50\n",
            "196/196 - 7s - loss: 1.0215 - sparse_categorical_accuracy: 0.6400 - val_loss: 1.1216 - val_sparse_categorical_accuracy: 0.6202\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/50\n",
            "196/196 - 7s - loss: 0.9977 - sparse_categorical_accuracy: 0.6450 - val_loss: 1.0821 - val_sparse_categorical_accuracy: 0.6275\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13/50\n",
            "196/196 - 7s - loss: 0.9819 - sparse_categorical_accuracy: 0.6527 - val_loss: 1.0559 - val_sparse_categorical_accuracy: 0.6331\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/50\n",
            "196/196 - 7s - loss: 0.9624 - sparse_categorical_accuracy: 0.6616 - val_loss: 1.0287 - val_sparse_categorical_accuracy: 0.6474\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15/50\n",
            "196/196 - 7s - loss: 0.9349 - sparse_categorical_accuracy: 0.6700 - val_loss: 1.1134 - val_sparse_categorical_accuracy: 0.6253\n",
            "Epoch 16/50\n",
            "196/196 - 7s - loss: 0.9254 - sparse_categorical_accuracy: 0.6740 - val_loss: 0.9992 - val_sparse_categorical_accuracy: 0.6586\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 17/50\n",
            "196/196 - 7s - loss: 0.9120 - sparse_categorical_accuracy: 0.6780 - val_loss: 0.9461 - val_sparse_categorical_accuracy: 0.6695\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18/50\n",
            "196/196 - 7s - loss: 0.8979 - sparse_categorical_accuracy: 0.6836 - val_loss: 1.0025 - val_sparse_categorical_accuracy: 0.6707\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 19/50\n",
            "196/196 - 7s - loss: 0.8846 - sparse_categorical_accuracy: 0.6850 - val_loss: 0.9537 - val_sparse_categorical_accuracy: 0.6789\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20/50\n",
            "196/196 - 7s - loss: 0.8678 - sparse_categorical_accuracy: 0.6924 - val_loss: 0.9246 - val_sparse_categorical_accuracy: 0.6855\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 21/50\n",
            "196/196 - 7s - loss: 0.8610 - sparse_categorical_accuracy: 0.6963 - val_loss: 0.9451 - val_sparse_categorical_accuracy: 0.6850\n",
            "Epoch 22/50\n",
            "196/196 - 7s - loss: 0.8553 - sparse_categorical_accuracy: 0.6959 - val_loss: 0.9342 - val_sparse_categorical_accuracy: 0.6923\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 23/50\n",
            "196/196 - 7s - loss: 0.8387 - sparse_categorical_accuracy: 0.7042 - val_loss: 0.9629 - val_sparse_categorical_accuracy: 0.6759\n",
            "Epoch 24/50\n",
            "196/196 - 7s - loss: 0.8189 - sparse_categorical_accuracy: 0.7107 - val_loss: 0.9564 - val_sparse_categorical_accuracy: 0.6846\n",
            "Epoch 25/50\n",
            "196/196 - 7s - loss: 0.8168 - sparse_categorical_accuracy: 0.7114 - val_loss: 0.9998 - val_sparse_categorical_accuracy: 0.6816\n",
            "Epoch 26/50\n",
            "196/196 - 7s - loss: 0.8083 - sparse_categorical_accuracy: 0.7159 - val_loss: 0.8898 - val_sparse_categorical_accuracy: 0.6991\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 27/50\n",
            "196/196 - 7s - loss: 0.8052 - sparse_categorical_accuracy: 0.7148 - val_loss: 0.8774 - val_sparse_categorical_accuracy: 0.7013\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 28/50\n",
            "196/196 - 7s - loss: 0.7893 - sparse_categorical_accuracy: 0.7193 - val_loss: 0.8700 - val_sparse_categorical_accuracy: 0.7167\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 29/50\n",
            "196/196 - 7s - loss: 0.7845 - sparse_categorical_accuracy: 0.7225 - val_loss: 0.8867 - val_sparse_categorical_accuracy: 0.7158\n",
            "Epoch 30/50\n",
            "196/196 - 7s - loss: 0.7714 - sparse_categorical_accuracy: 0.7271 - val_loss: 0.9296 - val_sparse_categorical_accuracy: 0.7042\n",
            "Epoch 31/50\n",
            "196/196 - 7s - loss: 0.7663 - sparse_categorical_accuracy: 0.7283 - val_loss: 0.8401 - val_sparse_categorical_accuracy: 0.7175\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 32/50\n",
            "196/196 - 7s - loss: 0.7596 - sparse_categorical_accuracy: 0.7316 - val_loss: 0.8293 - val_sparse_categorical_accuracy: 0.7184\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 33/50\n",
            "196/196 - 7s - loss: 0.7591 - sparse_categorical_accuracy: 0.7315 - val_loss: 0.8990 - val_sparse_categorical_accuracy: 0.7065\n",
            "Epoch 34/50\n",
            "196/196 - 7s - loss: 0.7549 - sparse_categorical_accuracy: 0.7336 - val_loss: 0.8682 - val_sparse_categorical_accuracy: 0.7141\n",
            "Epoch 35/50\n",
            "196/196 - 7s - loss: 0.7388 - sparse_categorical_accuracy: 0.7367 - val_loss: 0.9560 - val_sparse_categorical_accuracy: 0.6954\n",
            "Epoch 36/50\n",
            "196/196 - 7s - loss: 0.7305 - sparse_categorical_accuracy: 0.7411 - val_loss: 1.0233 - val_sparse_categorical_accuracy: 0.6907\n",
            "Epoch 37/50\n",
            "196/196 - 7s - loss: 0.7321 - sparse_categorical_accuracy: 0.7421 - val_loss: 0.9018 - val_sparse_categorical_accuracy: 0.7195\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 38/50\n",
            "196/196 - 7s - loss: 0.7234 - sparse_categorical_accuracy: 0.7450 - val_loss: 0.8473 - val_sparse_categorical_accuracy: 0.7189\n",
            "Epoch 39/50\n",
            "196/196 - 7s - loss: 0.7195 - sparse_categorical_accuracy: 0.7461 - val_loss: 0.7985 - val_sparse_categorical_accuracy: 0.7336\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 40/50\n",
            "196/196 - 7s - loss: 0.7076 - sparse_categorical_accuracy: 0.7494 - val_loss: 1.1507 - val_sparse_categorical_accuracy: 0.7007\n",
            "Epoch 41/50\n",
            "196/196 - 7s - loss: 0.7052 - sparse_categorical_accuracy: 0.7496 - val_loss: 0.8907 - val_sparse_categorical_accuracy: 0.7258\n",
            "Epoch 42/50\n",
            "196/196 - 7s - loss: 0.6982 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.9135 - val_sparse_categorical_accuracy: 0.7297\n",
            "Epoch 43/50\n",
            "196/196 - 7s - loss: 0.6922 - sparse_categorical_accuracy: 0.7533 - val_loss: 0.9639 - val_sparse_categorical_accuracy: 0.7334\n",
            "Epoch 44/50\n",
            "196/196 - 7s - loss: 0.6912 - sparse_categorical_accuracy: 0.7544 - val_loss: 0.8788 - val_sparse_categorical_accuracy: 0.7370\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 45/50\n",
            "196/196 - 7s - loss: 0.6874 - sparse_categorical_accuracy: 0.7556 - val_loss: 0.8393 - val_sparse_categorical_accuracy: 0.7294\n",
            "Epoch 46/50\n",
            "196/196 - 7s - loss: 0.6826 - sparse_categorical_accuracy: 0.7567 - val_loss: 0.8095 - val_sparse_categorical_accuracy: 0.7405\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 47/50\n",
            "196/196 - 7s - loss: 0.6815 - sparse_categorical_accuracy: 0.7590 - val_loss: 0.8497 - val_sparse_categorical_accuracy: 0.7418\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 48/50\n",
            "196/196 - 7s - loss: 0.6721 - sparse_categorical_accuracy: 0.7604 - val_loss: 0.8926 - val_sparse_categorical_accuracy: 0.7415\n",
            "Epoch 49/50\n",
            "196/196 - 7s - loss: 0.6759 - sparse_categorical_accuracy: 0.7627 - val_loss: 0.7780 - val_sparse_categorical_accuracy: 0.7476\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_60_layer_call_and_return_conditional_losses, conv2d_60_layer_call_fn, conv2d_61_layer_call_and_return_conditional_losses, conv2d_61_layer_call_fn, conv2d_62_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 50/50\n",
            "196/196 - 7s - loss: 0.6670 - sparse_categorical_accuracy: 0.7631 - val_loss: 0.8360 - val_sparse_categorical_accuracy: 0.7418\n",
            "Total training time 418.73418283462524 seconds\n",
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        7624      \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        9416      \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,212,474\n",
            "Trainable params: 1,212,474\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 10s - loss: 2.0175 - sparse_categorical_accuracy: 0.2534 - val_loss: 1.7068 - val_sparse_categorical_accuracy: 0.3751\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 8s - loss: 1.5782 - sparse_categorical_accuracy: 0.4311 - val_loss: 1.4998 - val_sparse_categorical_accuracy: 0.4723\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "196/196 - 8s - loss: 1.3834 - sparse_categorical_accuracy: 0.5067 - val_loss: 1.2865 - val_sparse_categorical_accuracy: 0.5360\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 8s - loss: 1.2593 - sparse_categorical_accuracy: 0.5528 - val_loss: 1.2195 - val_sparse_categorical_accuracy: 0.5697\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "196/196 - 8s - loss: 1.1997 - sparse_categorical_accuracy: 0.5748 - val_loss: 1.1822 - val_sparse_categorical_accuracy: 0.5915\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/50\n",
            "196/196 - 8s - loss: 1.1335 - sparse_categorical_accuracy: 0.6006 - val_loss: 1.0321 - val_sparse_categorical_accuracy: 0.6330\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "196/196 - 8s - loss: 1.0878 - sparse_categorical_accuracy: 0.6145 - val_loss: 1.0628 - val_sparse_categorical_accuracy: 0.6222\n",
            "Epoch 8/50\n",
            "196/196 - 8s - loss: 1.0508 - sparse_categorical_accuracy: 0.6258 - val_loss: 1.0622 - val_sparse_categorical_accuracy: 0.6255\n",
            "Epoch 9/50\n",
            "196/196 - 8s - loss: 1.0261 - sparse_categorical_accuracy: 0.6375 - val_loss: 1.0417 - val_sparse_categorical_accuracy: 0.6365\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/50\n",
            "196/196 - 8s - loss: 1.0016 - sparse_categorical_accuracy: 0.6465 - val_loss: 1.0063 - val_sparse_categorical_accuracy: 0.6494\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/50\n",
            "196/196 - 8s - loss: 0.9831 - sparse_categorical_accuracy: 0.6536 - val_loss: 0.9665 - val_sparse_categorical_accuracy: 0.6732\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/50\n",
            "196/196 - 8s - loss: 0.9521 - sparse_categorical_accuracy: 0.6653 - val_loss: 0.9661 - val_sparse_categorical_accuracy: 0.6600\n",
            "Epoch 13/50\n",
            "196/196 - 8s - loss: 0.9377 - sparse_categorical_accuracy: 0.6673 - val_loss: 0.9438 - val_sparse_categorical_accuracy: 0.6769\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/50\n",
            "196/196 - 8s - loss: 0.9288 - sparse_categorical_accuracy: 0.6711 - val_loss: 0.9065 - val_sparse_categorical_accuracy: 0.6808\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15/50\n",
            "196/196 - 8s - loss: 0.9094 - sparse_categorical_accuracy: 0.6777 - val_loss: 0.9122 - val_sparse_categorical_accuracy: 0.6789\n",
            "Epoch 16/50\n",
            "196/196 - 8s - loss: 0.8992 - sparse_categorical_accuracy: 0.6810 - val_loss: 0.8715 - val_sparse_categorical_accuracy: 0.7000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 17/50\n",
            "196/196 - 8s - loss: 0.8767 - sparse_categorical_accuracy: 0.6904 - val_loss: 0.8852 - val_sparse_categorical_accuracy: 0.6861\n",
            "Epoch 18/50\n",
            "196/196 - 8s - loss: 0.8722 - sparse_categorical_accuracy: 0.6904 - val_loss: 0.8356 - val_sparse_categorical_accuracy: 0.7113\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 19/50\n",
            "196/196 - 8s - loss: 0.8570 - sparse_categorical_accuracy: 0.6976 - val_loss: 0.8942 - val_sparse_categorical_accuracy: 0.6924\n",
            "Epoch 20/50\n",
            "196/196 - 8s - loss: 0.8451 - sparse_categorical_accuracy: 0.7021 - val_loss: 0.8813 - val_sparse_categorical_accuracy: 0.7037\n",
            "Epoch 21/50\n",
            "196/196 - 8s - loss: 0.8342 - sparse_categorical_accuracy: 0.7064 - val_loss: 0.8774 - val_sparse_categorical_accuracy: 0.7100\n",
            "Epoch 22/50\n",
            "196/196 - 8s - loss: 0.8134 - sparse_categorical_accuracy: 0.7132 - val_loss: 0.8748 - val_sparse_categorical_accuracy: 0.7126\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 23/50\n",
            "196/196 - 8s - loss: 0.8083 - sparse_categorical_accuracy: 0.7134 - val_loss: 0.8498 - val_sparse_categorical_accuracy: 0.7166\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 24/50\n",
            "196/196 - 8s - loss: 0.8020 - sparse_categorical_accuracy: 0.7165 - val_loss: 0.8684 - val_sparse_categorical_accuracy: 0.7119\n",
            "Epoch 25/50\n",
            "196/196 - 8s - loss: 0.7825 - sparse_categorical_accuracy: 0.7233 - val_loss: 0.8370 - val_sparse_categorical_accuracy: 0.7271\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 26/50\n",
            "196/196 - 8s - loss: 0.7824 - sparse_categorical_accuracy: 0.7247 - val_loss: 0.7987 - val_sparse_categorical_accuracy: 0.7312\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 27/50\n",
            "196/196 - 8s - loss: 0.7661 - sparse_categorical_accuracy: 0.7288 - val_loss: 0.7900 - val_sparse_categorical_accuracy: 0.7312\n",
            "Epoch 28/50\n",
            "196/196 - 8s - loss: 0.7639 - sparse_categorical_accuracy: 0.7312 - val_loss: 0.7863 - val_sparse_categorical_accuracy: 0.7332\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 29/50\n",
            "196/196 - 8s - loss: 0.7550 - sparse_categorical_accuracy: 0.7354 - val_loss: 0.7942 - val_sparse_categorical_accuracy: 0.7333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 30/50\n",
            "196/196 - 8s - loss: 0.7391 - sparse_categorical_accuracy: 0.7400 - val_loss: 0.8548 - val_sparse_categorical_accuracy: 0.7261\n",
            "Epoch 31/50\n",
            "196/196 - 8s - loss: 0.7388 - sparse_categorical_accuracy: 0.7385 - val_loss: 0.8171 - val_sparse_categorical_accuracy: 0.7287\n",
            "Epoch 32/50\n",
            "196/196 - 8s - loss: 0.7263 - sparse_categorical_accuracy: 0.7419 - val_loss: 0.8250 - val_sparse_categorical_accuracy: 0.7343\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 33/50\n",
            "196/196 - 8s - loss: 0.7148 - sparse_categorical_accuracy: 0.7469 - val_loss: 0.8122 - val_sparse_categorical_accuracy: 0.7353\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 34/50\n",
            "196/196 - 8s - loss: 0.7224 - sparse_categorical_accuracy: 0.7450 - val_loss: 0.7805 - val_sparse_categorical_accuracy: 0.7309\n",
            "Epoch 35/50\n",
            "196/196 - 8s - loss: 0.7114 - sparse_categorical_accuracy: 0.7483 - val_loss: 0.8417 - val_sparse_categorical_accuracy: 0.7318\n",
            "Epoch 36/50\n",
            "196/196 - 8s - loss: 0.7028 - sparse_categorical_accuracy: 0.7535 - val_loss: 0.8099 - val_sparse_categorical_accuracy: 0.7393\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 37/50\n",
            "196/196 - 8s - loss: 0.6954 - sparse_categorical_accuracy: 0.7524 - val_loss: 0.8805 - val_sparse_categorical_accuracy: 0.7444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 38/50\n",
            "196/196 - 8s - loss: 0.6836 - sparse_categorical_accuracy: 0.7603 - val_loss: 0.8349 - val_sparse_categorical_accuracy: 0.7442\n",
            "Epoch 39/50\n",
            "196/196 - 8s - loss: 0.6755 - sparse_categorical_accuracy: 0.7622 - val_loss: 0.8070 - val_sparse_categorical_accuracy: 0.7489\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 40/50\n",
            "196/196 - 8s - loss: 0.6696 - sparse_categorical_accuracy: 0.7637 - val_loss: 0.7700 - val_sparse_categorical_accuracy: 0.7518\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 41/50\n",
            "196/196 - 8s - loss: 0.6671 - sparse_categorical_accuracy: 0.7639 - val_loss: 0.7610 - val_sparse_categorical_accuracy: 0.7506\n",
            "Epoch 42/50\n",
            "196/196 - 8s - loss: 0.6594 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.8329 - val_sparse_categorical_accuracy: 0.7462\n",
            "Epoch 43/50\n",
            "196/196 - 8s - loss: 0.6546 - sparse_categorical_accuracy: 0.7680 - val_loss: 0.8850 - val_sparse_categorical_accuracy: 0.7449\n",
            "Epoch 44/50\n",
            "196/196 - 8s - loss: 0.6490 - sparse_categorical_accuracy: 0.7709 - val_loss: 0.8697 - val_sparse_categorical_accuracy: 0.7350\n",
            "Epoch 45/50\n",
            "196/196 - 8s - loss: 0.6445 - sparse_categorical_accuracy: 0.7700 - val_loss: 0.8336 - val_sparse_categorical_accuracy: 0.7429\n",
            "Epoch 46/50\n",
            "196/196 - 8s - loss: 0.6350 - sparse_categorical_accuracy: 0.7759 - val_loss: 0.8318 - val_sparse_categorical_accuracy: 0.7536\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 47/50\n",
            "196/196 - 8s - loss: 0.6265 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.7787 - val_sparse_categorical_accuracy: 0.7596\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_66_layer_call_and_return_conditional_losses, conv2d_66_layer_call_fn, conv2d_67_layer_call_and_return_conditional_losses, conv2d_67_layer_call_fn, conv2d_68_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_4hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 48/50\n",
            "196/196 - 8s - loss: 0.6304 - sparse_categorical_accuracy: 0.7779 - val_loss: 0.7878 - val_sparse_categorical_accuracy: 0.7529\n",
            "Epoch 49/50\n",
            "196/196 - 8s - loss: 0.6193 - sparse_categorical_accuracy: 0.7797 - val_loss: 0.8114 - val_sparse_categorical_accuracy: 0.7501\n",
            "Epoch 50/50\n",
            "196/196 - 8s - loss: 0.6138 - sparse_categorical_accuracy: 0.7810 - val_loss: 0.8894 - val_sparse_categorical_accuracy: 0.7551\n",
            "Total training time 474.61591696739197 seconds\n",
            "Model: \"model_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_13 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        1273      \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        1817      \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,198,524\n",
            "Trainable params: 1,198,524\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 7s - loss: 2.0259 - sparse_categorical_accuracy: 0.2586 - val_loss: 1.7543 - val_sparse_categorical_accuracy: 0.3787\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 5s - loss: 1.6270 - sparse_categorical_accuracy: 0.4147 - val_loss: 1.5823 - val_sparse_categorical_accuracy: 0.4122\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "196/196 - 5s - loss: 1.4663 - sparse_categorical_accuracy: 0.4758 - val_loss: 1.5001 - val_sparse_categorical_accuracy: 0.4511\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 5s - loss: 1.3783 - sparse_categorical_accuracy: 0.5101 - val_loss: 1.4647 - val_sparse_categorical_accuracy: 0.4643\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "196/196 - 5s - loss: 1.3120 - sparse_categorical_accuracy: 0.5325 - val_loss: 1.2447 - val_sparse_categorical_accuracy: 0.5603\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/50\n",
            "196/196 - 5s - loss: 1.2570 - sparse_categorical_accuracy: 0.5565 - val_loss: 1.2865 - val_sparse_categorical_accuracy: 0.5360\n",
            "Epoch 7/50\n",
            "196/196 - 5s - loss: 1.2038 - sparse_categorical_accuracy: 0.5767 - val_loss: 1.2259 - val_sparse_categorical_accuracy: 0.5621\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/50\n",
            "196/196 - 5s - loss: 1.1562 - sparse_categorical_accuracy: 0.5902 - val_loss: 1.1374 - val_sparse_categorical_accuracy: 0.5934\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/50\n",
            "196/196 - 5s - loss: 1.1236 - sparse_categorical_accuracy: 0.6056 - val_loss: 1.1506 - val_sparse_categorical_accuracy: 0.5882\n",
            "Epoch 10/50\n",
            "196/196 - 4s - loss: 1.0896 - sparse_categorical_accuracy: 0.6148 - val_loss: 1.1754 - val_sparse_categorical_accuracy: 0.5859\n",
            "Epoch 11/50\n",
            "196/196 - 4s - loss: 1.0646 - sparse_categorical_accuracy: 0.6228 - val_loss: 1.0802 - val_sparse_categorical_accuracy: 0.6158\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/50\n",
            "196/196 - 5s - loss: 1.0345 - sparse_categorical_accuracy: 0.6354 - val_loss: 1.1656 - val_sparse_categorical_accuracy: 0.5952\n",
            "Epoch 13/50\n",
            "196/196 - 4s - loss: 1.0155 - sparse_categorical_accuracy: 0.6417 - val_loss: 1.0195 - val_sparse_categorical_accuracy: 0.6455\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/50\n",
            "196/196 - 5s - loss: 0.9934 - sparse_categorical_accuracy: 0.6483 - val_loss: 1.0403 - val_sparse_categorical_accuracy: 0.6313\n",
            "Epoch 15/50\n",
            "196/196 - 5s - loss: 0.9743 - sparse_categorical_accuracy: 0.6556 - val_loss: 1.0944 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 16/50\n",
            "196/196 - 5s - loss: 0.9629 - sparse_categorical_accuracy: 0.6581 - val_loss: 1.0022 - val_sparse_categorical_accuracy: 0.6462\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 17/50\n",
            "196/196 - 5s - loss: 0.9427 - sparse_categorical_accuracy: 0.6657 - val_loss: 1.0364 - val_sparse_categorical_accuracy: 0.6439\n",
            "Epoch 18/50\n",
            "196/196 - 5s - loss: 0.9312 - sparse_categorical_accuracy: 0.6717 - val_loss: 1.0117 - val_sparse_categorical_accuracy: 0.6415\n",
            "Epoch 19/50\n",
            "196/196 - 5s - loss: 0.9143 - sparse_categorical_accuracy: 0.6754 - val_loss: 0.9587 - val_sparse_categorical_accuracy: 0.6673\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20/50\n",
            "196/196 - 5s - loss: 0.9067 - sparse_categorical_accuracy: 0.6804 - val_loss: 0.9570 - val_sparse_categorical_accuracy: 0.6683\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 21/50\n",
            "196/196 - 5s - loss: 0.8905 - sparse_categorical_accuracy: 0.6846 - val_loss: 0.9743 - val_sparse_categorical_accuracy: 0.6629\n",
            "Epoch 22/50\n",
            "196/196 - 5s - loss: 0.8829 - sparse_categorical_accuracy: 0.6869 - val_loss: 0.9550 - val_sparse_categorical_accuracy: 0.6766\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 23/50\n",
            "196/196 - 5s - loss: 0.8729 - sparse_categorical_accuracy: 0.6899 - val_loss: 0.8886 - val_sparse_categorical_accuracy: 0.6881\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 24/50\n",
            "196/196 - 5s - loss: 0.8636 - sparse_categorical_accuracy: 0.6931 - val_loss: 0.9133 - val_sparse_categorical_accuracy: 0.6841\n",
            "Epoch 25/50\n",
            "196/196 - 5s - loss: 0.8544 - sparse_categorical_accuracy: 0.6971 - val_loss: 0.8961 - val_sparse_categorical_accuracy: 0.6923\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 26/50\n",
            "196/196 - 5s - loss: 0.8383 - sparse_categorical_accuracy: 0.7017 - val_loss: 0.9104 - val_sparse_categorical_accuracy: 0.6858\n",
            "Epoch 27/50\n",
            "196/196 - 5s - loss: 0.8341 - sparse_categorical_accuracy: 0.7066 - val_loss: 0.9055 - val_sparse_categorical_accuracy: 0.6885\n",
            "Epoch 28/50\n",
            "196/196 - 5s - loss: 0.8176 - sparse_categorical_accuracy: 0.7092 - val_loss: 0.8768 - val_sparse_categorical_accuracy: 0.6958\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 29/50\n",
            "196/196 - 5s - loss: 0.8151 - sparse_categorical_accuracy: 0.7134 - val_loss: 0.8895 - val_sparse_categorical_accuracy: 0.6982\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 30/50\n",
            "196/196 - 5s - loss: 0.8017 - sparse_categorical_accuracy: 0.7149 - val_loss: 0.8517 - val_sparse_categorical_accuracy: 0.7089\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 31/50\n",
            "196/196 - 5s - loss: 0.8077 - sparse_categorical_accuracy: 0.7126 - val_loss: 0.8570 - val_sparse_categorical_accuracy: 0.7155\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 32/50\n",
            "196/196 - 5s - loss: 0.7916 - sparse_categorical_accuracy: 0.7187 - val_loss: 0.8367 - val_sparse_categorical_accuracy: 0.7127\n",
            "Epoch 33/50\n",
            "196/196 - 5s - loss: 0.7858 - sparse_categorical_accuracy: 0.7194 - val_loss: 0.8854 - val_sparse_categorical_accuracy: 0.6945\n",
            "Epoch 34/50\n",
            "196/196 - 5s - loss: 0.7754 - sparse_categorical_accuracy: 0.7237 - val_loss: 0.8325 - val_sparse_categorical_accuracy: 0.7199\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 35/50\n",
            "196/196 - 5s - loss: 0.7642 - sparse_categorical_accuracy: 0.7296 - val_loss: 0.8238 - val_sparse_categorical_accuracy: 0.7248\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 36/50\n",
            "196/196 - 5s - loss: 0.7614 - sparse_categorical_accuracy: 0.7293 - val_loss: 0.8018 - val_sparse_categorical_accuracy: 0.7258\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 37/50\n",
            "196/196 - 5s - loss: 0.7542 - sparse_categorical_accuracy: 0.7310 - val_loss: 0.8133 - val_sparse_categorical_accuracy: 0.7209\n",
            "Epoch 38/50\n",
            "196/196 - 5s - loss: 0.7530 - sparse_categorical_accuracy: 0.7335 - val_loss: 0.8117 - val_sparse_categorical_accuracy: 0.7254\n",
            "Epoch 39/50\n",
            "196/196 - 5s - loss: 0.7388 - sparse_categorical_accuracy: 0.7367 - val_loss: 0.8445 - val_sparse_categorical_accuracy: 0.7103\n",
            "Epoch 40/50\n",
            "196/196 - 5s - loss: 0.7351 - sparse_categorical_accuracy: 0.7376 - val_loss: 0.8474 - val_sparse_categorical_accuracy: 0.7170\n",
            "Epoch 41/50\n",
            "196/196 - 5s - loss: 0.7340 - sparse_categorical_accuracy: 0.7383 - val_loss: 0.8379 - val_sparse_categorical_accuracy: 0.7157\n",
            "Epoch 42/50\n",
            "196/196 - 5s - loss: 0.7367 - sparse_categorical_accuracy: 0.7391 - val_loss: 0.7948 - val_sparse_categorical_accuracy: 0.7245\n",
            "Epoch 43/50\n",
            "196/196 - 5s - loss: 0.7233 - sparse_categorical_accuracy: 0.7408 - val_loss: 0.8432 - val_sparse_categorical_accuracy: 0.7170\n",
            "Epoch 44/50\n",
            "196/196 - 5s - loss: 0.7214 - sparse_categorical_accuracy: 0.7436 - val_loss: 0.9057 - val_sparse_categorical_accuracy: 0.6953\n",
            "Epoch 45/50\n",
            "196/196 - 5s - loss: 0.7161 - sparse_categorical_accuracy: 0.7443 - val_loss: 0.7879 - val_sparse_categorical_accuracy: 0.7271\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 46/50\n",
            "196/196 - 5s - loss: 0.7034 - sparse_categorical_accuracy: 0.7486 - val_loss: 0.7984 - val_sparse_categorical_accuracy: 0.7356\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_72_layer_call_and_return_conditional_losses, conv2d_72_layer_call_fn, conv2d_73_layer_call_and_return_conditional_losses, conv2d_73_layer_call_fn, conv2d_74_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 47/50\n",
            "196/196 - 5s - loss: 0.7046 - sparse_categorical_accuracy: 0.7483 - val_loss: 0.7877 - val_sparse_categorical_accuracy: 0.7276\n",
            "Epoch 48/50\n",
            "196/196 - 5s - loss: 0.7057 - sparse_categorical_accuracy: 0.7470 - val_loss: 0.8175 - val_sparse_categorical_accuracy: 0.7264\n",
            "Epoch 49/50\n",
            "196/196 - 5s - loss: 0.6983 - sparse_categorical_accuracy: 0.7517 - val_loss: 0.8467 - val_sparse_categorical_accuracy: 0.7256\n",
            "Epoch 50/50\n",
            "196/196 - 5s - loss: 0.6937 - sparse_categorical_accuracy: 0.7518 - val_loss: 0.8025 - val_sparse_categorical_accuracy: 0.7314\n",
            "Total training time 300.4632797241211 seconds\n",
            "Model: \"model_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_14 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        2290      \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        3122      \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,200,846\n",
            "Trainable params: 1,200,846\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 9s - loss: 1.9985 - sparse_categorical_accuracy: 0.2574 - val_loss: 1.8109 - val_sparse_categorical_accuracy: 0.3404\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 6s - loss: 1.5912 - sparse_categorical_accuracy: 0.4235 - val_loss: 1.5996 - val_sparse_categorical_accuracy: 0.4278\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "196/196 - 6s - loss: 1.4418 - sparse_categorical_accuracy: 0.4806 - val_loss: 1.5122 - val_sparse_categorical_accuracy: 0.4576\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 6s - loss: 1.3509 - sparse_categorical_accuracy: 0.5175 - val_loss: 1.4120 - val_sparse_categorical_accuracy: 0.5041\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "196/196 - 6s - loss: 1.2903 - sparse_categorical_accuracy: 0.5383 - val_loss: 1.6166 - val_sparse_categorical_accuracy: 0.4605\n",
            "Epoch 6/50\n",
            "196/196 - 6s - loss: 1.2436 - sparse_categorical_accuracy: 0.5594 - val_loss: 1.2510 - val_sparse_categorical_accuracy: 0.5520\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "196/196 - 6s - loss: 1.1902 - sparse_categorical_accuracy: 0.5781 - val_loss: 1.2711 - val_sparse_categorical_accuracy: 0.5524\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/50\n",
            "196/196 - 6s - loss: 1.1623 - sparse_categorical_accuracy: 0.5880 - val_loss: 1.1906 - val_sparse_categorical_accuracy: 0.5846\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/50\n",
            "196/196 - 6s - loss: 1.1212 - sparse_categorical_accuracy: 0.6045 - val_loss: 1.1637 - val_sparse_categorical_accuracy: 0.5905\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/50\n",
            "196/196 - 6s - loss: 1.0827 - sparse_categorical_accuracy: 0.6190 - val_loss: 1.2579 - val_sparse_categorical_accuracy: 0.5778\n",
            "Epoch 11/50\n",
            "196/196 - 6s - loss: 1.0682 - sparse_categorical_accuracy: 0.6231 - val_loss: 1.1530 - val_sparse_categorical_accuracy: 0.5921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/50\n",
            "196/196 - 6s - loss: 1.0400 - sparse_categorical_accuracy: 0.6326 - val_loss: 1.0957 - val_sparse_categorical_accuracy: 0.6202\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13/50\n",
            "196/196 - 6s - loss: 1.0197 - sparse_categorical_accuracy: 0.6405 - val_loss: 1.0179 - val_sparse_categorical_accuracy: 0.6408\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/50\n",
            "196/196 - 6s - loss: 0.9923 - sparse_categorical_accuracy: 0.6510 - val_loss: 1.0486 - val_sparse_categorical_accuracy: 0.6333\n",
            "Epoch 15/50\n",
            "196/196 - 6s - loss: 0.9791 - sparse_categorical_accuracy: 0.6548 - val_loss: 0.9817 - val_sparse_categorical_accuracy: 0.6530\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16/50\n",
            "196/196 - 6s - loss: 0.9611 - sparse_categorical_accuracy: 0.6599 - val_loss: 1.2123 - val_sparse_categorical_accuracy: 0.5953\n",
            "Epoch 17/50\n",
            "196/196 - 6s - loss: 0.9540 - sparse_categorical_accuracy: 0.6655 - val_loss: 1.0330 - val_sparse_categorical_accuracy: 0.6370\n",
            "Epoch 18/50\n",
            "196/196 - 6s - loss: 0.9352 - sparse_categorical_accuracy: 0.6701 - val_loss: 1.0352 - val_sparse_categorical_accuracy: 0.6512\n",
            "Epoch 19/50\n",
            "196/196 - 6s - loss: 0.9087 - sparse_categorical_accuracy: 0.6794 - val_loss: 1.0717 - val_sparse_categorical_accuracy: 0.6331\n",
            "Epoch 20/50\n",
            "196/196 - 6s - loss: 0.9004 - sparse_categorical_accuracy: 0.6797 - val_loss: 0.9226 - val_sparse_categorical_accuracy: 0.6741\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 21/50\n",
            "196/196 - 6s - loss: 0.8835 - sparse_categorical_accuracy: 0.6872 - val_loss: 0.9887 - val_sparse_categorical_accuracy: 0.6668\n",
            "Epoch 22/50\n",
            "196/196 - 6s - loss: 0.8786 - sparse_categorical_accuracy: 0.6883 - val_loss: 1.0150 - val_sparse_categorical_accuracy: 0.6569\n",
            "Epoch 23/50\n",
            "196/196 - 6s - loss: 0.8712 - sparse_categorical_accuracy: 0.6917 - val_loss: 0.9632 - val_sparse_categorical_accuracy: 0.6715\n",
            "Epoch 24/50\n",
            "196/196 - 6s - loss: 0.8543 - sparse_categorical_accuracy: 0.6986 - val_loss: 0.8830 - val_sparse_categorical_accuracy: 0.6949\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 25/50\n",
            "196/196 - 6s - loss: 0.8401 - sparse_categorical_accuracy: 0.7027 - val_loss: 0.9273 - val_sparse_categorical_accuracy: 0.6890\n",
            "Epoch 26/50\n",
            "196/196 - 6s - loss: 0.8352 - sparse_categorical_accuracy: 0.7051 - val_loss: 0.8783 - val_sparse_categorical_accuracy: 0.7022\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 27/50\n",
            "196/196 - 6s - loss: 0.8241 - sparse_categorical_accuracy: 0.7118 - val_loss: 0.9163 - val_sparse_categorical_accuracy: 0.6882\n",
            "Epoch 28/50\n",
            "196/196 - 6s - loss: 0.8150 - sparse_categorical_accuracy: 0.7150 - val_loss: 0.9507 - val_sparse_categorical_accuracy: 0.6762\n",
            "Epoch 29/50\n",
            "196/196 - 6s - loss: 0.8092 - sparse_categorical_accuracy: 0.7161 - val_loss: 0.9291 - val_sparse_categorical_accuracy: 0.6900\n",
            "Epoch 30/50\n",
            "196/196 - 6s - loss: 0.8015 - sparse_categorical_accuracy: 0.7163 - val_loss: 0.8625 - val_sparse_categorical_accuracy: 0.7024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 31/50\n",
            "196/196 - 6s - loss: 0.7899 - sparse_categorical_accuracy: 0.7185 - val_loss: 0.9635 - val_sparse_categorical_accuracy: 0.6807\n",
            "Epoch 32/50\n",
            "196/196 - 6s - loss: 0.7845 - sparse_categorical_accuracy: 0.7239 - val_loss: 0.8907 - val_sparse_categorical_accuracy: 0.7046\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 33/50\n",
            "196/196 - 6s - loss: 0.7700 - sparse_categorical_accuracy: 0.7271 - val_loss: 1.0094 - val_sparse_categorical_accuracy: 0.6816\n",
            "Epoch 34/50\n",
            "196/196 - 6s - loss: 0.7719 - sparse_categorical_accuracy: 0.7272 - val_loss: 0.9248 - val_sparse_categorical_accuracy: 0.7004\n",
            "Epoch 35/50\n",
            "196/196 - 6s - loss: 0.7628 - sparse_categorical_accuracy: 0.7297 - val_loss: 0.8308 - val_sparse_categorical_accuracy: 0.7260\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 36/50\n",
            "196/196 - 6s - loss: 0.7585 - sparse_categorical_accuracy: 0.7343 - val_loss: 0.8851 - val_sparse_categorical_accuracy: 0.7103\n",
            "Epoch 37/50\n",
            "196/196 - 6s - loss: 0.7520 - sparse_categorical_accuracy: 0.7321 - val_loss: 0.9655 - val_sparse_categorical_accuracy: 0.7003\n",
            "Epoch 38/50\n",
            "196/196 - 6s - loss: 0.7434 - sparse_categorical_accuracy: 0.7385 - val_loss: 0.8225 - val_sparse_categorical_accuracy: 0.7230\n",
            "Epoch 39/50\n",
            "196/196 - 6s - loss: 0.7445 - sparse_categorical_accuracy: 0.7337 - val_loss: 0.8560 - val_sparse_categorical_accuracy: 0.7245\n",
            "Epoch 40/50\n",
            "196/196 - 6s - loss: 0.7418 - sparse_categorical_accuracy: 0.7366 - val_loss: 0.8892 - val_sparse_categorical_accuracy: 0.7138\n",
            "Epoch 41/50\n",
            "196/196 - 6s - loss: 0.7283 - sparse_categorical_accuracy: 0.7429 - val_loss: 0.8670 - val_sparse_categorical_accuracy: 0.7210\n",
            "Epoch 42/50\n",
            "196/196 - 6s - loss: 0.7278 - sparse_categorical_accuracy: 0.7414 - val_loss: 0.8245 - val_sparse_categorical_accuracy: 0.7308\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 43/50\n",
            "196/196 - 6s - loss: 0.7158 - sparse_categorical_accuracy: 0.7438 - val_loss: 0.7999 - val_sparse_categorical_accuracy: 0.7323\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 44/50\n",
            "196/196 - 6s - loss: 0.7155 - sparse_categorical_accuracy: 0.7468 - val_loss: 0.8862 - val_sparse_categorical_accuracy: 0.7316\n",
            "Epoch 45/50\n",
            "196/196 - 6s - loss: 0.7082 - sparse_categorical_accuracy: 0.7485 - val_loss: 0.8787 - val_sparse_categorical_accuracy: 0.7173\n",
            "Epoch 46/50\n",
            "196/196 - 6s - loss: 0.7080 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.8670 - val_sparse_categorical_accuracy: 0.7269\n",
            "Epoch 47/50\n",
            "196/196 - 6s - loss: 0.7038 - sparse_categorical_accuracy: 0.7507 - val_loss: 0.8257 - val_sparse_categorical_accuracy: 0.7255\n",
            "Epoch 48/50\n",
            "196/196 - 6s - loss: 0.7012 - sparse_categorical_accuracy: 0.7516 - val_loss: 0.8045 - val_sparse_categorical_accuracy: 0.7348\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 49/50\n",
            "196/196 - 6s - loss: 0.6918 - sparse_categorical_accuracy: 0.7549 - val_loss: 0.8597 - val_sparse_categorical_accuracy: 0.7287\n",
            "Epoch 50/50\n",
            "196/196 - 6s - loss: 0.6850 - sparse_categorical_accuracy: 0.7541 - val_loss: 0.8473 - val_sparse_categorical_accuracy: 0.7379\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_78_layer_call_and_return_conditional_losses, conv2d_78_layer_call_fn, conv2d_79_layer_call_and_return_conditional_losses, conv2d_79_layer_call_fn, conv2d_80_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total training time 381.4183394908905 seconds\n",
            "Model: \"model_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_15 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        4324      \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        5732      \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,205,490\n",
            "Trainable params: 1,205,490\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 9s - loss: 1.9548 - sparse_categorical_accuracy: 0.2794 - val_loss: 1.6761 - val_sparse_categorical_accuracy: 0.3955\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 7s - loss: 1.5584 - sparse_categorical_accuracy: 0.4386 - val_loss: 1.5465 - val_sparse_categorical_accuracy: 0.4367\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "196/196 - 7s - loss: 1.3975 - sparse_categorical_accuracy: 0.5025 - val_loss: 1.4168 - val_sparse_categorical_accuracy: 0.4839\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 7s - loss: 1.2898 - sparse_categorical_accuracy: 0.5398 - val_loss: 1.3188 - val_sparse_categorical_accuracy: 0.5263\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "196/196 - 7s - loss: 1.2143 - sparse_categorical_accuracy: 0.5697 - val_loss: 1.2256 - val_sparse_categorical_accuracy: 0.5632\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/50\n",
            "196/196 - 7s - loss: 1.1536 - sparse_categorical_accuracy: 0.5924 - val_loss: 1.2056 - val_sparse_categorical_accuracy: 0.5755\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "196/196 - 7s - loss: 1.1131 - sparse_categorical_accuracy: 0.6047 - val_loss: 1.3259 - val_sparse_categorical_accuracy: 0.5577\n",
            "Epoch 8/50\n",
            "196/196 - 7s - loss: 1.0671 - sparse_categorical_accuracy: 0.6244 - val_loss: 1.1826 - val_sparse_categorical_accuracy: 0.5856\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/50\n",
            "196/196 - 7s - loss: 1.0378 - sparse_categorical_accuracy: 0.6336 - val_loss: 1.0997 - val_sparse_categorical_accuracy: 0.6200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/50\n",
            "196/196 - 7s - loss: 1.0063 - sparse_categorical_accuracy: 0.6445 - val_loss: 1.1746 - val_sparse_categorical_accuracy: 0.6047\n",
            "Epoch 11/50\n",
            "196/196 - 7s - loss: 0.9761 - sparse_categorical_accuracy: 0.6533 - val_loss: 1.2334 - val_sparse_categorical_accuracy: 0.6061\n",
            "Epoch 12/50\n",
            "196/196 - 7s - loss: 0.9573 - sparse_categorical_accuracy: 0.6633 - val_loss: 1.1014 - val_sparse_categorical_accuracy: 0.6384\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13/50\n",
            "196/196 - 7s - loss: 0.9362 - sparse_categorical_accuracy: 0.6698 - val_loss: 1.0180 - val_sparse_categorical_accuracy: 0.6571\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/50\n",
            "196/196 - 7s - loss: 0.9177 - sparse_categorical_accuracy: 0.6745 - val_loss: 1.0844 - val_sparse_categorical_accuracy: 0.6565\n",
            "Epoch 15/50\n",
            "196/196 - 7s - loss: 0.9036 - sparse_categorical_accuracy: 0.6803 - val_loss: 1.1284 - val_sparse_categorical_accuracy: 0.6427\n",
            "Epoch 16/50\n",
            "196/196 - 7s - loss: 0.8882 - sparse_categorical_accuracy: 0.6876 - val_loss: 1.0115 - val_sparse_categorical_accuracy: 0.6666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 17/50\n",
            "196/196 - 7s - loss: 0.8678 - sparse_categorical_accuracy: 0.6938 - val_loss: 1.2005 - val_sparse_categorical_accuracy: 0.6425\n",
            "Epoch 18/50\n",
            "196/196 - 7s - loss: 0.8430 - sparse_categorical_accuracy: 0.7008 - val_loss: 1.0569 - val_sparse_categorical_accuracy: 0.6693\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 19/50\n",
            "196/196 - 7s - loss: 0.8378 - sparse_categorical_accuracy: 0.7018 - val_loss: 1.0897 - val_sparse_categorical_accuracy: 0.6549\n",
            "Epoch 20/50\n",
            "196/196 - 7s - loss: 0.8263 - sparse_categorical_accuracy: 0.7115 - val_loss: 1.0027 - val_sparse_categorical_accuracy: 0.6870\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 21/50\n",
            "196/196 - 7s - loss: 0.8108 - sparse_categorical_accuracy: 0.7141 - val_loss: 0.9715 - val_sparse_categorical_accuracy: 0.6779\n",
            "Epoch 22/50\n",
            "196/196 - 7s - loss: 0.8020 - sparse_categorical_accuracy: 0.7182 - val_loss: 1.0077 - val_sparse_categorical_accuracy: 0.6780\n",
            "Epoch 23/50\n",
            "196/196 - 7s - loss: 0.7908 - sparse_categorical_accuracy: 0.7212 - val_loss: 1.0110 - val_sparse_categorical_accuracy: 0.6931\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 24/50\n",
            "196/196 - 7s - loss: 0.7757 - sparse_categorical_accuracy: 0.7263 - val_loss: 0.8523 - val_sparse_categorical_accuracy: 0.7086\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 25/50\n",
            "196/196 - 7s - loss: 0.7652 - sparse_categorical_accuracy: 0.7318 - val_loss: 0.9553 - val_sparse_categorical_accuracy: 0.7016\n",
            "Epoch 26/50\n",
            "196/196 - 7s - loss: 0.7556 - sparse_categorical_accuracy: 0.7352 - val_loss: 0.9319 - val_sparse_categorical_accuracy: 0.6971\n",
            "Epoch 27/50\n",
            "196/196 - 7s - loss: 0.7493 - sparse_categorical_accuracy: 0.7356 - val_loss: 0.9496 - val_sparse_categorical_accuracy: 0.7007\n",
            "Epoch 28/50\n",
            "196/196 - 7s - loss: 0.7381 - sparse_categorical_accuracy: 0.7413 - val_loss: 1.1473 - val_sparse_categorical_accuracy: 0.6769\n",
            "Epoch 29/50\n",
            "196/196 - 7s - loss: 0.7299 - sparse_categorical_accuracy: 0.7450 - val_loss: 1.0409 - val_sparse_categorical_accuracy: 0.7008\n",
            "Epoch 30/50\n",
            "196/196 - 7s - loss: 0.7216 - sparse_categorical_accuracy: 0.7461 - val_loss: 1.0835 - val_sparse_categorical_accuracy: 0.6921\n",
            "Epoch 31/50\n",
            "196/196 - 7s - loss: 0.7146 - sparse_categorical_accuracy: 0.7501 - val_loss: 0.9192 - val_sparse_categorical_accuracy: 0.7273\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 32/50\n",
            "196/196 - 7s - loss: 0.7108 - sparse_categorical_accuracy: 0.7473 - val_loss: 1.0643 - val_sparse_categorical_accuracy: 0.7045\n",
            "Epoch 33/50\n",
            "196/196 - 7s - loss: 0.7058 - sparse_categorical_accuracy: 0.7538 - val_loss: 0.9601 - val_sparse_categorical_accuracy: 0.7177\n",
            "Epoch 34/50\n",
            "196/196 - 7s - loss: 0.6860 - sparse_categorical_accuracy: 0.7582 - val_loss: 1.0211 - val_sparse_categorical_accuracy: 0.7128\n",
            "Epoch 35/50\n",
            "196/196 - 7s - loss: 0.6749 - sparse_categorical_accuracy: 0.7608 - val_loss: 1.0951 - val_sparse_categorical_accuracy: 0.7031\n",
            "Epoch 36/50\n",
            "196/196 - 7s - loss: 0.6756 - sparse_categorical_accuracy: 0.7621 - val_loss: 1.0074 - val_sparse_categorical_accuracy: 0.7082\n",
            "Epoch 37/50\n",
            "196/196 - 7s - loss: 0.6638 - sparse_categorical_accuracy: 0.7658 - val_loss: 1.1197 - val_sparse_categorical_accuracy: 0.7052\n",
            "Epoch 38/50\n",
            "196/196 - 7s - loss: 0.6676 - sparse_categorical_accuracy: 0.7646 - val_loss: 1.1425 - val_sparse_categorical_accuracy: 0.7088\n",
            "Epoch 39/50\n",
            "196/196 - 7s - loss: 0.6544 - sparse_categorical_accuracy: 0.7696 - val_loss: 1.2183 - val_sparse_categorical_accuracy: 0.6981\n",
            "Epoch 40/50\n",
            "196/196 - 7s - loss: 0.6562 - sparse_categorical_accuracy: 0.7712 - val_loss: 1.0703 - val_sparse_categorical_accuracy: 0.7154\n",
            "Epoch 41/50\n",
            "196/196 - 7s - loss: 0.6412 - sparse_categorical_accuracy: 0.7749 - val_loss: 1.1767 - val_sparse_categorical_accuracy: 0.7073\n",
            "Epoch 42/50\n",
            "196/196 - 7s - loss: 0.6429 - sparse_categorical_accuracy: 0.7742 - val_loss: 1.1605 - val_sparse_categorical_accuracy: 0.7081\n",
            "Epoch 43/50\n",
            "196/196 - 7s - loss: 0.6344 - sparse_categorical_accuracy: 0.7766 - val_loss: 1.2417 - val_sparse_categorical_accuracy: 0.7028\n",
            "Epoch 44/50\n",
            "196/196 - 7s - loss: 0.6351 - sparse_categorical_accuracy: 0.7770 - val_loss: 0.8401 - val_sparse_categorical_accuracy: 0.7479\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_84_layer_call_and_return_conditional_losses, conv2d_84_layer_call_fn, conv2d_85_layer_call_and_return_conditional_losses, conv2d_85_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 45/50\n",
            "196/196 - 7s - loss: 0.6262 - sparse_categorical_accuracy: 0.7787 - val_loss: 1.1893 - val_sparse_categorical_accuracy: 0.7027\n",
            "Epoch 46/50\n",
            "196/196 - 7s - loss: 0.6167 - sparse_categorical_accuracy: 0.7803 - val_loss: 0.9159 - val_sparse_categorical_accuracy: 0.7373\n",
            "Epoch 47/50\n",
            "196/196 - 7s - loss: 0.6183 - sparse_categorical_accuracy: 0.7816 - val_loss: 1.1291 - val_sparse_categorical_accuracy: 0.7310\n",
            "Epoch 48/50\n",
            "196/196 - 7s - loss: 0.6095 - sparse_categorical_accuracy: 0.7852 - val_loss: 1.2410 - val_sparse_categorical_accuracy: 0.6930\n",
            "Epoch 49/50\n",
            "196/196 - 7s - loss: 0.6001 - sparse_categorical_accuracy: 0.7876 - val_loss: 1.1388 - val_sparse_categorical_accuracy: 0.7268\n",
            "Epoch 50/50\n",
            "196/196 - 7s - loss: 0.6092 - sparse_categorical_accuracy: 0.7847 - val_loss: 1.5373 - val_sparse_categorical_accuracy: 0.6875\n",
            "Total training time 396.42595314979553 seconds\n",
            "Model: \"model_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_16 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        8392      \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        10952     \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,214,778\n",
            "Trainable params: 1,214,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 10s - loss: 1.9777 - sparse_categorical_accuracy: 0.2643 - val_loss: 1.8147 - val_sparse_categorical_accuracy: 0.3419\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 8s - loss: 1.5636 - sparse_categorical_accuracy: 0.4304 - val_loss: 1.5673 - val_sparse_categorical_accuracy: 0.4323\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "196/196 - 8s - loss: 1.4015 - sparse_categorical_accuracy: 0.4951 - val_loss: 1.3977 - val_sparse_categorical_accuracy: 0.5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 8s - loss: 1.2869 - sparse_categorical_accuracy: 0.5430 - val_loss: 1.6943 - val_sparse_categorical_accuracy: 0.4593\n",
            "Epoch 5/50\n",
            "196/196 - 8s - loss: 1.1988 - sparse_categorical_accuracy: 0.5756 - val_loss: 1.3659 - val_sparse_categorical_accuracy: 0.5414\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/50\n",
            "196/196 - 8s - loss: 1.1456 - sparse_categorical_accuracy: 0.5946 - val_loss: 1.2526 - val_sparse_categorical_accuracy: 0.5689\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "196/196 - 8s - loss: 1.0934 - sparse_categorical_accuracy: 0.6123 - val_loss: 1.6195 - val_sparse_categorical_accuracy: 0.5257\n",
            "Epoch 8/50\n",
            "196/196 - 8s - loss: 1.0571 - sparse_categorical_accuracy: 0.6264 - val_loss: 1.2617 - val_sparse_categorical_accuracy: 0.5836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/50\n",
            "196/196 - 8s - loss: 1.0166 - sparse_categorical_accuracy: 0.6431 - val_loss: 1.3704 - val_sparse_categorical_accuracy: 0.5717\n",
            "Epoch 10/50\n",
            "196/196 - 8s - loss: 1.0000 - sparse_categorical_accuracy: 0.6472 - val_loss: 1.1873 - val_sparse_categorical_accuracy: 0.6222\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/50\n",
            "196/196 - 8s - loss: 0.9718 - sparse_categorical_accuracy: 0.6571 - val_loss: 1.3303 - val_sparse_categorical_accuracy: 0.5840\n",
            "Epoch 12/50\n",
            "196/196 - 8s - loss: 0.9443 - sparse_categorical_accuracy: 0.6669 - val_loss: 1.1950 - val_sparse_categorical_accuracy: 0.6158\n",
            "Epoch 13/50\n",
            "196/196 - 8s - loss: 0.9273 - sparse_categorical_accuracy: 0.6709 - val_loss: 1.2606 - val_sparse_categorical_accuracy: 0.6145\n",
            "Epoch 14/50\n",
            "196/196 - 8s - loss: 0.9005 - sparse_categorical_accuracy: 0.6807 - val_loss: 1.1319 - val_sparse_categorical_accuracy: 0.6307\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15/50\n",
            "196/196 - 8s - loss: 0.8829 - sparse_categorical_accuracy: 0.6875 - val_loss: 1.1014 - val_sparse_categorical_accuracy: 0.6527\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16/50\n",
            "196/196 - 8s - loss: 0.8706 - sparse_categorical_accuracy: 0.6920 - val_loss: 1.0654 - val_sparse_categorical_accuracy: 0.6471\n",
            "Epoch 17/50\n",
            "196/196 - 8s - loss: 0.8526 - sparse_categorical_accuracy: 0.6971 - val_loss: 0.9880 - val_sparse_categorical_accuracy: 0.6669\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18/50\n",
            "196/196 - 8s - loss: 0.8429 - sparse_categorical_accuracy: 0.7002 - val_loss: 1.0976 - val_sparse_categorical_accuracy: 0.6555\n",
            "Epoch 19/50\n",
            "196/196 - 8s - loss: 0.8312 - sparse_categorical_accuracy: 0.7075 - val_loss: 1.0977 - val_sparse_categorical_accuracy: 0.6775\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20/50\n",
            "196/196 - 8s - loss: 0.8222 - sparse_categorical_accuracy: 0.7084 - val_loss: 0.8954 - val_sparse_categorical_accuracy: 0.7043\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 21/50\n",
            "196/196 - 8s - loss: 0.8035 - sparse_categorical_accuracy: 0.7135 - val_loss: 1.1102 - val_sparse_categorical_accuracy: 0.6728\n",
            "Epoch 22/50\n",
            "196/196 - 8s - loss: 0.7922 - sparse_categorical_accuracy: 0.7197 - val_loss: 1.0700 - val_sparse_categorical_accuracy: 0.6779\n",
            "Epoch 23/50\n",
            "196/196 - 8s - loss: 0.7821 - sparse_categorical_accuracy: 0.7243 - val_loss: 1.0794 - val_sparse_categorical_accuracy: 0.6727\n",
            "Epoch 24/50\n",
            "196/196 - 8s - loss: 0.7698 - sparse_categorical_accuracy: 0.7278 - val_loss: 0.9173 - val_sparse_categorical_accuracy: 0.7038\n",
            "Epoch 25/50\n",
            "196/196 - 8s - loss: 0.7621 - sparse_categorical_accuracy: 0.7286 - val_loss: 1.0947 - val_sparse_categorical_accuracy: 0.6810\n",
            "Epoch 26/50\n",
            "196/196 - 8s - loss: 0.7454 - sparse_categorical_accuracy: 0.7351 - val_loss: 0.9854 - val_sparse_categorical_accuracy: 0.7053\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 27/50\n",
            "196/196 - 8s - loss: 0.7421 - sparse_categorical_accuracy: 0.7367 - val_loss: 1.0013 - val_sparse_categorical_accuracy: 0.7052\n",
            "Epoch 28/50\n",
            "196/196 - 8s - loss: 0.7335 - sparse_categorical_accuracy: 0.7409 - val_loss: 1.0242 - val_sparse_categorical_accuracy: 0.6949\n",
            "Epoch 29/50\n",
            "196/196 - 8s - loss: 0.7222 - sparse_categorical_accuracy: 0.7440 - val_loss: 0.9450 - val_sparse_categorical_accuracy: 0.7078\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 30/50\n",
            "196/196 - 8s - loss: 0.7198 - sparse_categorical_accuracy: 0.7437 - val_loss: 0.8497 - val_sparse_categorical_accuracy: 0.7280\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 31/50\n",
            "196/196 - 8s - loss: 0.7149 - sparse_categorical_accuracy: 0.7474 - val_loss: 0.9124 - val_sparse_categorical_accuracy: 0.7130\n",
            "Epoch 32/50\n",
            "196/196 - 8s - loss: 0.6975 - sparse_categorical_accuracy: 0.7546 - val_loss: 0.8390 - val_sparse_categorical_accuracy: 0.7323\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 33/50\n",
            "196/196 - 8s - loss: 0.6949 - sparse_categorical_accuracy: 0.7541 - val_loss: 0.9984 - val_sparse_categorical_accuracy: 0.7104\n",
            "Epoch 34/50\n",
            "196/196 - 8s - loss: 0.6908 - sparse_categorical_accuracy: 0.7550 - val_loss: 1.0292 - val_sparse_categorical_accuracy: 0.7083\n",
            "Epoch 35/50\n",
            "196/196 - 8s - loss: 0.6822 - sparse_categorical_accuracy: 0.7563 - val_loss: 0.9945 - val_sparse_categorical_accuracy: 0.7043\n",
            "Epoch 36/50\n",
            "196/196 - 8s - loss: 0.6766 - sparse_categorical_accuracy: 0.7597 - val_loss: 0.9745 - val_sparse_categorical_accuracy: 0.7232\n",
            "Epoch 37/50\n",
            "196/196 - 8s - loss: 0.6684 - sparse_categorical_accuracy: 0.7625 - val_loss: 1.1017 - val_sparse_categorical_accuracy: 0.7146\n",
            "Epoch 38/50\n",
            "196/196 - 8s - loss: 0.6592 - sparse_categorical_accuracy: 0.7662 - val_loss: 0.8834 - val_sparse_categorical_accuracy: 0.7283\n",
            "Epoch 39/50\n",
            "196/196 - 8s - loss: 0.6584 - sparse_categorical_accuracy: 0.7677 - val_loss: 0.8985 - val_sparse_categorical_accuracy: 0.7410\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_90_layer_call_and_return_conditional_losses, conv2d_90_layer_call_fn, conv2d_91_layer_call_and_return_conditional_losses, conv2d_91_layer_call_fn, conv2d_92_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_1udim_8hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 40/50\n",
            "196/196 - 8s - loss: 0.6459 - sparse_categorical_accuracy: 0.7713 - val_loss: 1.0689 - val_sparse_categorical_accuracy: 0.7152\n",
            "Epoch 41/50\n",
            "196/196 - 8s - loss: 0.6408 - sparse_categorical_accuracy: 0.7725 - val_loss: 0.9693 - val_sparse_categorical_accuracy: 0.7233\n",
            "Epoch 42/50\n",
            "196/196 - 8s - loss: 0.6335 - sparse_categorical_accuracy: 0.7772 - val_loss: 0.9040 - val_sparse_categorical_accuracy: 0.7278\n",
            "Epoch 43/50\n",
            "196/196 - 8s - loss: 0.6303 - sparse_categorical_accuracy: 0.7747 - val_loss: 0.9977 - val_sparse_categorical_accuracy: 0.7253\n",
            "Epoch 44/50\n",
            "196/196 - 8s - loss: 0.6258 - sparse_categorical_accuracy: 0.7765 - val_loss: 0.8539 - val_sparse_categorical_accuracy: 0.7340\n",
            "Epoch 45/50\n",
            "196/196 - 8s - loss: 0.6245 - sparse_categorical_accuracy: 0.7788 - val_loss: 1.0009 - val_sparse_categorical_accuracy: 0.7307\n",
            "Epoch 46/50\n",
            "196/196 - 8s - loss: 0.6235 - sparse_categorical_accuracy: 0.7778 - val_loss: 1.1617 - val_sparse_categorical_accuracy: 0.7148\n",
            "Epoch 47/50\n",
            "196/196 - 8s - loss: 0.6095 - sparse_categorical_accuracy: 0.7832 - val_loss: 0.9346 - val_sparse_categorical_accuracy: 0.7317\n",
            "Epoch 48/50\n",
            "196/196 - 8s - loss: 0.6080 - sparse_categorical_accuracy: 0.7828 - val_loss: 1.0750 - val_sparse_categorical_accuracy: 0.7255\n",
            "Epoch 49/50\n",
            "196/196 - 8s - loss: 0.6059 - sparse_categorical_accuracy: 0.7829 - val_loss: 0.8797 - val_sparse_categorical_accuracy: 0.7393\n",
            "Epoch 50/50\n",
            "196/196 - 8s - loss: 0.6001 - sparse_categorical_accuracy: 0.7861 - val_loss: 0.9338 - val_sparse_categorical_accuracy: 0.7353\n",
            "Total training time 451.2892825603485 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGScdXR7HZXv"
      },
      "source": [
        "##Exp 4 - 2 Heads, X u dim, Y Key dim\n",
        "Model : LAMBDA  \n",
        "Preprocessing : False  \n",
        "Batch size : 256  \n",
        "Key dim : 1,2,4,8  \n",
        "u dim : 2,4,8  \n",
        "Heads : 2  \n",
        "Pos. emb. size : 14  \n",
        "LambdaConv : False  \n",
        "\n",
        "---\n",
        "<pre>\n",
        "Q = k * hd       =  2, 4, 8,16|  2,  4,  8, 16|  2,  4,  8, 16|\n",
        "K = k * u        =  2, 4, 8,16|  4,  8, 16, 32|  8, 16, 32, 64|\n",
        "V = 64 // hd * u = 64,64,64,64|128,128,128,128|256,256,256,256|\n",
        "</pre>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCKaERn-PBme",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9932e37b-9c2f-4573-e2a9-f1e771a24305"
      },
      "source": [
        "hds = 2\n",
        "for u_dim in [2,4,8]:\n",
        "  for k_dim in [1,2,4,8]:\n",
        "    model = LambdaNetwork(num_classes=num_classes, \n",
        "                          image_height=image_height, \n",
        "                          image_width=image_width,\n",
        "                          k_dim=k_dim,\n",
        "                          u_dim=u_dim,\n",
        "                          num_heads=hds,\n",
        "                          n_r_size=14,\n",
        "                          local_contexts=False,\n",
        "                          preprocess=False).model()\n",
        "    model.summary()\n",
        "    if 'LAMBDA' not in history:\n",
        "      history['LAMBDA'] = dict()\n",
        "    if hds not in history['LAMBDA']:\n",
        "      history['LAMBDA'][hds] = dict()\n",
        "    if u_dim not in history['LAMBDA'][hds]:\n",
        "      history['LAMBDA'][hds][u_dim] = dict()\n",
        "    history['LAMBDA'][hds][u_dim][k_dim]= train_and_eval(model, SAVE_PATH + f'_LAMBDA_{k_dim}kdim_{u_dim}udim_{hds}hds', verbose=2)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_17 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        3634      \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        5810      \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,204,878\n",
            "Trainable params: 1,204,878\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 8s - loss: 1.9620 - sparse_categorical_accuracy: 0.2843 - val_loss: 1.7279 - val_sparse_categorical_accuracy: 0.3728\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 6s - loss: 1.6026 - sparse_categorical_accuracy: 0.4182 - val_loss: 1.5571 - val_sparse_categorical_accuracy: 0.4527\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "196/196 - 6s - loss: 1.4504 - sparse_categorical_accuracy: 0.4824 - val_loss: 1.4233 - val_sparse_categorical_accuracy: 0.4982\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 6s - loss: 1.3470 - sparse_categorical_accuracy: 0.5203 - val_loss: 1.2914 - val_sparse_categorical_accuracy: 0.5373\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "196/196 - 6s - loss: 1.2697 - sparse_categorical_accuracy: 0.5448 - val_loss: 1.1870 - val_sparse_categorical_accuracy: 0.5774\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/50\n",
            "196/196 - 6s - loss: 1.2088 - sparse_categorical_accuracy: 0.5722 - val_loss: 1.1223 - val_sparse_categorical_accuracy: 0.6047\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "196/196 - 6s - loss: 1.1648 - sparse_categorical_accuracy: 0.5857 - val_loss: 1.0794 - val_sparse_categorical_accuracy: 0.6178\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/50\n",
            "196/196 - 6s - loss: 1.1191 - sparse_categorical_accuracy: 0.6047 - val_loss: 1.0546 - val_sparse_categorical_accuracy: 0.6250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/50\n",
            "196/196 - 6s - loss: 1.0924 - sparse_categorical_accuracy: 0.6129 - val_loss: 1.0151 - val_sparse_categorical_accuracy: 0.6426\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/50\n",
            "196/196 - 6s - loss: 1.0608 - sparse_categorical_accuracy: 0.6255 - val_loss: 0.9701 - val_sparse_categorical_accuracy: 0.6523\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/50\n",
            "196/196 - 6s - loss: 1.0263 - sparse_categorical_accuracy: 0.6378 - val_loss: 0.9759 - val_sparse_categorical_accuracy: 0.6582\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/50\n",
            "196/196 - 6s - loss: 1.0071 - sparse_categorical_accuracy: 0.6450 - val_loss: 0.9118 - val_sparse_categorical_accuracy: 0.6783\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13/50\n",
            "196/196 - 6s - loss: 0.9722 - sparse_categorical_accuracy: 0.6559 - val_loss: 0.9582 - val_sparse_categorical_accuracy: 0.6554\n",
            "Epoch 14/50\n",
            "196/196 - 6s - loss: 0.9591 - sparse_categorical_accuracy: 0.6617 - val_loss: 0.9120 - val_sparse_categorical_accuracy: 0.6782\n",
            "Epoch 15/50\n",
            "196/196 - 6s - loss: 0.9431 - sparse_categorical_accuracy: 0.6661 - val_loss: 0.8783 - val_sparse_categorical_accuracy: 0.6863\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16/50\n",
            "196/196 - 6s - loss: 0.9234 - sparse_categorical_accuracy: 0.6731 - val_loss: 0.8932 - val_sparse_categorical_accuracy: 0.6761\n",
            "Epoch 17/50\n",
            "196/196 - 6s - loss: 0.9117 - sparse_categorical_accuracy: 0.6774 - val_loss: 0.8599 - val_sparse_categorical_accuracy: 0.6955\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18/50\n",
            "196/196 - 6s - loss: 0.8904 - sparse_categorical_accuracy: 0.6841 - val_loss: 0.8506 - val_sparse_categorical_accuracy: 0.7027\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 19/50\n",
            "196/196 - 6s - loss: 0.8760 - sparse_categorical_accuracy: 0.6886 - val_loss: 0.8726 - val_sparse_categorical_accuracy: 0.6879\n",
            "Epoch 20/50\n",
            "196/196 - 6s - loss: 0.8574 - sparse_categorical_accuracy: 0.6971 - val_loss: 0.8303 - val_sparse_categorical_accuracy: 0.7053\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 21/50\n",
            "196/196 - 6s - loss: 0.8491 - sparse_categorical_accuracy: 0.6989 - val_loss: 0.8149 - val_sparse_categorical_accuracy: 0.7132\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 22/50\n",
            "196/196 - 6s - loss: 0.8334 - sparse_categorical_accuracy: 0.7046 - val_loss: 0.8232 - val_sparse_categorical_accuracy: 0.7095\n",
            "Epoch 23/50\n",
            "196/196 - 6s - loss: 0.8260 - sparse_categorical_accuracy: 0.7075 - val_loss: 0.7821 - val_sparse_categorical_accuracy: 0.7300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 24/50\n",
            "196/196 - 6s - loss: 0.8135 - sparse_categorical_accuracy: 0.7134 - val_loss: 0.7643 - val_sparse_categorical_accuracy: 0.7288\n",
            "Epoch 25/50\n",
            "196/196 - 6s - loss: 0.8038 - sparse_categorical_accuracy: 0.7149 - val_loss: 0.7705 - val_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 26/50\n",
            "196/196 - 6s - loss: 0.7887 - sparse_categorical_accuracy: 0.7202 - val_loss: 0.7666 - val_sparse_categorical_accuracy: 0.7325\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 27/50\n",
            "196/196 - 6s - loss: 0.7881 - sparse_categorical_accuracy: 0.7218 - val_loss: 0.7633 - val_sparse_categorical_accuracy: 0.7371\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 28/50\n",
            "196/196 - 6s - loss: 0.7621 - sparse_categorical_accuracy: 0.7315 - val_loss: 0.7734 - val_sparse_categorical_accuracy: 0.7336\n",
            "Epoch 29/50\n",
            "196/196 - 6s - loss: 0.7632 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.7798 - val_sparse_categorical_accuracy: 0.7307\n",
            "Epoch 30/50\n",
            "196/196 - 6s - loss: 0.7482 - sparse_categorical_accuracy: 0.7343 - val_loss: 0.7375 - val_sparse_categorical_accuracy: 0.7477\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 31/50\n",
            "196/196 - 6s - loss: 0.7400 - sparse_categorical_accuracy: 0.7396 - val_loss: 0.7669 - val_sparse_categorical_accuracy: 0.7419\n",
            "Epoch 32/50\n",
            "196/196 - 6s - loss: 0.7270 - sparse_categorical_accuracy: 0.7419 - val_loss: 0.7453 - val_sparse_categorical_accuracy: 0.7509\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 33/50\n",
            "196/196 - 6s - loss: 0.7275 - sparse_categorical_accuracy: 0.7411 - val_loss: 0.7360 - val_sparse_categorical_accuracy: 0.7484\n",
            "Epoch 34/50\n",
            "196/196 - 6s - loss: 0.7182 - sparse_categorical_accuracy: 0.7451 - val_loss: 0.7095 - val_sparse_categorical_accuracy: 0.7541\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 35/50\n",
            "196/196 - 6s - loss: 0.7139 - sparse_categorical_accuracy: 0.7482 - val_loss: 0.7062 - val_sparse_categorical_accuracy: 0.7562\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 36/50\n",
            "196/196 - 6s - loss: 0.6980 - sparse_categorical_accuracy: 0.7505 - val_loss: 0.7305 - val_sparse_categorical_accuracy: 0.7527\n",
            "Epoch 37/50\n",
            "196/196 - 6s - loss: 0.6974 - sparse_categorical_accuracy: 0.7526 - val_loss: 0.7154 - val_sparse_categorical_accuracy: 0.7518\n",
            "Epoch 38/50\n",
            "196/196 - 6s - loss: 0.6918 - sparse_categorical_accuracy: 0.7555 - val_loss: 0.7086 - val_sparse_categorical_accuracy: 0.7629\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 39/50\n",
            "196/196 - 6s - loss: 0.6787 - sparse_categorical_accuracy: 0.7579 - val_loss: 0.7038 - val_sparse_categorical_accuracy: 0.7614\n",
            "Epoch 40/50\n",
            "196/196 - 6s - loss: 0.6769 - sparse_categorical_accuracy: 0.7607 - val_loss: 0.7176 - val_sparse_categorical_accuracy: 0.7505\n",
            "Epoch 41/50\n",
            "196/196 - 6s - loss: 0.6755 - sparse_categorical_accuracy: 0.7616 - val_loss: 0.7210 - val_sparse_categorical_accuracy: 0.7634\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 42/50\n",
            "196/196 - 6s - loss: 0.6639 - sparse_categorical_accuracy: 0.7646 - val_loss: 0.7519 - val_sparse_categorical_accuracy: 0.7633\n",
            "Epoch 43/50\n",
            "196/196 - 6s - loss: 0.6565 - sparse_categorical_accuracy: 0.7685 - val_loss: 0.6900 - val_sparse_categorical_accuracy: 0.7679\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 44/50\n",
            "196/196 - 6s - loss: 0.6523 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.6897 - val_sparse_categorical_accuracy: 0.7649\n",
            "Epoch 45/50\n",
            "196/196 - 6s - loss: 0.6463 - sparse_categorical_accuracy: 0.7700 - val_loss: 0.7076 - val_sparse_categorical_accuracy: 0.7625\n",
            "Epoch 46/50\n",
            "196/196 - 6s - loss: 0.6456 - sparse_categorical_accuracy: 0.7714 - val_loss: 0.7373 - val_sparse_categorical_accuracy: 0.7584\n",
            "Epoch 47/50\n",
            "196/196 - 6s - loss: 0.6472 - sparse_categorical_accuracy: 0.7719 - val_loss: 0.6774 - val_sparse_categorical_accuracy: 0.7703\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 48/50\n",
            "196/196 - 6s - loss: 0.6362 - sparse_categorical_accuracy: 0.7756 - val_loss: 0.6989 - val_sparse_categorical_accuracy: 0.7631\n",
            "Epoch 49/50\n",
            "196/196 - 6s - loss: 0.6315 - sparse_categorical_accuracy: 0.7755 - val_loss: 0.7716 - val_sparse_categorical_accuracy: 0.7687\n",
            "Epoch 50/50\n",
            "196/196 - 6s - loss: 0.6260 - sparse_categorical_accuracy: 0.7785 - val_loss: 0.7004 - val_sparse_categorical_accuracy: 0.7715\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_96_layer_call_and_return_conditional_losses, conv2d_96_layer_call_fn, conv2d_97_layer_call_and_return_conditional_losses, conv2d_97_layer_call_fn, conv2d_98_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total training time 379.5628914833069 seconds\n",
            "Model: \"model_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_18 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        5220      \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        7524      \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,208,178\n",
            "Trainable params: 1,208,178\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 10s - loss: 1.9547 - sparse_categorical_accuracy: 0.2730 - val_loss: 1.7212 - val_sparse_categorical_accuracy: 0.3681\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 8s - loss: 1.5844 - sparse_categorical_accuracy: 0.4253 - val_loss: 1.5398 - val_sparse_categorical_accuracy: 0.4325\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "196/196 - 8s - loss: 1.4129 - sparse_categorical_accuracy: 0.4911 - val_loss: 1.5328 - val_sparse_categorical_accuracy: 0.4548\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 8s - loss: 1.3119 - sparse_categorical_accuracy: 0.5310 - val_loss: 1.2980 - val_sparse_categorical_accuracy: 0.5389\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "196/196 - 8s - loss: 1.2339 - sparse_categorical_accuracy: 0.5613 - val_loss: 1.3585 - val_sparse_categorical_accuracy: 0.5351\n",
            "Epoch 6/50\n",
            "196/196 - 8s - loss: 1.1700 - sparse_categorical_accuracy: 0.5867 - val_loss: 1.2133 - val_sparse_categorical_accuracy: 0.5702\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "196/196 - 8s - loss: 1.1115 - sparse_categorical_accuracy: 0.6057 - val_loss: 1.0702 - val_sparse_categorical_accuracy: 0.6193\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/50\n",
            "196/196 - 8s - loss: 1.0765 - sparse_categorical_accuracy: 0.6152 - val_loss: 1.1661 - val_sparse_categorical_accuracy: 0.5970\n",
            "Epoch 9/50\n",
            "196/196 - 7s - loss: 1.0389 - sparse_categorical_accuracy: 0.6316 - val_loss: 1.0306 - val_sparse_categorical_accuracy: 0.6367\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/50\n",
            "196/196 - 8s - loss: 1.0010 - sparse_categorical_accuracy: 0.6447 - val_loss: 1.1671 - val_sparse_categorical_accuracy: 0.6065\n",
            "Epoch 11/50\n",
            "196/196 - 7s - loss: 0.9756 - sparse_categorical_accuracy: 0.6549 - val_loss: 0.9964 - val_sparse_categorical_accuracy: 0.6497\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/50\n",
            "196/196 - 8s - loss: 0.9468 - sparse_categorical_accuracy: 0.6650 - val_loss: 0.9813 - val_sparse_categorical_accuracy: 0.6595\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13/50\n",
            "196/196 - 8s - loss: 0.9246 - sparse_categorical_accuracy: 0.6707 - val_loss: 0.9047 - val_sparse_categorical_accuracy: 0.6858\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/50\n",
            "196/196 - 8s - loss: 0.9044 - sparse_categorical_accuracy: 0.6816 - val_loss: 0.9315 - val_sparse_categorical_accuracy: 0.6723\n",
            "Epoch 15/50\n",
            "196/196 - 7s - loss: 0.8937 - sparse_categorical_accuracy: 0.6852 - val_loss: 0.9264 - val_sparse_categorical_accuracy: 0.6805\n",
            "Epoch 16/50\n",
            "196/196 - 7s - loss: 0.8720 - sparse_categorical_accuracy: 0.6933 - val_loss: 0.8709 - val_sparse_categorical_accuracy: 0.6954\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 17/50\n",
            "196/196 - 7s - loss: 0.8516 - sparse_categorical_accuracy: 0.6993 - val_loss: 0.8302 - val_sparse_categorical_accuracy: 0.7108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18/50\n",
            "196/196 - 7s - loss: 0.8334 - sparse_categorical_accuracy: 0.7077 - val_loss: 0.8821 - val_sparse_categorical_accuracy: 0.6955\n",
            "Epoch 19/50\n",
            "196/196 - 7s - loss: 0.8318 - sparse_categorical_accuracy: 0.7060 - val_loss: 0.8194 - val_sparse_categorical_accuracy: 0.7154\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20/50\n",
            "196/196 - 8s - loss: 0.8017 - sparse_categorical_accuracy: 0.7160 - val_loss: 0.8194 - val_sparse_categorical_accuracy: 0.7223\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 21/50\n",
            "196/196 - 8s - loss: 0.7964 - sparse_categorical_accuracy: 0.7205 - val_loss: 0.8272 - val_sparse_categorical_accuracy: 0.7157\n",
            "Epoch 22/50\n",
            "196/196 - 7s - loss: 0.7814 - sparse_categorical_accuracy: 0.7263 - val_loss: 0.8158 - val_sparse_categorical_accuracy: 0.7227\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 23/50\n",
            "196/196 - 8s - loss: 0.7772 - sparse_categorical_accuracy: 0.7261 - val_loss: 0.8196 - val_sparse_categorical_accuracy: 0.7211\n",
            "Epoch 24/50\n",
            "196/196 - 7s - loss: 0.7593 - sparse_categorical_accuracy: 0.7324 - val_loss: 0.7529 - val_sparse_categorical_accuracy: 0.7432\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 25/50\n",
            "196/196 - 8s - loss: 0.7419 - sparse_categorical_accuracy: 0.7379 - val_loss: 0.7531 - val_sparse_categorical_accuracy: 0.7394\n",
            "Epoch 26/50\n",
            "196/196 - 7s - loss: 0.7381 - sparse_categorical_accuracy: 0.7377 - val_loss: 0.7433 - val_sparse_categorical_accuracy: 0.7434\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 27/50\n",
            "196/196 - 8s - loss: 0.7170 - sparse_categorical_accuracy: 0.7483 - val_loss: 0.8014 - val_sparse_categorical_accuracy: 0.7394\n",
            "Epoch 28/50\n",
            "196/196 - 7s - loss: 0.7167 - sparse_categorical_accuracy: 0.7470 - val_loss: 0.7609 - val_sparse_categorical_accuracy: 0.7436\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 29/50\n",
            "196/196 - 8s - loss: 0.7052 - sparse_categorical_accuracy: 0.7498 - val_loss: 0.7452 - val_sparse_categorical_accuracy: 0.7508\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 30/50\n",
            "196/196 - 7s - loss: 0.6947 - sparse_categorical_accuracy: 0.7552 - val_loss: 0.7929 - val_sparse_categorical_accuracy: 0.7379\n",
            "Epoch 31/50\n",
            "196/196 - 7s - loss: 0.6970 - sparse_categorical_accuracy: 0.7546 - val_loss: 0.7089 - val_sparse_categorical_accuracy: 0.7595\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 32/50\n",
            "196/196 - 7s - loss: 0.6843 - sparse_categorical_accuracy: 0.7589 - val_loss: 0.8712 - val_sparse_categorical_accuracy: 0.7258\n",
            "Epoch 33/50\n",
            "196/196 - 7s - loss: 0.6731 - sparse_categorical_accuracy: 0.7619 - val_loss: 0.8633 - val_sparse_categorical_accuracy: 0.7403\n",
            "Epoch 34/50\n",
            "196/196 - 7s - loss: 0.6690 - sparse_categorical_accuracy: 0.7639 - val_loss: 0.8076 - val_sparse_categorical_accuracy: 0.7449\n",
            "Epoch 35/50\n",
            "196/196 - 7s - loss: 0.6587 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.7741 - val_sparse_categorical_accuracy: 0.7463\n",
            "Epoch 36/50\n",
            "196/196 - 7s - loss: 0.6479 - sparse_categorical_accuracy: 0.7700 - val_loss: 0.7388 - val_sparse_categorical_accuracy: 0.7585\n",
            "Epoch 37/50\n",
            "196/196 - 7s - loss: 0.6425 - sparse_categorical_accuracy: 0.7720 - val_loss: 0.8271 - val_sparse_categorical_accuracy: 0.7394\n",
            "Epoch 38/50\n",
            "196/196 - 7s - loss: 0.6411 - sparse_categorical_accuracy: 0.7738 - val_loss: 0.8674 - val_sparse_categorical_accuracy: 0.7501\n",
            "Epoch 39/50\n",
            "196/196 - 7s - loss: 0.6343 - sparse_categorical_accuracy: 0.7745 - val_loss: 0.7326 - val_sparse_categorical_accuracy: 0.7655\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 40/50\n",
            "196/196 - 8s - loss: 0.6260 - sparse_categorical_accuracy: 0.7772 - val_loss: 0.7395 - val_sparse_categorical_accuracy: 0.7621\n",
            "Epoch 41/50\n",
            "196/196 - 7s - loss: 0.6178 - sparse_categorical_accuracy: 0.7807 - val_loss: 0.7988 - val_sparse_categorical_accuracy: 0.7607\n",
            "Epoch 42/50\n",
            "196/196 - 7s - loss: 0.6097 - sparse_categorical_accuracy: 0.7837 - val_loss: 0.8074 - val_sparse_categorical_accuracy: 0.7592\n",
            "Epoch 43/50\n",
            "196/196 - 7s - loss: 0.6084 - sparse_categorical_accuracy: 0.7855 - val_loss: 0.7751 - val_sparse_categorical_accuracy: 0.7571\n",
            "Epoch 44/50\n",
            "196/196 - 7s - loss: 0.6052 - sparse_categorical_accuracy: 0.7831 - val_loss: 0.8144 - val_sparse_categorical_accuracy: 0.7605\n",
            "Epoch 45/50\n",
            "196/196 - 7s - loss: 0.6021 - sparse_categorical_accuracy: 0.7870 - val_loss: 0.7864 - val_sparse_categorical_accuracy: 0.7614\n",
            "Epoch 46/50\n",
            "196/196 - 7s - loss: 0.5930 - sparse_categorical_accuracy: 0.7900 - val_loss: 0.7261 - val_sparse_categorical_accuracy: 0.7760\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 47/50\n",
            "196/196 - 8s - loss: 0.5860 - sparse_categorical_accuracy: 0.7917 - val_loss: 0.7240 - val_sparse_categorical_accuracy: 0.7704\n",
            "Epoch 48/50\n",
            "196/196 - 7s - loss: 0.5888 - sparse_categorical_accuracy: 0.7905 - val_loss: 0.7005 - val_sparse_categorical_accuracy: 0.7729\n",
            "Epoch 49/50\n",
            "196/196 - 7s - loss: 0.5760 - sparse_categorical_accuracy: 0.7942 - val_loss: 0.7131 - val_sparse_categorical_accuracy: 0.7823\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_102_layer_call_and_return_conditional_losses, conv2d_102_layer_call_fn, conv2d_103_layer_call_and_return_conditional_losses, conv2d_103_layer_call_fn, conv2d_104_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 50/50\n",
            "196/196 - 8s - loss: 0.5746 - sparse_categorical_accuracy: 0.7958 - val_loss: 0.6784 - val_sparse_categorical_accuracy: 0.7815\n",
            "Total training time 444.45463705062866 seconds\n",
            "Model: \"model_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_19 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        8392      \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        10952     \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,214,778\n",
            "Trainable params: 1,214,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 11s - loss: 1.9536 - sparse_categorical_accuracy: 0.2715 - val_loss: 1.8200 - val_sparse_categorical_accuracy: 0.3392\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 9s - loss: 1.5449 - sparse_categorical_accuracy: 0.4414 - val_loss: 1.5843 - val_sparse_categorical_accuracy: 0.4282\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "196/196 - 9s - loss: 1.3802 - sparse_categorical_accuracy: 0.5028 - val_loss: 1.4225 - val_sparse_categorical_accuracy: 0.4862\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 9s - loss: 1.2487 - sparse_categorical_accuracy: 0.5521 - val_loss: 1.4196 - val_sparse_categorical_accuracy: 0.5133\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "196/196 - 9s - loss: 1.1687 - sparse_categorical_accuracy: 0.5846 - val_loss: 1.2846 - val_sparse_categorical_accuracy: 0.5613\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/50\n",
            "196/196 - 9s - loss: 1.1042 - sparse_categorical_accuracy: 0.6098 - val_loss: 1.2880 - val_sparse_categorical_accuracy: 0.5600\n",
            "Epoch 7/50\n",
            "196/196 - 9s - loss: 1.0580 - sparse_categorical_accuracy: 0.6278 - val_loss: 1.2345 - val_sparse_categorical_accuracy: 0.5959\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/50\n",
            "196/196 - 9s - loss: 1.0151 - sparse_categorical_accuracy: 0.6404 - val_loss: 1.0344 - val_sparse_categorical_accuracy: 0.6438\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/50\n",
            "196/196 - 9s - loss: 0.9724 - sparse_categorical_accuracy: 0.6566 - val_loss: 1.1654 - val_sparse_categorical_accuracy: 0.6200\n",
            "Epoch 10/50\n",
            "196/196 - 9s - loss: 0.9429 - sparse_categorical_accuracy: 0.6669 - val_loss: 1.0358 - val_sparse_categorical_accuracy: 0.6550\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/50\n",
            "196/196 - 9s - loss: 0.9166 - sparse_categorical_accuracy: 0.6755 - val_loss: 1.0352 - val_sparse_categorical_accuracy: 0.6539\n",
            "Epoch 12/50\n",
            "196/196 - 9s - loss: 0.8986 - sparse_categorical_accuracy: 0.6832 - val_loss: 0.9190 - val_sparse_categorical_accuracy: 0.6866\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13/50\n",
            "196/196 - 9s - loss: 0.8787 - sparse_categorical_accuracy: 0.6899 - val_loss: 0.8779 - val_sparse_categorical_accuracy: 0.6951\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/50\n",
            "196/196 - 9s - loss: 0.8590 - sparse_categorical_accuracy: 0.6961 - val_loss: 0.8832 - val_sparse_categorical_accuracy: 0.6975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15/50\n",
            "196/196 - 9s - loss: 0.8355 - sparse_categorical_accuracy: 0.7079 - val_loss: 0.8589 - val_sparse_categorical_accuracy: 0.7083\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16/50\n",
            "196/196 - 9s - loss: 0.8225 - sparse_categorical_accuracy: 0.7111 - val_loss: 0.9268 - val_sparse_categorical_accuracy: 0.7075\n",
            "Epoch 17/50\n",
            "196/196 - 9s - loss: 0.7965 - sparse_categorical_accuracy: 0.7190 - val_loss: 0.8455 - val_sparse_categorical_accuracy: 0.7106\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18/50\n",
            "196/196 - 9s - loss: 0.7861 - sparse_categorical_accuracy: 0.7230 - val_loss: 0.8895 - val_sparse_categorical_accuracy: 0.7152\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 19/50\n",
            "196/196 - 9s - loss: 0.7683 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.8697 - val_sparse_categorical_accuracy: 0.7252\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20/50\n",
            "196/196 - 9s - loss: 0.7547 - sparse_categorical_accuracy: 0.7340 - val_loss: 0.8294 - val_sparse_categorical_accuracy: 0.7229\n",
            "Epoch 21/50\n",
            "196/196 - 9s - loss: 0.7454 - sparse_categorical_accuracy: 0.7373 - val_loss: 0.8008 - val_sparse_categorical_accuracy: 0.7359\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 22/50\n",
            "196/196 - 9s - loss: 0.7286 - sparse_categorical_accuracy: 0.7432 - val_loss: 0.8964 - val_sparse_categorical_accuracy: 0.7319\n",
            "Epoch 23/50\n",
            "196/196 - 9s - loss: 0.7214 - sparse_categorical_accuracy: 0.7451 - val_loss: 0.8173 - val_sparse_categorical_accuracy: 0.7355\n",
            "Epoch 24/50\n",
            "196/196 - 9s - loss: 0.7096 - sparse_categorical_accuracy: 0.7498 - val_loss: 0.8128 - val_sparse_categorical_accuracy: 0.7336\n",
            "Epoch 25/50\n",
            "196/196 - 9s - loss: 0.6984 - sparse_categorical_accuracy: 0.7539 - val_loss: 0.7973 - val_sparse_categorical_accuracy: 0.7434\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 26/50\n",
            "196/196 - 9s - loss: 0.6831 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.8354 - val_sparse_categorical_accuracy: 0.7335\n",
            "Epoch 27/50\n",
            "196/196 - 9s - loss: 0.6779 - sparse_categorical_accuracy: 0.7616 - val_loss: 0.8012 - val_sparse_categorical_accuracy: 0.7386\n",
            "Epoch 28/50\n",
            "196/196 - 9s - loss: 0.6700 - sparse_categorical_accuracy: 0.7622 - val_loss: 0.7555 - val_sparse_categorical_accuracy: 0.7520\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 29/50\n",
            "196/196 - 9s - loss: 0.6615 - sparse_categorical_accuracy: 0.7687 - val_loss: 0.7657 - val_sparse_categorical_accuracy: 0.7569\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 30/50\n",
            "196/196 - 9s - loss: 0.6529 - sparse_categorical_accuracy: 0.7703 - val_loss: 0.8147 - val_sparse_categorical_accuracy: 0.7433\n",
            "Epoch 31/50\n",
            "196/196 - 9s - loss: 0.6446 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.8766 - val_sparse_categorical_accuracy: 0.7315\n",
            "Epoch 32/50\n",
            "196/196 - 9s - loss: 0.6397 - sparse_categorical_accuracy: 0.7737 - val_loss: 0.8240 - val_sparse_categorical_accuracy: 0.7510\n",
            "Epoch 33/50\n",
            "196/196 - 9s - loss: 0.6304 - sparse_categorical_accuracy: 0.7784 - val_loss: 0.7689 - val_sparse_categorical_accuracy: 0.7540\n",
            "Epoch 34/50\n",
            "196/196 - 9s - loss: 0.6268 - sparse_categorical_accuracy: 0.7778 - val_loss: 0.8138 - val_sparse_categorical_accuracy: 0.7467\n",
            "Epoch 35/50\n",
            "196/196 - 9s - loss: 0.6176 - sparse_categorical_accuracy: 0.7788 - val_loss: 0.8214 - val_sparse_categorical_accuracy: 0.7549\n",
            "Epoch 36/50\n",
            "196/196 - 9s - loss: 0.6107 - sparse_categorical_accuracy: 0.7850 - val_loss: 0.7452 - val_sparse_categorical_accuracy: 0.7534\n",
            "Epoch 37/50\n",
            "196/196 - 9s - loss: 0.6088 - sparse_categorical_accuracy: 0.7830 - val_loss: 0.7587 - val_sparse_categorical_accuracy: 0.7600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 38/50\n",
            "196/196 - 9s - loss: 0.5910 - sparse_categorical_accuracy: 0.7917 - val_loss: 0.8063 - val_sparse_categorical_accuracy: 0.7496\n",
            "Epoch 39/50\n",
            "196/196 - 9s - loss: 0.5865 - sparse_categorical_accuracy: 0.7934 - val_loss: 0.6966 - val_sparse_categorical_accuracy: 0.7710\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 40/50\n",
            "196/196 - 9s - loss: 0.5841 - sparse_categorical_accuracy: 0.7919 - val_loss: 0.7624 - val_sparse_categorical_accuracy: 0.7590\n",
            "Epoch 41/50\n",
            "196/196 - 9s - loss: 0.5743 - sparse_categorical_accuracy: 0.7963 - val_loss: 0.8255 - val_sparse_categorical_accuracy: 0.7613\n",
            "Epoch 42/50\n",
            "196/196 - 9s - loss: 0.5721 - sparse_categorical_accuracy: 0.7984 - val_loss: 0.7421 - val_sparse_categorical_accuracy: 0.7595\n",
            "Epoch 43/50\n",
            "196/196 - 9s - loss: 0.5733 - sparse_categorical_accuracy: 0.7963 - val_loss: 0.7388 - val_sparse_categorical_accuracy: 0.7745\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_108_layer_call_and_return_conditional_losses, conv2d_108_layer_call_fn, conv2d_109_layer_call_and_return_conditional_losses, conv2d_109_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 44/50\n",
            "196/196 - 9s - loss: 0.5572 - sparse_categorical_accuracy: 0.8031 - val_loss: 0.7584 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 45/50\n",
            "196/196 - 9s - loss: 0.5625 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.9101 - val_sparse_categorical_accuracy: 0.7541\n",
            "Epoch 46/50\n",
            "196/196 - 9s - loss: 0.5517 - sparse_categorical_accuracy: 0.8044 - val_loss: 0.9631 - val_sparse_categorical_accuracy: 0.7419\n",
            "Epoch 47/50\n",
            "196/196 - 9s - loss: 0.5496 - sparse_categorical_accuracy: 0.8053 - val_loss: 0.8694 - val_sparse_categorical_accuracy: 0.7637\n",
            "Epoch 48/50\n",
            "196/196 - 9s - loss: 0.5498 - sparse_categorical_accuracy: 0.8081 - val_loss: 0.7117 - val_sparse_categorical_accuracy: 0.7671\n",
            "Epoch 49/50\n",
            "196/196 - 9s - loss: 0.5362 - sparse_categorical_accuracy: 0.8091 - val_loss: 0.8990 - val_sparse_categorical_accuracy: 0.7574\n",
            "Epoch 50/50\n",
            "196/196 - 9s - loss: 0.5377 - sparse_categorical_accuracy: 0.8095 - val_loss: 0.7943 - val_sparse_categorical_accuracy: 0.7742\n",
            "Total training time 509.83647298812866 seconds\n",
            "Model: \"model_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_20 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        14736     \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        17808     \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,227,978\n",
            "Trainable params: 1,227,978\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 14s - loss: 1.9496 - sparse_categorical_accuracy: 0.2776 - val_loss: 1.7729 - val_sparse_categorical_accuracy: 0.3383\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 12s - loss: 1.5479 - sparse_categorical_accuracy: 0.4334 - val_loss: 1.5092 - val_sparse_categorical_accuracy: 0.4538\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "196/196 - 12s - loss: 1.3583 - sparse_categorical_accuracy: 0.5130 - val_loss: 1.4378 - val_sparse_categorical_accuracy: 0.5038\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 12s - loss: 1.2183 - sparse_categorical_accuracy: 0.5649 - val_loss: 1.1682 - val_sparse_categorical_accuracy: 0.5761\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "196/196 - 12s - loss: 1.1352 - sparse_categorical_accuracy: 0.5986 - val_loss: 1.3162 - val_sparse_categorical_accuracy: 0.5721\n",
            "Epoch 6/50\n",
            "196/196 - 12s - loss: 1.0668 - sparse_categorical_accuracy: 0.6244 - val_loss: 1.2277 - val_sparse_categorical_accuracy: 0.5818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "196/196 - 12s - loss: 1.0197 - sparse_categorical_accuracy: 0.6414 - val_loss: 1.1641 - val_sparse_categorical_accuracy: 0.6192\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/50\n",
            "196/196 - 12s - loss: 0.9808 - sparse_categorical_accuracy: 0.6550 - val_loss: 0.9055 - val_sparse_categorical_accuracy: 0.6813\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/50\n",
            "196/196 - 12s - loss: 0.9361 - sparse_categorical_accuracy: 0.6720 - val_loss: 0.9012 - val_sparse_categorical_accuracy: 0.6874\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/50\n",
            "196/196 - 12s - loss: 0.9017 - sparse_categorical_accuracy: 0.6840 - val_loss: 0.8657 - val_sparse_categorical_accuracy: 0.6996\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/50\n",
            "196/196 - 12s - loss: 0.8915 - sparse_categorical_accuracy: 0.6904 - val_loss: 0.9348 - val_sparse_categorical_accuracy: 0.6948\n",
            "Epoch 12/50\n",
            "196/196 - 12s - loss: 0.8589 - sparse_categorical_accuracy: 0.7000 - val_loss: 1.1032 - val_sparse_categorical_accuracy: 0.6733\n",
            "Epoch 13/50\n",
            "196/196 - 12s - loss: 0.8345 - sparse_categorical_accuracy: 0.7067 - val_loss: 0.9325 - val_sparse_categorical_accuracy: 0.6920\n",
            "Epoch 14/50\n",
            "196/196 - 12s - loss: 0.8158 - sparse_categorical_accuracy: 0.7139 - val_loss: 0.8243 - val_sparse_categorical_accuracy: 0.7282\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15/50\n",
            "196/196 - 12s - loss: 0.8067 - sparse_categorical_accuracy: 0.7160 - val_loss: 0.8449 - val_sparse_categorical_accuracy: 0.7130\n",
            "Epoch 16/50\n",
            "196/196 - 12s - loss: 0.7874 - sparse_categorical_accuracy: 0.7241 - val_loss: 0.8704 - val_sparse_categorical_accuracy: 0.7094\n",
            "Epoch 17/50\n",
            "196/196 - 12s - loss: 0.7703 - sparse_categorical_accuracy: 0.7298 - val_loss: 0.9046 - val_sparse_categorical_accuracy: 0.7141\n",
            "Epoch 18/50\n",
            "196/196 - 12s - loss: 0.7596 - sparse_categorical_accuracy: 0.7335 - val_loss: 0.9622 - val_sparse_categorical_accuracy: 0.7228\n",
            "Epoch 19/50\n",
            "196/196 - 12s - loss: 0.7370 - sparse_categorical_accuracy: 0.7425 - val_loss: 0.7880 - val_sparse_categorical_accuracy: 0.7322\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20/50\n",
            "196/196 - 12s - loss: 0.7355 - sparse_categorical_accuracy: 0.7416 - val_loss: 0.8375 - val_sparse_categorical_accuracy: 0.7313\n",
            "Epoch 21/50\n",
            "196/196 - 12s - loss: 0.7187 - sparse_categorical_accuracy: 0.7503 - val_loss: 0.7704 - val_sparse_categorical_accuracy: 0.7400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 22/50\n",
            "196/196 - 12s - loss: 0.7128 - sparse_categorical_accuracy: 0.7476 - val_loss: 0.7679 - val_sparse_categorical_accuracy: 0.7419\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 23/50\n",
            "196/196 - 12s - loss: 0.6961 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.8571 - val_sparse_categorical_accuracy: 0.7383\n",
            "Epoch 24/50\n",
            "196/196 - 12s - loss: 0.6866 - sparse_categorical_accuracy: 0.7593 - val_loss: 0.8074 - val_sparse_categorical_accuracy: 0.7457\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 25/50\n",
            "196/196 - 12s - loss: 0.6770 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.9025 - val_sparse_categorical_accuracy: 0.7375\n",
            "Epoch 26/50\n",
            "196/196 - 12s - loss: 0.6727 - sparse_categorical_accuracy: 0.7638 - val_loss: 0.7837 - val_sparse_categorical_accuracy: 0.7470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 27/50\n",
            "196/196 - 12s - loss: 0.6544 - sparse_categorical_accuracy: 0.7715 - val_loss: 0.8061 - val_sparse_categorical_accuracy: 0.7467\n",
            "Epoch 28/50\n",
            "196/196 - 12s - loss: 0.6534 - sparse_categorical_accuracy: 0.7710 - val_loss: 0.7728 - val_sparse_categorical_accuracy: 0.7602\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 29/50\n",
            "196/196 - 12s - loss: 0.6417 - sparse_categorical_accuracy: 0.7740 - val_loss: 0.7871 - val_sparse_categorical_accuracy: 0.7484\n",
            "Epoch 30/50\n",
            "196/196 - 12s - loss: 0.6289 - sparse_categorical_accuracy: 0.7797 - val_loss: 0.8118 - val_sparse_categorical_accuracy: 0.7549\n",
            "Epoch 31/50\n",
            "196/196 - 12s - loss: 0.6272 - sparse_categorical_accuracy: 0.7805 - val_loss: 0.9207 - val_sparse_categorical_accuracy: 0.7414\n",
            "Epoch 32/50\n",
            "196/196 - 12s - loss: 0.6173 - sparse_categorical_accuracy: 0.7820 - val_loss: 0.7186 - val_sparse_categorical_accuracy: 0.7599\n",
            "Epoch 33/50\n",
            "196/196 - 12s - loss: 0.6179 - sparse_categorical_accuracy: 0.7816 - val_loss: 0.7567 - val_sparse_categorical_accuracy: 0.7568\n",
            "Epoch 34/50\n",
            "196/196 - 12s - loss: 0.6051 - sparse_categorical_accuracy: 0.7873 - val_loss: 0.8044 - val_sparse_categorical_accuracy: 0.7557\n",
            "Epoch 35/50\n",
            "196/196 - 12s - loss: 0.6068 - sparse_categorical_accuracy: 0.7884 - val_loss: 0.7492 - val_sparse_categorical_accuracy: 0.7591\n",
            "Epoch 36/50\n",
            "196/196 - 12s - loss: 0.5852 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.8659 - val_sparse_categorical_accuracy: 0.7378\n",
            "Epoch 37/50\n",
            "196/196 - 12s - loss: 0.5819 - sparse_categorical_accuracy: 0.7944 - val_loss: 0.8331 - val_sparse_categorical_accuracy: 0.7593\n",
            "Epoch 38/50\n",
            "196/196 - 12s - loss: 0.5756 - sparse_categorical_accuracy: 0.7980 - val_loss: 0.8291 - val_sparse_categorical_accuracy: 0.7573\n",
            "Epoch 39/50\n",
            "196/196 - 12s - loss: 0.5705 - sparse_categorical_accuracy: 0.7988 - val_loss: 0.7324 - val_sparse_categorical_accuracy: 0.7647\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 40/50\n",
            "196/196 - 12s - loss: 0.5726 - sparse_categorical_accuracy: 0.7992 - val_loss: 0.9229 - val_sparse_categorical_accuracy: 0.7550\n",
            "Epoch 41/50\n",
            "196/196 - 12s - loss: 0.5565 - sparse_categorical_accuracy: 0.8045 - val_loss: 0.8286 - val_sparse_categorical_accuracy: 0.7696\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 42/50\n",
            "196/196 - 12s - loss: 0.5558 - sparse_categorical_accuracy: 0.8040 - val_loss: 0.7972 - val_sparse_categorical_accuracy: 0.7625\n",
            "Epoch 43/50\n",
            "196/196 - 12s - loss: 0.5513 - sparse_categorical_accuracy: 0.8064 - val_loss: 1.0238 - val_sparse_categorical_accuracy: 0.7603\n",
            "Epoch 44/50\n",
            "196/196 - 12s - loss: 0.5480 - sparse_categorical_accuracy: 0.8078 - val_loss: 0.8387 - val_sparse_categorical_accuracy: 0.7631\n",
            "Epoch 45/50\n",
            "196/196 - 12s - loss: 0.5425 - sparse_categorical_accuracy: 0.8080 - val_loss: 0.8797 - val_sparse_categorical_accuracy: 0.7670\n",
            "Epoch 46/50\n",
            "196/196 - 12s - loss: 0.5383 - sparse_categorical_accuracy: 0.8107 - val_loss: 0.7236 - val_sparse_categorical_accuracy: 0.7638\n",
            "Epoch 47/50\n",
            "196/196 - 12s - loss: 0.5294 - sparse_categorical_accuracy: 0.8158 - val_loss: 0.8245 - val_sparse_categorical_accuracy: 0.7679\n",
            "Epoch 48/50\n",
            "196/196 - 12s - loss: 0.5348 - sparse_categorical_accuracy: 0.8133 - val_loss: 0.7802 - val_sparse_categorical_accuracy: 0.7690\n",
            "Epoch 49/50\n",
            "196/196 - 12s - loss: 0.5193 - sparse_categorical_accuracy: 0.8177 - val_loss: 0.7752 - val_sparse_categorical_accuracy: 0.7696\n",
            "Epoch 50/50\n",
            "196/196 - 12s - loss: 0.5208 - sparse_categorical_accuracy: 0.8170 - val_loss: 0.8647 - val_sparse_categorical_accuracy: 0.7703\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_114_layer_call_and_return_conditional_losses, conv2d_114_layer_call_fn, conv2d_115_layer_call_and_return_conditional_losses, conv2d_115_layer_call_fn, conv2d_116_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_2udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total training time 639.891987323761 seconds\n",
            "Model: \"model_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_21 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        7204      \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        11492     \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,214,130\n",
            "Trainable params: 1,214,130\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 10s - loss: 1.9385 - sparse_categorical_accuracy: 0.2928 - val_loss: 1.6645 - val_sparse_categorical_accuracy: 0.4117\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 7s - loss: 1.5696 - sparse_categorical_accuracy: 0.4348 - val_loss: 1.4628 - val_sparse_categorical_accuracy: 0.4502\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "196/196 - 8s - loss: 1.4298 - sparse_categorical_accuracy: 0.4892 - val_loss: 1.4400 - val_sparse_categorical_accuracy: 0.4792\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 8s - loss: 1.3445 - sparse_categorical_accuracy: 0.5216 - val_loss: 1.2515 - val_sparse_categorical_accuracy: 0.5530\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "196/196 - 7s - loss: 1.2650 - sparse_categorical_accuracy: 0.5537 - val_loss: 1.2557 - val_sparse_categorical_accuracy: 0.5704\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/50\n",
            "196/196 - 7s - loss: 1.1989 - sparse_categorical_accuracy: 0.5748 - val_loss: 1.1397 - val_sparse_categorical_accuracy: 0.5911\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "196/196 - 7s - loss: 1.1403 - sparse_categorical_accuracy: 0.5960 - val_loss: 1.0357 - val_sparse_categorical_accuracy: 0.6348\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/50\n",
            "196/196 - 7s - loss: 1.1020 - sparse_categorical_accuracy: 0.6102 - val_loss: 1.0909 - val_sparse_categorical_accuracy: 0.6201\n",
            "Epoch 9/50\n",
            "196/196 - 7s - loss: 1.0550 - sparse_categorical_accuracy: 0.6277 - val_loss: 0.9717 - val_sparse_categorical_accuracy: 0.6643\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/50\n",
            "196/196 - 7s - loss: 1.0187 - sparse_categorical_accuracy: 0.6406 - val_loss: 0.9816 - val_sparse_categorical_accuracy: 0.6597\n",
            "Epoch 11/50\n",
            "196/196 - 7s - loss: 0.9829 - sparse_categorical_accuracy: 0.6531 - val_loss: 0.9524 - val_sparse_categorical_accuracy: 0.6676\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/50\n",
            "196/196 - 7s - loss: 0.9584 - sparse_categorical_accuracy: 0.6661 - val_loss: 0.9149 - val_sparse_categorical_accuracy: 0.6816\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13/50\n",
            "196/196 - 7s - loss: 0.9279 - sparse_categorical_accuracy: 0.6748 - val_loss: 0.8839 - val_sparse_categorical_accuracy: 0.6901\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/50\n",
            "196/196 - 7s - loss: 0.9089 - sparse_categorical_accuracy: 0.6796 - val_loss: 0.9067 - val_sparse_categorical_accuracy: 0.6887\n",
            "Epoch 15/50\n",
            "196/196 - 7s - loss: 0.8768 - sparse_categorical_accuracy: 0.6917 - val_loss: 0.8374 - val_sparse_categorical_accuracy: 0.7059\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16/50\n",
            "196/196 - 7s - loss: 0.8532 - sparse_categorical_accuracy: 0.7022 - val_loss: 0.8181 - val_sparse_categorical_accuracy: 0.7144\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 17/50\n",
            "196/196 - 7s - loss: 0.8383 - sparse_categorical_accuracy: 0.7073 - val_loss: 0.8119 - val_sparse_categorical_accuracy: 0.7166\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18/50\n",
            "196/196 - 7s - loss: 0.8205 - sparse_categorical_accuracy: 0.7113 - val_loss: 0.8314 - val_sparse_categorical_accuracy: 0.7161\n",
            "Epoch 19/50\n",
            "196/196 - 7s - loss: 0.8106 - sparse_categorical_accuracy: 0.7174 - val_loss: 0.8104 - val_sparse_categorical_accuracy: 0.7207\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20/50\n",
            "196/196 - 7s - loss: 0.7924 - sparse_categorical_accuracy: 0.7192 - val_loss: 0.7742 - val_sparse_categorical_accuracy: 0.7340\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 21/50\n",
            "196/196 - 7s - loss: 0.7766 - sparse_categorical_accuracy: 0.7272 - val_loss: 0.7927 - val_sparse_categorical_accuracy: 0.7297\n",
            "Epoch 22/50\n",
            "196/196 - 7s - loss: 0.7617 - sparse_categorical_accuracy: 0.7320 - val_loss: 0.7943 - val_sparse_categorical_accuracy: 0.7335\n",
            "Epoch 23/50\n",
            "196/196 - 7s - loss: 0.7571 - sparse_categorical_accuracy: 0.7333 - val_loss: 0.8154 - val_sparse_categorical_accuracy: 0.7362\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 24/50\n",
            "196/196 - 7s - loss: 0.7334 - sparse_categorical_accuracy: 0.7423 - val_loss: 0.7528 - val_sparse_categorical_accuracy: 0.7438\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 25/50\n",
            "196/196 - 7s - loss: 0.7316 - sparse_categorical_accuracy: 0.7419 - val_loss: 0.7820 - val_sparse_categorical_accuracy: 0.7355\n",
            "Epoch 26/50\n",
            "196/196 - 7s - loss: 0.7230 - sparse_categorical_accuracy: 0.7459 - val_loss: 0.7559 - val_sparse_categorical_accuracy: 0.7383\n",
            "Epoch 27/50\n",
            "196/196 - 7s - loss: 0.7120 - sparse_categorical_accuracy: 0.7501 - val_loss: 0.7601 - val_sparse_categorical_accuracy: 0.7433\n",
            "Epoch 28/50\n",
            "196/196 - 7s - loss: 0.6978 - sparse_categorical_accuracy: 0.7537 - val_loss: 0.8019 - val_sparse_categorical_accuracy: 0.7458\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 29/50\n",
            "196/196 - 7s - loss: 0.6894 - sparse_categorical_accuracy: 0.7572 - val_loss: 0.7256 - val_sparse_categorical_accuracy: 0.7524\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 30/50\n",
            "196/196 - 7s - loss: 0.6826 - sparse_categorical_accuracy: 0.7583 - val_loss: 0.7945 - val_sparse_categorical_accuracy: 0.7496\n",
            "Epoch 31/50\n",
            "196/196 - 7s - loss: 0.6859 - sparse_categorical_accuracy: 0.7572 - val_loss: 0.7093 - val_sparse_categorical_accuracy: 0.7635\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 32/50\n",
            "196/196 - 7s - loss: 0.6699 - sparse_categorical_accuracy: 0.7648 - val_loss: 0.7433 - val_sparse_categorical_accuracy: 0.7575\n",
            "Epoch 33/50\n",
            "196/196 - 7s - loss: 0.6617 - sparse_categorical_accuracy: 0.7656 - val_loss: 0.7299 - val_sparse_categorical_accuracy: 0.7562\n",
            "Epoch 34/50\n",
            "196/196 - 7s - loss: 0.6463 - sparse_categorical_accuracy: 0.7715 - val_loss: 0.7790 - val_sparse_categorical_accuracy: 0.7584\n",
            "Epoch 35/50\n",
            "196/196 - 7s - loss: 0.6480 - sparse_categorical_accuracy: 0.7699 - val_loss: 0.7421 - val_sparse_categorical_accuracy: 0.7640\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 36/50\n",
            "196/196 - 7s - loss: 0.6410 - sparse_categorical_accuracy: 0.7719 - val_loss: 0.7576 - val_sparse_categorical_accuracy: 0.7508\n",
            "Epoch 37/50\n",
            "196/196 - 7s - loss: 0.6292 - sparse_categorical_accuracy: 0.7781 - val_loss: 0.7427 - val_sparse_categorical_accuracy: 0.7536\n",
            "Epoch 38/50\n",
            "196/196 - 7s - loss: 0.6245 - sparse_categorical_accuracy: 0.7803 - val_loss: 0.7296 - val_sparse_categorical_accuracy: 0.7661\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 39/50\n",
            "196/196 - 7s - loss: 0.6234 - sparse_categorical_accuracy: 0.7797 - val_loss: 0.7908 - val_sparse_categorical_accuracy: 0.7552\n",
            "Epoch 40/50\n",
            "196/196 - 7s - loss: 0.6101 - sparse_categorical_accuracy: 0.7834 - val_loss: 0.7615 - val_sparse_categorical_accuracy: 0.7628\n",
            "Epoch 41/50\n",
            "196/196 - 7s - loss: 0.6106 - sparse_categorical_accuracy: 0.7846 - val_loss: 0.7159 - val_sparse_categorical_accuracy: 0.7675\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 42/50\n",
            "196/196 - 7s - loss: 0.6073 - sparse_categorical_accuracy: 0.7865 - val_loss: 0.7220 - val_sparse_categorical_accuracy: 0.7668\n",
            "Epoch 43/50\n",
            "196/196 - 7s - loss: 0.6003 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.7447 - val_sparse_categorical_accuracy: 0.7660\n",
            "Epoch 44/50\n",
            "196/196 - 7s - loss: 0.5954 - sparse_categorical_accuracy: 0.7910 - val_loss: 0.7549 - val_sparse_categorical_accuracy: 0.7666\n",
            "Epoch 45/50\n",
            "196/196 - 7s - loss: 0.5856 - sparse_categorical_accuracy: 0.7919 - val_loss: 0.7482 - val_sparse_categorical_accuracy: 0.7729\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 46/50\n",
            "196/196 - 7s - loss: 0.5889 - sparse_categorical_accuracy: 0.7924 - val_loss: 0.7215 - val_sparse_categorical_accuracy: 0.7673\n",
            "Epoch 47/50\n",
            "196/196 - 7s - loss: 0.5793 - sparse_categorical_accuracy: 0.7968 - val_loss: 0.8251 - val_sparse_categorical_accuracy: 0.7642\n",
            "Epoch 48/50\n",
            "196/196 - 7s - loss: 0.5764 - sparse_categorical_accuracy: 0.7965 - val_loss: 0.7331 - val_sparse_categorical_accuracy: 0.7618\n",
            "Epoch 49/50\n",
            "196/196 - 7s - loss: 0.5681 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.6841 - val_sparse_categorical_accuracy: 0.7785\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_120_layer_call_and_return_conditional_losses, conv2d_120_layer_call_fn, conv2d_121_layer_call_and_return_conditional_losses, conv2d_121_layer_call_fn, conv2d_122_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 50/50\n",
            "196/196 - 7s - loss: 0.5662 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.6939 - val_sparse_categorical_accuracy: 0.7722\n",
            "Total training time 448.04464769363403 seconds\n",
            "Model: \"model_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_22 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        10312     \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        14792     \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,220,538\n",
            "Trainable params: 1,220,538\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 12s - loss: 1.9481 - sparse_categorical_accuracy: 0.2875 - val_loss: 1.7144 - val_sparse_categorical_accuracy: 0.3699\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 9s - loss: 1.5051 - sparse_categorical_accuracy: 0.4622 - val_loss: 1.6793 - val_sparse_categorical_accuracy: 0.4123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "196/196 - 9s - loss: 1.3207 - sparse_categorical_accuracy: 0.5315 - val_loss: 1.2405 - val_sparse_categorical_accuracy: 0.5657\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 9s - loss: 1.1963 - sparse_categorical_accuracy: 0.5768 - val_loss: 1.2500 - val_sparse_categorical_accuracy: 0.5794\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "196/196 - 9s - loss: 1.1277 - sparse_categorical_accuracy: 0.6031 - val_loss: 1.1953 - val_sparse_categorical_accuracy: 0.5861\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/50\n",
            "196/196 - 9s - loss: 1.0627 - sparse_categorical_accuracy: 0.6251 - val_loss: 1.0593 - val_sparse_categorical_accuracy: 0.6349\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "196/196 - 9s - loss: 1.0119 - sparse_categorical_accuracy: 0.6445 - val_loss: 1.0393 - val_sparse_categorical_accuracy: 0.6421\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/50\n",
            "196/196 - 9s - loss: 0.9735 - sparse_categorical_accuracy: 0.6579 - val_loss: 1.0845 - val_sparse_categorical_accuracy: 0.6479\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/50\n",
            "196/196 - 9s - loss: 0.9292 - sparse_categorical_accuracy: 0.6760 - val_loss: 1.2010 - val_sparse_categorical_accuracy: 0.6326\n",
            "Epoch 10/50\n",
            "196/196 - 9s - loss: 0.8996 - sparse_categorical_accuracy: 0.6857 - val_loss: 0.9631 - val_sparse_categorical_accuracy: 0.6845\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/50\n",
            "196/196 - 9s - loss: 0.8724 - sparse_categorical_accuracy: 0.6946 - val_loss: 1.0199 - val_sparse_categorical_accuracy: 0.6753\n",
            "Epoch 12/50\n",
            "196/196 - 9s - loss: 0.8497 - sparse_categorical_accuracy: 0.7040 - val_loss: 1.0358 - val_sparse_categorical_accuracy: 0.6703\n",
            "Epoch 13/50\n",
            "196/196 - 9s - loss: 0.8206 - sparse_categorical_accuracy: 0.7140 - val_loss: 0.8282 - val_sparse_categorical_accuracy: 0.7196\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/50\n",
            "196/196 - 9s - loss: 0.8005 - sparse_categorical_accuracy: 0.7225 - val_loss: 0.8510 - val_sparse_categorical_accuracy: 0.7066\n",
            "Epoch 15/50\n",
            "196/196 - 9s - loss: 0.7842 - sparse_categorical_accuracy: 0.7270 - val_loss: 0.8093 - val_sparse_categorical_accuracy: 0.7250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16/50\n",
            "196/196 - 9s - loss: 0.7576 - sparse_categorical_accuracy: 0.7345 - val_loss: 0.8663 - val_sparse_categorical_accuracy: 0.7152\n",
            "Epoch 17/50\n",
            "196/196 - 9s - loss: 0.7511 - sparse_categorical_accuracy: 0.7382 - val_loss: 0.8622 - val_sparse_categorical_accuracy: 0.7267\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18/50\n",
            "196/196 - 9s - loss: 0.7324 - sparse_categorical_accuracy: 0.7439 - val_loss: 0.8473 - val_sparse_categorical_accuracy: 0.7257\n",
            "Epoch 19/50\n",
            "196/196 - 9s - loss: 0.7169 - sparse_categorical_accuracy: 0.7479 - val_loss: 1.0087 - val_sparse_categorical_accuracy: 0.7126\n",
            "Epoch 20/50\n",
            "196/196 - 9s - loss: 0.7058 - sparse_categorical_accuracy: 0.7556 - val_loss: 0.7903 - val_sparse_categorical_accuracy: 0.7396\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 21/50\n",
            "196/196 - 9s - loss: 0.6914 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.7928 - val_sparse_categorical_accuracy: 0.7459\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 22/50\n",
            "196/196 - 9s - loss: 0.6707 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.9044 - val_sparse_categorical_accuracy: 0.7309\n",
            "Epoch 23/50\n",
            "196/196 - 9s - loss: 0.6602 - sparse_categorical_accuracy: 0.7682 - val_loss: 0.7759 - val_sparse_categorical_accuracy: 0.7457\n",
            "Epoch 24/50\n",
            "196/196 - 9s - loss: 0.6537 - sparse_categorical_accuracy: 0.7703 - val_loss: 0.9157 - val_sparse_categorical_accuracy: 0.7391\n",
            "Epoch 25/50\n",
            "196/196 - 9s - loss: 0.6334 - sparse_categorical_accuracy: 0.7759 - val_loss: 0.7775 - val_sparse_categorical_accuracy: 0.7527\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 26/50\n",
            "196/196 - 9s - loss: 0.6369 - sparse_categorical_accuracy: 0.7760 - val_loss: 0.8437 - val_sparse_categorical_accuracy: 0.7493\n",
            "Epoch 27/50\n",
            "196/196 - 9s - loss: 0.6180 - sparse_categorical_accuracy: 0.7816 - val_loss: 0.9566 - val_sparse_categorical_accuracy: 0.7333\n",
            "Epoch 28/50\n",
            "196/196 - 9s - loss: 0.6217 - sparse_categorical_accuracy: 0.7830 - val_loss: 0.8127 - val_sparse_categorical_accuracy: 0.7517\n",
            "Epoch 29/50\n",
            "196/196 - 9s - loss: 0.6083 - sparse_categorical_accuracy: 0.7865 - val_loss: 0.7801 - val_sparse_categorical_accuracy: 0.7536\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 30/50\n",
            "196/196 - 9s - loss: 0.6093 - sparse_categorical_accuracy: 0.7880 - val_loss: 0.7268 - val_sparse_categorical_accuracy: 0.7640\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 31/50\n",
            "196/196 - 9s - loss: 0.5947 - sparse_categorical_accuracy: 0.7915 - val_loss: 0.8070 - val_sparse_categorical_accuracy: 0.7599\n",
            "Epoch 32/50\n",
            "196/196 - 9s - loss: 0.5827 - sparse_categorical_accuracy: 0.7960 - val_loss: 0.8666 - val_sparse_categorical_accuracy: 0.7512\n",
            "Epoch 33/50\n",
            "196/196 - 9s - loss: 0.5706 - sparse_categorical_accuracy: 0.7970 - val_loss: 0.9552 - val_sparse_categorical_accuracy: 0.7571\n",
            "Epoch 34/50\n",
            "196/196 - 9s - loss: 0.5694 - sparse_categorical_accuracy: 0.8013 - val_loss: 0.9131 - val_sparse_categorical_accuracy: 0.7416\n",
            "Epoch 35/50\n",
            "196/196 - 9s - loss: 0.5594 - sparse_categorical_accuracy: 0.8044 - val_loss: 0.8032 - val_sparse_categorical_accuracy: 0.7626\n",
            "Epoch 36/50\n",
            "196/196 - 9s - loss: 0.5545 - sparse_categorical_accuracy: 0.8062 - val_loss: 0.7249 - val_sparse_categorical_accuracy: 0.7724\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 37/50\n",
            "196/196 - 9s - loss: 0.5494 - sparse_categorical_accuracy: 0.8056 - val_loss: 0.8731 - val_sparse_categorical_accuracy: 0.7608\n",
            "Epoch 38/50\n",
            "196/196 - 9s - loss: 0.5428 - sparse_categorical_accuracy: 0.8097 - val_loss: 0.7825 - val_sparse_categorical_accuracy: 0.7673\n",
            "Epoch 39/50\n",
            "196/196 - 9s - loss: 0.5385 - sparse_categorical_accuracy: 0.8104 - val_loss: 0.7412 - val_sparse_categorical_accuracy: 0.7696\n",
            "Epoch 40/50\n",
            "196/196 - 9s - loss: 0.5286 - sparse_categorical_accuracy: 0.8152 - val_loss: 0.8933 - val_sparse_categorical_accuracy: 0.7602\n",
            "Epoch 41/50\n",
            "196/196 - 9s - loss: 0.5230 - sparse_categorical_accuracy: 0.8177 - val_loss: 0.9592 - val_sparse_categorical_accuracy: 0.7559\n",
            "Epoch 42/50\n",
            "196/196 - 9s - loss: 0.5201 - sparse_categorical_accuracy: 0.8172 - val_loss: 0.7725 - val_sparse_categorical_accuracy: 0.7618\n",
            "Epoch 43/50\n",
            "196/196 - 9s - loss: 0.5152 - sparse_categorical_accuracy: 0.8184 - val_loss: 0.9885 - val_sparse_categorical_accuracy: 0.7616\n",
            "Epoch 44/50\n",
            "196/196 - 9s - loss: 0.5081 - sparse_categorical_accuracy: 0.8215 - val_loss: 0.7959 - val_sparse_categorical_accuracy: 0.7709\n",
            "Epoch 45/50\n",
            "196/196 - 9s - loss: 0.5053 - sparse_categorical_accuracy: 0.8234 - val_loss: 0.7752 - val_sparse_categorical_accuracy: 0.7741\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 46/50\n",
            "196/196 - 9s - loss: 0.5048 - sparse_categorical_accuracy: 0.8220 - val_loss: 0.8136 - val_sparse_categorical_accuracy: 0.7687\n",
            "Epoch 47/50\n",
            "196/196 - 9s - loss: 0.4908 - sparse_categorical_accuracy: 0.8292 - val_loss: 0.7280 - val_sparse_categorical_accuracy: 0.7789\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_126_layer_call_and_return_conditional_losses, conv2d_126_layer_call_fn, conv2d_127_layer_call_and_return_conditional_losses, conv2d_127_layer_call_fn, conv2d_128_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 48/50\n",
            "196/196 - 9s - loss: 0.4966 - sparse_categorical_accuracy: 0.8251 - val_loss: 0.7985 - val_sparse_categorical_accuracy: 0.7754\n",
            "Epoch 49/50\n",
            "196/196 - 9s - loss: 0.4842 - sparse_categorical_accuracy: 0.8301 - val_loss: 0.7872 - val_sparse_categorical_accuracy: 0.7730\n",
            "Epoch 50/50\n",
            "196/196 - 9s - loss: 0.4836 - sparse_categorical_accuracy: 0.8301 - val_loss: 0.9140 - val_sparse_categorical_accuracy: 0.7710\n",
            "Total training time 530.8620512485504 seconds\n",
            "Model: \"model_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_23 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        16528     \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        21392     \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,233,354\n",
            "Trainable params: 1,233,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 14s - loss: 2.0277 - sparse_categorical_accuracy: 0.2465 - val_loss: 1.7498 - val_sparse_categorical_accuracy: 0.3374\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 12s - loss: 1.6294 - sparse_categorical_accuracy: 0.4016 - val_loss: 1.5727 - val_sparse_categorical_accuracy: 0.4179\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "196/196 - 12s - loss: 1.4382 - sparse_categorical_accuracy: 0.4805 - val_loss: 1.5862 - val_sparse_categorical_accuracy: 0.4491\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 12s - loss: 1.2908 - sparse_categorical_accuracy: 0.5365 - val_loss: 1.4286 - val_sparse_categorical_accuracy: 0.5004\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "196/196 - 12s - loss: 1.1948 - sparse_categorical_accuracy: 0.5729 - val_loss: 1.2149 - val_sparse_categorical_accuracy: 0.5759\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/50\n",
            "196/196 - 12s - loss: 1.1192 - sparse_categorical_accuracy: 0.6020 - val_loss: 1.2478 - val_sparse_categorical_accuracy: 0.5919\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "196/196 - 12s - loss: 1.0676 - sparse_categorical_accuracy: 0.6231 - val_loss: 1.1596 - val_sparse_categorical_accuracy: 0.6072\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/50\n",
            "196/196 - 12s - loss: 1.0172 - sparse_categorical_accuracy: 0.6414 - val_loss: 1.0379 - val_sparse_categorical_accuracy: 0.6496\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/50\n",
            "196/196 - 12s - loss: 0.9839 - sparse_categorical_accuracy: 0.6519 - val_loss: 1.0297 - val_sparse_categorical_accuracy: 0.6471\n",
            "Epoch 10/50\n",
            "196/196 - 12s - loss: 0.9392 - sparse_categorical_accuracy: 0.6678 - val_loss: 0.8891 - val_sparse_categorical_accuracy: 0.6898\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/50\n",
            "196/196 - 12s - loss: 0.9132 - sparse_categorical_accuracy: 0.6789 - val_loss: 1.0109 - val_sparse_categorical_accuracy: 0.6545\n",
            "Epoch 12/50\n",
            "196/196 - 12s - loss: 0.8836 - sparse_categorical_accuracy: 0.6896 - val_loss: 0.9445 - val_sparse_categorical_accuracy: 0.6814\n",
            "Epoch 13/50\n",
            "196/196 - 12s - loss: 0.8610 - sparse_categorical_accuracy: 0.6961 - val_loss: 0.8989 - val_sparse_categorical_accuracy: 0.7066\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/50\n",
            "196/196 - 12s - loss: 0.8392 - sparse_categorical_accuracy: 0.7058 - val_loss: 0.8518 - val_sparse_categorical_accuracy: 0.7043\n",
            "Epoch 15/50\n",
            "196/196 - 12s - loss: 0.8221 - sparse_categorical_accuracy: 0.7105 - val_loss: 0.8899 - val_sparse_categorical_accuracy: 0.7044\n",
            "Epoch 16/50\n",
            "196/196 - 12s - loss: 0.8042 - sparse_categorical_accuracy: 0.7159 - val_loss: 0.8168 - val_sparse_categorical_accuracy: 0.7240\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 17/50\n",
            "196/196 - 12s - loss: 0.7802 - sparse_categorical_accuracy: 0.7239 - val_loss: 0.9230 - val_sparse_categorical_accuracy: 0.7217\n",
            "Epoch 18/50\n",
            "196/196 - 12s - loss: 0.7631 - sparse_categorical_accuracy: 0.7315 - val_loss: 0.8137 - val_sparse_categorical_accuracy: 0.7334\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 19/50\n",
            "196/196 - 12s - loss: 0.7615 - sparse_categorical_accuracy: 0.7336 - val_loss: 0.8227 - val_sparse_categorical_accuracy: 0.7221\n",
            "Epoch 20/50\n",
            "196/196 - 12s - loss: 0.7398 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.7665 - val_sparse_categorical_accuracy: 0.7466\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 21/50\n",
            "196/196 - 12s - loss: 0.7205 - sparse_categorical_accuracy: 0.7471 - val_loss: 0.9110 - val_sparse_categorical_accuracy: 0.7360\n",
            "Epoch 22/50\n",
            "196/196 - 12s - loss: 0.7069 - sparse_categorical_accuracy: 0.7511 - val_loss: 0.7902 - val_sparse_categorical_accuracy: 0.7449\n",
            "Epoch 23/50\n",
            "196/196 - 12s - loss: 0.6984 - sparse_categorical_accuracy: 0.7534 - val_loss: 0.7580 - val_sparse_categorical_accuracy: 0.7486\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 24/50\n",
            "196/196 - 12s - loss: 0.6871 - sparse_categorical_accuracy: 0.7592 - val_loss: 0.8386 - val_sparse_categorical_accuracy: 0.7466\n",
            "Epoch 25/50\n",
            "196/196 - 12s - loss: 0.6790 - sparse_categorical_accuracy: 0.7614 - val_loss: 0.8178 - val_sparse_categorical_accuracy: 0.7452\n",
            "Epoch 26/50\n",
            "196/196 - 12s - loss: 0.6757 - sparse_categorical_accuracy: 0.7623 - val_loss: 0.7091 - val_sparse_categorical_accuracy: 0.7551\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 27/50\n",
            "196/196 - 12s - loss: 0.6596 - sparse_categorical_accuracy: 0.7670 - val_loss: 0.7957 - val_sparse_categorical_accuracy: 0.7453\n",
            "Epoch 28/50\n",
            "196/196 - 12s - loss: 0.6472 - sparse_categorical_accuracy: 0.7722 - val_loss: 0.7165 - val_sparse_categorical_accuracy: 0.7609\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 29/50\n",
            "196/196 - 12s - loss: 0.6397 - sparse_categorical_accuracy: 0.7743 - val_loss: 0.7216 - val_sparse_categorical_accuracy: 0.7649\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 30/50\n",
            "196/196 - 12s - loss: 0.6356 - sparse_categorical_accuracy: 0.7767 - val_loss: 0.7947 - val_sparse_categorical_accuracy: 0.7549\n",
            "Epoch 31/50\n",
            "196/196 - 12s - loss: 0.6227 - sparse_categorical_accuracy: 0.7809 - val_loss: 0.8420 - val_sparse_categorical_accuracy: 0.7539\n",
            "Epoch 32/50\n",
            "196/196 - 12s - loss: 0.6157 - sparse_categorical_accuracy: 0.7859 - val_loss: 0.7670 - val_sparse_categorical_accuracy: 0.7619\n",
            "Epoch 33/50\n",
            "196/196 - 12s - loss: 0.6038 - sparse_categorical_accuracy: 0.7873 - val_loss: 0.7766 - val_sparse_categorical_accuracy: 0.7582\n",
            "Epoch 34/50\n",
            "196/196 - 12s - loss: 0.6010 - sparse_categorical_accuracy: 0.7881 - val_loss: 0.8050 - val_sparse_categorical_accuracy: 0.7626\n",
            "Epoch 35/50\n",
            "196/196 - 12s - loss: 0.6018 - sparse_categorical_accuracy: 0.7904 - val_loss: 0.7298 - val_sparse_categorical_accuracy: 0.7703\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 36/50\n",
            "196/196 - 12s - loss: 0.5892 - sparse_categorical_accuracy: 0.7939 - val_loss: 0.7484 - val_sparse_categorical_accuracy: 0.7607\n",
            "Epoch 37/50\n",
            "196/196 - 12s - loss: 0.5797 - sparse_categorical_accuracy: 0.7957 - val_loss: 0.6861 - val_sparse_categorical_accuracy: 0.7706\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 38/50\n",
            "196/196 - 12s - loss: 0.5768 - sparse_categorical_accuracy: 0.7972 - val_loss: 0.8274 - val_sparse_categorical_accuracy: 0.7581\n",
            "Epoch 39/50\n",
            "196/196 - 12s - loss: 0.5698 - sparse_categorical_accuracy: 0.7987 - val_loss: 0.7598 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 40/50\n",
            "196/196 - 12s - loss: 0.5591 - sparse_categorical_accuracy: 0.8037 - val_loss: 0.8299 - val_sparse_categorical_accuracy: 0.7630\n",
            "Epoch 41/50\n",
            "196/196 - 12s - loss: 0.5596 - sparse_categorical_accuracy: 0.8037 - val_loss: 0.7632 - val_sparse_categorical_accuracy: 0.7615\n",
            "Epoch 42/50\n",
            "196/196 - 12s - loss: 0.5535 - sparse_categorical_accuracy: 0.8087 - val_loss: 0.7778 - val_sparse_categorical_accuracy: 0.7665\n",
            "Epoch 43/50\n",
            "196/196 - 12s - loss: 0.5489 - sparse_categorical_accuracy: 0.8069 - val_loss: 0.7270 - val_sparse_categorical_accuracy: 0.7752\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 44/50\n",
            "196/196 - 12s - loss: 0.5438 - sparse_categorical_accuracy: 0.8103 - val_loss: 0.7807 - val_sparse_categorical_accuracy: 0.7718\n",
            "Epoch 45/50\n",
            "196/196 - 12s - loss: 0.5395 - sparse_categorical_accuracy: 0.8099 - val_loss: 0.7823 - val_sparse_categorical_accuracy: 0.7781\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 46/50\n",
            "196/196 - 12s - loss: 0.5257 - sparse_categorical_accuracy: 0.8141 - val_loss: 0.8555 - val_sparse_categorical_accuracy: 0.7686\n",
            "Epoch 47/50\n",
            "196/196 - 12s - loss: 0.5332 - sparse_categorical_accuracy: 0.8132 - val_loss: 0.8417 - val_sparse_categorical_accuracy: 0.7672\n",
            "Epoch 48/50\n",
            "196/196 - 12s - loss: 0.5220 - sparse_categorical_accuracy: 0.8162 - val_loss: 0.7643 - val_sparse_categorical_accuracy: 0.7756\n",
            "Epoch 49/50\n",
            "196/196 - 12s - loss: 0.5163 - sparse_categorical_accuracy: 0.8187 - val_loss: 0.7061 - val_sparse_categorical_accuracy: 0.7807\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_132_layer_call_and_return_conditional_losses, conv2d_132_layer_call_fn, conv2d_133_layer_call_and_return_conditional_losses, conv2d_133_layer_call_fn, conv2d_134_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 50/50\n",
            "196/196 - 12s - loss: 0.5179 - sparse_categorical_accuracy: 0.8188 - val_loss: 0.7489 - val_sparse_categorical_accuracy: 0.7705\n",
            "Total training time 661.721734046936 seconds\n",
            "Model: \"model_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_24 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        28960     \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        34592     \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,258,986\n",
            "Trainable params: 1,258,986\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 19s - loss: 1.9105 - sparse_categorical_accuracy: 0.2999 - val_loss: 1.6739 - val_sparse_categorical_accuracy: 0.3840\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 17s - loss: 1.4566 - sparse_categorical_accuracy: 0.4749 - val_loss: 1.3136 - val_sparse_categorical_accuracy: 0.5319\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "196/196 - 17s - loss: 1.2583 - sparse_categorical_accuracy: 0.5533 - val_loss: 1.3285 - val_sparse_categorical_accuracy: 0.5426\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 17s - loss: 1.1493 - sparse_categorical_accuracy: 0.5961 - val_loss: 1.1493 - val_sparse_categorical_accuracy: 0.5983\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "196/196 - 17s - loss: 1.0658 - sparse_categorical_accuracy: 0.6219 - val_loss: 1.0272 - val_sparse_categorical_accuracy: 0.6462\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/50\n",
            "196/196 - 17s - loss: 0.9983 - sparse_categorical_accuracy: 0.6524 - val_loss: 1.0042 - val_sparse_categorical_accuracy: 0.6552\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "196/196 - 17s - loss: 0.9560 - sparse_categorical_accuracy: 0.6664 - val_loss: 1.0346 - val_sparse_categorical_accuracy: 0.6747\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/50\n",
            "196/196 - 17s - loss: 0.9102 - sparse_categorical_accuracy: 0.6791 - val_loss: 0.9064 - val_sparse_categorical_accuracy: 0.6918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/50\n",
            "196/196 - 17s - loss: 0.8782 - sparse_categorical_accuracy: 0.6921 - val_loss: 0.8936 - val_sparse_categorical_accuracy: 0.6970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/50\n",
            "196/196 - 17s - loss: 0.8438 - sparse_categorical_accuracy: 0.7042 - val_loss: 0.8521 - val_sparse_categorical_accuracy: 0.7084\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/50\n",
            "196/196 - 17s - loss: 0.8187 - sparse_categorical_accuracy: 0.7144 - val_loss: 0.8692 - val_sparse_categorical_accuracy: 0.7026\n",
            "Epoch 12/50\n",
            "196/196 - 17s - loss: 0.7899 - sparse_categorical_accuracy: 0.7245 - val_loss: 0.8509 - val_sparse_categorical_accuracy: 0.7149\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13/50\n",
            "196/196 - 17s - loss: 0.7657 - sparse_categorical_accuracy: 0.7304 - val_loss: 0.8534 - val_sparse_categorical_accuracy: 0.7177\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/50\n",
            "196/196 - 17s - loss: 0.7505 - sparse_categorical_accuracy: 0.7399 - val_loss: 0.7721 - val_sparse_categorical_accuracy: 0.7375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15/50\n",
            "196/196 - 17s - loss: 0.7343 - sparse_categorical_accuracy: 0.7427 - val_loss: 0.7830 - val_sparse_categorical_accuracy: 0.7482\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16/50\n",
            "196/196 - 17s - loss: 0.7131 - sparse_categorical_accuracy: 0.7520 - val_loss: 0.9062 - val_sparse_categorical_accuracy: 0.7312\n",
            "Epoch 17/50\n",
            "196/196 - 17s - loss: 0.7000 - sparse_categorical_accuracy: 0.7538 - val_loss: 0.7635 - val_sparse_categorical_accuracy: 0.7514\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18/50\n",
            "196/196 - 17s - loss: 0.6816 - sparse_categorical_accuracy: 0.7623 - val_loss: 0.7750 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 19/50\n",
            "196/196 - 17s - loss: 0.6591 - sparse_categorical_accuracy: 0.7687 - val_loss: 0.7791 - val_sparse_categorical_accuracy: 0.7497\n",
            "Epoch 20/50\n",
            "196/196 - 17s - loss: 0.6554 - sparse_categorical_accuracy: 0.7715 - val_loss: 0.8181 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 21/50\n",
            "196/196 - 17s - loss: 0.6406 - sparse_categorical_accuracy: 0.7749 - val_loss: 0.8446 - val_sparse_categorical_accuracy: 0.7526\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 22/50\n",
            "196/196 - 17s - loss: 0.6317 - sparse_categorical_accuracy: 0.7770 - val_loss: 0.9619 - val_sparse_categorical_accuracy: 0.7480\n",
            "Epoch 23/50\n",
            "196/196 - 17s - loss: 0.6282 - sparse_categorical_accuracy: 0.7796 - val_loss: 0.8952 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 24/50\n",
            "196/196 - 17s - loss: 0.6059 - sparse_categorical_accuracy: 0.7883 - val_loss: 0.9171 - val_sparse_categorical_accuracy: 0.7594\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 25/50\n",
            "196/196 - 17s - loss: 0.6055 - sparse_categorical_accuracy: 0.7866 - val_loss: 0.8048 - val_sparse_categorical_accuracy: 0.7512\n",
            "Epoch 26/50\n",
            "196/196 - 17s - loss: 0.5902 - sparse_categorical_accuracy: 0.7921 - val_loss: 0.8031 - val_sparse_categorical_accuracy: 0.7557\n",
            "Epoch 27/50\n",
            "196/196 - 17s - loss: 0.5801 - sparse_categorical_accuracy: 0.7967 - val_loss: 0.8587 - val_sparse_categorical_accuracy: 0.7516\n",
            "Epoch 28/50\n",
            "196/196 - 17s - loss: 0.5656 - sparse_categorical_accuracy: 0.8010 - val_loss: 0.8121 - val_sparse_categorical_accuracy: 0.7623\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 29/50\n",
            "196/196 - 17s - loss: 0.5576 - sparse_categorical_accuracy: 0.8036 - val_loss: 1.0201 - val_sparse_categorical_accuracy: 0.7435\n",
            "Epoch 30/50\n",
            "196/196 - 17s - loss: 0.5522 - sparse_categorical_accuracy: 0.8054 - val_loss: 0.7169 - val_sparse_categorical_accuracy: 0.7634\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 31/50\n",
            "196/196 - 17s - loss: 0.5487 - sparse_categorical_accuracy: 0.8063 - val_loss: 0.8514 - val_sparse_categorical_accuracy: 0.7564\n",
            "Epoch 32/50\n",
            "196/196 - 17s - loss: 0.5352 - sparse_categorical_accuracy: 0.8113 - val_loss: 0.8392 - val_sparse_categorical_accuracy: 0.7693\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 33/50\n",
            "196/196 - 17s - loss: 0.5239 - sparse_categorical_accuracy: 0.8156 - val_loss: 0.8535 - val_sparse_categorical_accuracy: 0.7635\n",
            "Epoch 34/50\n",
            "196/196 - 17s - loss: 0.5304 - sparse_categorical_accuracy: 0.8124 - val_loss: 0.8124 - val_sparse_categorical_accuracy: 0.7790\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 35/50\n",
            "196/196 - 17s - loss: 0.5165 - sparse_categorical_accuracy: 0.8187 - val_loss: 0.7938 - val_sparse_categorical_accuracy: 0.7752\n",
            "Epoch 36/50\n",
            "196/196 - 17s - loss: 0.5123 - sparse_categorical_accuracy: 0.8194 - val_loss: 0.6583 - val_sparse_categorical_accuracy: 0.7839\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 37/50\n",
            "196/196 - 17s - loss: 0.5083 - sparse_categorical_accuracy: 0.8223 - val_loss: 0.7132 - val_sparse_categorical_accuracy: 0.7799\n",
            "Epoch 38/50\n",
            "196/196 - 17s - loss: 0.5014 - sparse_categorical_accuracy: 0.8232 - val_loss: 0.8743 - val_sparse_categorical_accuracy: 0.7748\n",
            "Epoch 39/50\n",
            "196/196 - 17s - loss: 0.4964 - sparse_categorical_accuracy: 0.8259 - val_loss: 0.9115 - val_sparse_categorical_accuracy: 0.7676\n",
            "Epoch 40/50\n",
            "196/196 - 17s - loss: 0.4906 - sparse_categorical_accuracy: 0.8271 - val_loss: 0.7719 - val_sparse_categorical_accuracy: 0.7819\n",
            "Epoch 41/50\n",
            "196/196 - 17s - loss: 0.4843 - sparse_categorical_accuracy: 0.8276 - val_loss: 0.8015 - val_sparse_categorical_accuracy: 0.7789\n",
            "Epoch 42/50\n",
            "196/196 - 17s - loss: 0.4860 - sparse_categorical_accuracy: 0.8299 - val_loss: 0.7684 - val_sparse_categorical_accuracy: 0.7768\n",
            "Epoch 43/50\n",
            "196/196 - 17s - loss: 0.4716 - sparse_categorical_accuracy: 0.8323 - val_loss: 0.8677 - val_sparse_categorical_accuracy: 0.7726\n",
            "Epoch 44/50\n",
            "196/196 - 17s - loss: 0.4667 - sparse_categorical_accuracy: 0.8360 - val_loss: 0.7716 - val_sparse_categorical_accuracy: 0.7821\n",
            "Epoch 45/50\n",
            "196/196 - 17s - loss: 0.4690 - sparse_categorical_accuracy: 0.8336 - val_loss: 0.8337 - val_sparse_categorical_accuracy: 0.7710\n",
            "Epoch 46/50\n",
            "196/196 - 17s - loss: 0.4585 - sparse_categorical_accuracy: 0.8383 - val_loss: 1.0015 - val_sparse_categorical_accuracy: 0.7594\n",
            "Epoch 47/50\n",
            "196/196 - 17s - loss: 0.4583 - sparse_categorical_accuracy: 0.8386 - val_loss: 0.8164 - val_sparse_categorical_accuracy: 0.7808\n",
            "Epoch 48/50\n",
            "196/196 - 17s - loss: 0.4544 - sparse_categorical_accuracy: 0.8392 - val_loss: 0.7864 - val_sparse_categorical_accuracy: 0.7777\n",
            "Epoch 49/50\n",
            "196/196 - 17s - loss: 0.4542 - sparse_categorical_accuracy: 0.8407 - val_loss: 0.8881 - val_sparse_categorical_accuracy: 0.7755\n",
            "Epoch 50/50\n",
            "196/196 - 17s - loss: 0.4438 - sparse_categorical_accuracy: 0.8438 - val_loss: 0.8709 - val_sparse_categorical_accuracy: 0.7849\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_138_layer_call_and_return_conditional_losses, conv2d_138_layer_call_fn, conv2d_139_layer_call_and_return_conditional_losses, conv2d_139_layer_call_fn, conv2d_140_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_4udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total training time 917.1482973098755 seconds\n",
            "Model: \"model_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_25 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        14344     \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        22856     \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,232,634\n",
            "Trainable params: 1,232,634\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 13s - loss: 1.9352 - sparse_categorical_accuracy: 0.2880 - val_loss: 1.7482 - val_sparse_categorical_accuracy: 0.3517\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 11s - loss: 1.5026 - sparse_categorical_accuracy: 0.4569 - val_loss: 1.4130 - val_sparse_categorical_accuracy: 0.4878\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "196/196 - 11s - loss: 1.3070 - sparse_categorical_accuracy: 0.5354 - val_loss: 1.3119 - val_sparse_categorical_accuracy: 0.5269\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 11s - loss: 1.1938 - sparse_categorical_accuracy: 0.5773 - val_loss: 1.2228 - val_sparse_categorical_accuracy: 0.5853\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "196/196 - 11s - loss: 1.1142 - sparse_categorical_accuracy: 0.6095 - val_loss: 1.1063 - val_sparse_categorical_accuracy: 0.6182\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/50\n",
            "196/196 - 10s - loss: 1.0437 - sparse_categorical_accuracy: 0.6309 - val_loss: 1.0174 - val_sparse_categorical_accuracy: 0.6507\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "196/196 - 10s - loss: 0.9874 - sparse_categorical_accuracy: 0.6531 - val_loss: 0.9762 - val_sparse_categorical_accuracy: 0.6631\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/50\n",
            "196/196 - 11s - loss: 0.9383 - sparse_categorical_accuracy: 0.6714 - val_loss: 0.9254 - val_sparse_categorical_accuracy: 0.6818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/50\n",
            "196/196 - 10s - loss: 0.9024 - sparse_categorical_accuracy: 0.6834 - val_loss: 0.8702 - val_sparse_categorical_accuracy: 0.7004\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/50\n",
            "196/196 - 10s - loss: 0.8575 - sparse_categorical_accuracy: 0.6983 - val_loss: 0.8340 - val_sparse_categorical_accuracy: 0.7136\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/50\n",
            "196/196 - 11s - loss: 0.8293 - sparse_categorical_accuracy: 0.7082 - val_loss: 0.8188 - val_sparse_categorical_accuracy: 0.7160\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/50\n",
            "196/196 - 11s - loss: 0.7988 - sparse_categorical_accuracy: 0.7172 - val_loss: 0.7961 - val_sparse_categorical_accuracy: 0.7244\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13/50\n",
            "196/196 - 11s - loss: 0.7798 - sparse_categorical_accuracy: 0.7263 - val_loss: 0.8174 - val_sparse_categorical_accuracy: 0.7225\n",
            "Epoch 14/50\n",
            "196/196 - 11s - loss: 0.7597 - sparse_categorical_accuracy: 0.7333 - val_loss: 0.7910 - val_sparse_categorical_accuracy: 0.7263\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15/50\n",
            "196/196 - 11s - loss: 0.7258 - sparse_categorical_accuracy: 0.7449 - val_loss: 0.8079 - val_sparse_categorical_accuracy: 0.7419\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16/50\n",
            "196/196 - 11s - loss: 0.7149 - sparse_categorical_accuracy: 0.7487 - val_loss: 0.9426 - val_sparse_categorical_accuracy: 0.7247\n",
            "Epoch 17/50\n",
            "196/196 - 11s - loss: 0.7066 - sparse_categorical_accuracy: 0.7526 - val_loss: 0.7306 - val_sparse_categorical_accuracy: 0.7560\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18/50\n",
            "196/196 - 11s - loss: 0.6750 - sparse_categorical_accuracy: 0.7623 - val_loss: 0.7820 - val_sparse_categorical_accuracy: 0.7547\n",
            "Epoch 19/50\n",
            "196/196 - 11s - loss: 0.6648 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.7475 - val_sparse_categorical_accuracy: 0.7508\n",
            "Epoch 20/50\n",
            "196/196 - 11s - loss: 0.6503 - sparse_categorical_accuracy: 0.7720 - val_loss: 0.7535 - val_sparse_categorical_accuracy: 0.7533\n",
            "Epoch 21/50\n",
            "196/196 - 11s - loss: 0.6340 - sparse_categorical_accuracy: 0.7775 - val_loss: 0.6994 - val_sparse_categorical_accuracy: 0.7678\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 22/50\n",
            "196/196 - 11s - loss: 0.6147 - sparse_categorical_accuracy: 0.7833 - val_loss: 0.7764 - val_sparse_categorical_accuracy: 0.7547\n",
            "Epoch 23/50\n",
            "196/196 - 10s - loss: 0.6136 - sparse_categorical_accuracy: 0.7853 - val_loss: 0.7948 - val_sparse_categorical_accuracy: 0.7579\n",
            "Epoch 24/50\n",
            "196/196 - 11s - loss: 0.5971 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.7359 - val_sparse_categorical_accuracy: 0.7704\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 25/50\n",
            "196/196 - 11s - loss: 0.5961 - sparse_categorical_accuracy: 0.7903 - val_loss: 0.7525 - val_sparse_categorical_accuracy: 0.7732\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 26/50\n",
            "196/196 - 11s - loss: 0.5788 - sparse_categorical_accuracy: 0.7981 - val_loss: 0.6717 - val_sparse_categorical_accuracy: 0.7754\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 27/50\n",
            "196/196 - 10s - loss: 0.5730 - sparse_categorical_accuracy: 0.7980 - val_loss: 0.7027 - val_sparse_categorical_accuracy: 0.7657\n",
            "Epoch 28/50\n",
            "196/196 - 10s - loss: 0.5632 - sparse_categorical_accuracy: 0.8014 - val_loss: 0.6985 - val_sparse_categorical_accuracy: 0.7740\n",
            "Epoch 29/50\n",
            "196/196 - 10s - loss: 0.5598 - sparse_categorical_accuracy: 0.8063 - val_loss: 0.7924 - val_sparse_categorical_accuracy: 0.7697\n",
            "Epoch 30/50\n",
            "196/196 - 10s - loss: 0.5448 - sparse_categorical_accuracy: 0.8075 - val_loss: 0.7109 - val_sparse_categorical_accuracy: 0.7785\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 31/50\n",
            "196/196 - 10s - loss: 0.5369 - sparse_categorical_accuracy: 0.8110 - val_loss: 0.7352 - val_sparse_categorical_accuracy: 0.7662\n",
            "Epoch 32/50\n",
            "196/196 - 10s - loss: 0.5294 - sparse_categorical_accuracy: 0.8145 - val_loss: 0.6902 - val_sparse_categorical_accuracy: 0.7805\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 33/50\n",
            "196/196 - 11s - loss: 0.5271 - sparse_categorical_accuracy: 0.8124 - val_loss: 0.8671 - val_sparse_categorical_accuracy: 0.7768\n",
            "Epoch 34/50\n",
            "196/196 - 11s - loss: 0.5179 - sparse_categorical_accuracy: 0.8193 - val_loss: 0.7413 - val_sparse_categorical_accuracy: 0.7816\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 35/50\n",
            "196/196 - 11s - loss: 0.5134 - sparse_categorical_accuracy: 0.8202 - val_loss: 0.7067 - val_sparse_categorical_accuracy: 0.7829\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 36/50\n",
            "196/196 - 11s - loss: 0.5022 - sparse_categorical_accuracy: 0.8222 - val_loss: 0.6792 - val_sparse_categorical_accuracy: 0.7859\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 37/50\n",
            "196/196 - 10s - loss: 0.4968 - sparse_categorical_accuracy: 0.8237 - val_loss: 0.7333 - val_sparse_categorical_accuracy: 0.7862\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 38/50\n",
            "196/196 - 10s - loss: 0.4833 - sparse_categorical_accuracy: 0.8288 - val_loss: 0.7829 - val_sparse_categorical_accuracy: 0.7845\n",
            "Epoch 39/50\n",
            "196/196 - 10s - loss: 0.4802 - sparse_categorical_accuracy: 0.8290 - val_loss: 0.8982 - val_sparse_categorical_accuracy: 0.7832\n",
            "Epoch 40/50\n",
            "196/196 - 10s - loss: 0.4762 - sparse_categorical_accuracy: 0.8313 - val_loss: 0.7117 - val_sparse_categorical_accuracy: 0.7867\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 41/50\n",
            "196/196 - 10s - loss: 0.4753 - sparse_categorical_accuracy: 0.8322 - val_loss: 0.7249 - val_sparse_categorical_accuracy: 0.7895\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 42/50\n",
            "196/196 - 10s - loss: 0.4651 - sparse_categorical_accuracy: 0.8367 - val_loss: 0.7246 - val_sparse_categorical_accuracy: 0.7860\n",
            "Epoch 43/50\n",
            "196/196 - 11s - loss: 0.4641 - sparse_categorical_accuracy: 0.8352 - val_loss: 0.6894 - val_sparse_categorical_accuracy: 0.7833\n",
            "Epoch 44/50\n",
            "196/196 - 11s - loss: 0.4542 - sparse_categorical_accuracy: 0.8399 - val_loss: 0.6926 - val_sparse_categorical_accuracy: 0.7892\n",
            "Epoch 45/50\n",
            "196/196 - 11s - loss: 0.4479 - sparse_categorical_accuracy: 0.8419 - val_loss: 0.7546 - val_sparse_categorical_accuracy: 0.7884\n",
            "Epoch 46/50\n",
            "196/196 - 11s - loss: 0.4423 - sparse_categorical_accuracy: 0.8435 - val_loss: 0.8708 - val_sparse_categorical_accuracy: 0.7896\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 47/50\n",
            "196/196 - 10s - loss: 0.4442 - sparse_categorical_accuracy: 0.8444 - val_loss: 0.6847 - val_sparse_categorical_accuracy: 0.7822\n",
            "Epoch 48/50\n",
            "196/196 - 10s - loss: 0.4313 - sparse_categorical_accuracy: 0.8458 - val_loss: 0.6934 - val_sparse_categorical_accuracy: 0.7882\n",
            "Epoch 49/50\n",
            "196/196 - 11s - loss: 0.4366 - sparse_categorical_accuracy: 0.8477 - val_loss: 0.7068 - val_sparse_categorical_accuracy: 0.7939\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_144_layer_call_and_return_conditional_losses, conv2d_144_layer_call_fn, conv2d_145_layer_call_and_return_conditional_losses, conv2d_145_layer_call_fn, conv2d_146_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_1kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 50/50\n",
            "196/196 - 11s - loss: 0.4340 - sparse_categorical_accuracy: 0.8472 - val_loss: 0.7500 - val_sparse_categorical_accuracy: 0.7842\n",
            "Total training time 611.7990305423737 seconds\n",
            "Model: \"model_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_26 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        20496     \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        29328     \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,245,258\n",
            "Trainable params: 1,245,258\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 16s - loss: 1.8903 - sparse_categorical_accuracy: 0.3088 - val_loss: 1.7654 - val_sparse_categorical_accuracy: 0.3621\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 14s - loss: 1.4643 - sparse_categorical_accuracy: 0.4749 - val_loss: 1.5872 - val_sparse_categorical_accuracy: 0.4390\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "196/196 - 13s - loss: 1.2579 - sparse_categorical_accuracy: 0.5515 - val_loss: 1.9086 - val_sparse_categorical_accuracy: 0.4926\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 13s - loss: 1.1223 - sparse_categorical_accuracy: 0.6065 - val_loss: 1.2423 - val_sparse_categorical_accuracy: 0.5831\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "196/196 - 13s - loss: 1.0366 - sparse_categorical_accuracy: 0.6348 - val_loss: 1.3037 - val_sparse_categorical_accuracy: 0.5747\n",
            "Epoch 6/50\n",
            "196/196 - 13s - loss: 0.9734 - sparse_categorical_accuracy: 0.6591 - val_loss: 1.0016 - val_sparse_categorical_accuracy: 0.6481\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "196/196 - 13s - loss: 0.9089 - sparse_categorical_accuracy: 0.6820 - val_loss: 0.9467 - val_sparse_categorical_accuracy: 0.6773\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/50\n",
            "196/196 - 14s - loss: 0.8692 - sparse_categorical_accuracy: 0.6933 - val_loss: 0.8826 - val_sparse_categorical_accuracy: 0.7003\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/50\n",
            "196/196 - 14s - loss: 0.8292 - sparse_categorical_accuracy: 0.7105 - val_loss: 0.9109 - val_sparse_categorical_accuracy: 0.6897\n",
            "Epoch 10/50\n",
            "196/196 - 13s - loss: 0.7896 - sparse_categorical_accuracy: 0.7227 - val_loss: 0.8932 - val_sparse_categorical_accuracy: 0.7038\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/50\n",
            "196/196 - 13s - loss: 0.7631 - sparse_categorical_accuracy: 0.7332 - val_loss: 0.7392 - val_sparse_categorical_accuracy: 0.7466\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/50\n",
            "196/196 - 13s - loss: 0.7332 - sparse_categorical_accuracy: 0.7435 - val_loss: 0.7360 - val_sparse_categorical_accuracy: 0.7526\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13/50\n",
            "196/196 - 14s - loss: 0.7044 - sparse_categorical_accuracy: 0.7519 - val_loss: 0.7786 - val_sparse_categorical_accuracy: 0.7378\n",
            "Epoch 14/50\n",
            "196/196 - 14s - loss: 0.6941 - sparse_categorical_accuracy: 0.7574 - val_loss: 0.8859 - val_sparse_categorical_accuracy: 0.7170\n",
            "Epoch 15/50\n",
            "196/196 - 14s - loss: 0.6779 - sparse_categorical_accuracy: 0.7619 - val_loss: 0.8003 - val_sparse_categorical_accuracy: 0.7492\n",
            "Epoch 16/50\n",
            "196/196 - 13s - loss: 0.6537 - sparse_categorical_accuracy: 0.7692 - val_loss: 0.8021 - val_sparse_categorical_accuracy: 0.7523\n",
            "Epoch 17/50\n",
            "196/196 - 13s - loss: 0.6392 - sparse_categorical_accuracy: 0.7751 - val_loss: 0.7193 - val_sparse_categorical_accuracy: 0.7617\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18/50\n",
            "196/196 - 13s - loss: 0.6187 - sparse_categorical_accuracy: 0.7827 - val_loss: 0.8315 - val_sparse_categorical_accuracy: 0.7550\n",
            "Epoch 19/50\n",
            "196/196 - 13s - loss: 0.6070 - sparse_categorical_accuracy: 0.7878 - val_loss: 0.8479 - val_sparse_categorical_accuracy: 0.7417\n",
            "Epoch 20/50\n",
            "196/196 - 14s - loss: 0.6011 - sparse_categorical_accuracy: 0.7896 - val_loss: 0.7404 - val_sparse_categorical_accuracy: 0.7612\n",
            "Epoch 21/50\n",
            "196/196 - 13s - loss: 0.5843 - sparse_categorical_accuracy: 0.7932 - val_loss: 0.9128 - val_sparse_categorical_accuracy: 0.7441\n",
            "Epoch 22/50\n",
            "196/196 - 13s - loss: 0.5721 - sparse_categorical_accuracy: 0.7996 - val_loss: 0.7065 - val_sparse_categorical_accuracy: 0.7662\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 23/50\n",
            "196/196 - 13s - loss: 0.5624 - sparse_categorical_accuracy: 0.8040 - val_loss: 0.8678 - val_sparse_categorical_accuracy: 0.7467\n",
            "Epoch 24/50\n",
            "196/196 - 13s - loss: 0.5526 - sparse_categorical_accuracy: 0.8075 - val_loss: 0.7260 - val_sparse_categorical_accuracy: 0.7794\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 25/50\n",
            "196/196 - 13s - loss: 0.5371 - sparse_categorical_accuracy: 0.8107 - val_loss: 0.8186 - val_sparse_categorical_accuracy: 0.7687\n",
            "Epoch 26/50\n",
            "196/196 - 13s - loss: 0.5329 - sparse_categorical_accuracy: 0.8142 - val_loss: 0.6993 - val_sparse_categorical_accuracy: 0.7829\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 27/50\n",
            "196/196 - 13s - loss: 0.5244 - sparse_categorical_accuracy: 0.8145 - val_loss: 0.7793 - val_sparse_categorical_accuracy: 0.7815\n",
            "Epoch 28/50\n",
            "196/196 - 13s - loss: 0.5125 - sparse_categorical_accuracy: 0.8192 - val_loss: 0.7568 - val_sparse_categorical_accuracy: 0.7851\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 29/50\n",
            "196/196 - 13s - loss: 0.5014 - sparse_categorical_accuracy: 0.8229 - val_loss: 0.8003 - val_sparse_categorical_accuracy: 0.7894\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 30/50\n",
            "196/196 - 13s - loss: 0.4946 - sparse_categorical_accuracy: 0.8266 - val_loss: 0.7141 - val_sparse_categorical_accuracy: 0.7810\n",
            "Epoch 31/50\n",
            "196/196 - 13s - loss: 0.4981 - sparse_categorical_accuracy: 0.8246 - val_loss: 0.7257 - val_sparse_categorical_accuracy: 0.7905\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 32/50\n",
            "196/196 - 14s - loss: 0.4838 - sparse_categorical_accuracy: 0.8292 - val_loss: 0.7587 - val_sparse_categorical_accuracy: 0.7862\n",
            "Epoch 33/50\n",
            "196/196 - 13s - loss: 0.4712 - sparse_categorical_accuracy: 0.8344 - val_loss: 0.7054 - val_sparse_categorical_accuracy: 0.7942\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 34/50\n",
            "196/196 - 14s - loss: 0.4673 - sparse_categorical_accuracy: 0.8341 - val_loss: 0.7803 - val_sparse_categorical_accuracy: 0.7875\n",
            "Epoch 35/50\n",
            "196/196 - 13s - loss: 0.4675 - sparse_categorical_accuracy: 0.8345 - val_loss: 0.6882 - val_sparse_categorical_accuracy: 0.7892\n",
            "Epoch 36/50\n",
            "196/196 - 13s - loss: 0.4520 - sparse_categorical_accuracy: 0.8406 - val_loss: 0.7488 - val_sparse_categorical_accuracy: 0.7897\n",
            "Epoch 37/50\n",
            "196/196 - 13s - loss: 0.4515 - sparse_categorical_accuracy: 0.8432 - val_loss: 0.7785 - val_sparse_categorical_accuracy: 0.7855\n",
            "Epoch 38/50\n",
            "196/196 - 13s - loss: 0.4445 - sparse_categorical_accuracy: 0.8441 - val_loss: 0.8447 - val_sparse_categorical_accuracy: 0.7843\n",
            "Epoch 39/50\n",
            "196/196 - 13s - loss: 0.4451 - sparse_categorical_accuracy: 0.8430 - val_loss: 0.7550 - val_sparse_categorical_accuracy: 0.7849\n",
            "Epoch 40/50\n",
            "196/196 - 13s - loss: 0.4301 - sparse_categorical_accuracy: 0.8477 - val_loss: 0.7661 - val_sparse_categorical_accuracy: 0.7914\n",
            "Epoch 41/50\n",
            "196/196 - 13s - loss: 0.4291 - sparse_categorical_accuracy: 0.8478 - val_loss: 0.8252 - val_sparse_categorical_accuracy: 0.7848\n",
            "Epoch 42/50\n",
            "196/196 - 13s - loss: 0.4190 - sparse_categorical_accuracy: 0.8513 - val_loss: 0.9179 - val_sparse_categorical_accuracy: 0.7790\n",
            "Epoch 43/50\n",
            "196/196 - 13s - loss: 0.4215 - sparse_categorical_accuracy: 0.8517 - val_loss: 0.7830 - val_sparse_categorical_accuracy: 0.7896\n",
            "Epoch 44/50\n",
            "196/196 - 13s - loss: 0.4148 - sparse_categorical_accuracy: 0.8537 - val_loss: 0.7406 - val_sparse_categorical_accuracy: 0.7972\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_150_layer_call_and_return_conditional_losses, conv2d_150_layer_call_fn, conv2d_151_layer_call_and_return_conditional_losses, conv2d_151_layer_call_fn, conv2d_152_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_2kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 45/50\n",
            "196/196 - 13s - loss: 0.4082 - sparse_categorical_accuracy: 0.8572 - val_loss: 0.7397 - val_sparse_categorical_accuracy: 0.7954\n",
            "Epoch 46/50\n",
            "196/196 - 13s - loss: 0.4092 - sparse_categorical_accuracy: 0.8538 - val_loss: 0.7575 - val_sparse_categorical_accuracy: 0.7913\n",
            "Epoch 47/50\n",
            "196/196 - 13s - loss: 0.4001 - sparse_categorical_accuracy: 0.8593 - val_loss: 0.7870 - val_sparse_categorical_accuracy: 0.7944\n",
            "Epoch 48/50\n",
            "196/196 - 13s - loss: 0.3991 - sparse_categorical_accuracy: 0.8598 - val_loss: 0.8465 - val_sparse_categorical_accuracy: 0.7958\n",
            "Epoch 49/50\n",
            "196/196 - 13s - loss: 0.3955 - sparse_categorical_accuracy: 0.8602 - val_loss: 0.7813 - val_sparse_categorical_accuracy: 0.7877\n",
            "Epoch 50/50\n",
            "196/196 - 13s - loss: 0.3888 - sparse_categorical_accuracy: 0.8625 - val_loss: 0.7494 - val_sparse_categorical_accuracy: 0.7957\n",
            "Total training time 729.7639191150665 seconds\n",
            "Model: \"model_26\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_27 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        32800     \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        42272     \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,270,506\n",
            "Trainable params: 1,270,506\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 20s - loss: 1.9370 - sparse_categorical_accuracy: 0.2825 - val_loss: 1.6970 - val_sparse_categorical_accuracy: 0.3543\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 18s - loss: 1.5055 - sparse_categorical_accuracy: 0.4596 - val_loss: 1.6181 - val_sparse_categorical_accuracy: 0.4198\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "196/196 - 18s - loss: 1.3159 - sparse_categorical_accuracy: 0.5349 - val_loss: 1.3485 - val_sparse_categorical_accuracy: 0.5259\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 18s - loss: 1.1865 - sparse_categorical_accuracy: 0.5798 - val_loss: 1.2821 - val_sparse_categorical_accuracy: 0.5411\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "196/196 - 18s - loss: 1.1086 - sparse_categorical_accuracy: 0.6083 - val_loss: 1.3374 - val_sparse_categorical_accuracy: 0.5330\n",
            "Epoch 6/50\n",
            "196/196 - 18s - loss: 1.0361 - sparse_categorical_accuracy: 0.6379 - val_loss: 1.3084 - val_sparse_categorical_accuracy: 0.5854\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "196/196 - 18s - loss: 0.9911 - sparse_categorical_accuracy: 0.6499 - val_loss: 1.1516 - val_sparse_categorical_accuracy: 0.6090\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/50\n",
            "196/196 - 18s - loss: 0.9416 - sparse_categorical_accuracy: 0.6675 - val_loss: 1.0764 - val_sparse_categorical_accuracy: 0.6232\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/50\n",
            "196/196 - 18s - loss: 0.9005 - sparse_categorical_accuracy: 0.6836 - val_loss: 0.8600 - val_sparse_categorical_accuracy: 0.7003\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/50\n",
            "196/196 - 18s - loss: 0.8649 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.9968 - val_sparse_categorical_accuracy: 0.6694\n",
            "Epoch 11/50\n",
            "196/196 - 18s - loss: 0.8324 - sparse_categorical_accuracy: 0.7048 - val_loss: 0.9832 - val_sparse_categorical_accuracy: 0.6676\n",
            "Epoch 12/50\n",
            "196/196 - 18s - loss: 0.8012 - sparse_categorical_accuracy: 0.7182 - val_loss: 1.0057 - val_sparse_categorical_accuracy: 0.6842\n",
            "Epoch 13/50\n",
            "196/196 - 18s - loss: 0.7824 - sparse_categorical_accuracy: 0.7260 - val_loss: 0.8475 - val_sparse_categorical_accuracy: 0.7130\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/50\n",
            "196/196 - 18s - loss: 0.7595 - sparse_categorical_accuracy: 0.7338 - val_loss: 0.8993 - val_sparse_categorical_accuracy: 0.7133\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15/50\n",
            "196/196 - 18s - loss: 0.7384 - sparse_categorical_accuracy: 0.7414 - val_loss: 1.0653 - val_sparse_categorical_accuracy: 0.6711\n",
            "Epoch 16/50\n",
            "196/196 - 18s - loss: 0.7209 - sparse_categorical_accuracy: 0.7449 - val_loss: 1.0534 - val_sparse_categorical_accuracy: 0.7215\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 17/50\n",
            "196/196 - 18s - loss: 0.7025 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.8126 - val_sparse_categorical_accuracy: 0.7375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18/50\n",
            "196/196 - 18s - loss: 0.6826 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.8225 - val_sparse_categorical_accuracy: 0.7255\n",
            "Epoch 19/50\n",
            "196/196 - 18s - loss: 0.6667 - sparse_categorical_accuracy: 0.7645 - val_loss: 0.8105 - val_sparse_categorical_accuracy: 0.7412\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20/50\n",
            "196/196 - 18s - loss: 0.6539 - sparse_categorical_accuracy: 0.7706 - val_loss: 0.7560 - val_sparse_categorical_accuracy: 0.7408\n",
            "Epoch 21/50\n",
            "196/196 - 18s - loss: 0.6329 - sparse_categorical_accuracy: 0.7778 - val_loss: 0.8055 - val_sparse_categorical_accuracy: 0.7390\n",
            "Epoch 22/50\n",
            "196/196 - 18s - loss: 0.6253 - sparse_categorical_accuracy: 0.7803 - val_loss: 1.0708 - val_sparse_categorical_accuracy: 0.7039\n",
            "Epoch 23/50\n",
            "196/196 - 18s - loss: 0.6147 - sparse_categorical_accuracy: 0.7823 - val_loss: 0.8136 - val_sparse_categorical_accuracy: 0.7441\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 24/50\n",
            "196/196 - 18s - loss: 0.6100 - sparse_categorical_accuracy: 0.7859 - val_loss: 0.7399 - val_sparse_categorical_accuracy: 0.7687\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 25/50\n",
            "196/196 - 18s - loss: 0.5937 - sparse_categorical_accuracy: 0.7906 - val_loss: 1.0144 - val_sparse_categorical_accuracy: 0.7183\n",
            "Epoch 26/50\n",
            "196/196 - 18s - loss: 0.5874 - sparse_categorical_accuracy: 0.7939 - val_loss: 0.7224 - val_sparse_categorical_accuracy: 0.7751\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 27/50\n",
            "196/196 - 18s - loss: 0.5774 - sparse_categorical_accuracy: 0.7955 - val_loss: 0.8821 - val_sparse_categorical_accuracy: 0.7462\n",
            "Epoch 28/50\n",
            "196/196 - 18s - loss: 0.5629 - sparse_categorical_accuracy: 0.8007 - val_loss: 0.9237 - val_sparse_categorical_accuracy: 0.7610\n",
            "Epoch 29/50\n",
            "196/196 - 18s - loss: 0.5525 - sparse_categorical_accuracy: 0.8051 - val_loss: 0.8542 - val_sparse_categorical_accuracy: 0.7471\n",
            "Epoch 30/50\n",
            "196/196 - 18s - loss: 0.5437 - sparse_categorical_accuracy: 0.8052 - val_loss: 0.8122 - val_sparse_categorical_accuracy: 0.7642\n",
            "Epoch 31/50\n",
            "196/196 - 18s - loss: 0.5425 - sparse_categorical_accuracy: 0.8102 - val_loss: 0.8470 - val_sparse_categorical_accuracy: 0.7640\n",
            "Epoch 32/50\n",
            "196/196 - 18s - loss: 0.5433 - sparse_categorical_accuracy: 0.8080 - val_loss: 0.8404 - val_sparse_categorical_accuracy: 0.7537\n",
            "Epoch 33/50\n",
            "196/196 - 18s - loss: 0.5246 - sparse_categorical_accuracy: 0.8148 - val_loss: 0.8122 - val_sparse_categorical_accuracy: 0.7634\n",
            "Epoch 34/50\n",
            "196/196 - 18s - loss: 0.5258 - sparse_categorical_accuracy: 0.8163 - val_loss: 0.7538 - val_sparse_categorical_accuracy: 0.7641\n",
            "Epoch 35/50\n",
            "196/196 - 18s - loss: 0.5099 - sparse_categorical_accuracy: 0.8191 - val_loss: 0.7756 - val_sparse_categorical_accuracy: 0.7694\n",
            "Epoch 36/50\n",
            "196/196 - 18s - loss: 0.5105 - sparse_categorical_accuracy: 0.8206 - val_loss: 0.8880 - val_sparse_categorical_accuracy: 0.7649\n",
            "Epoch 37/50\n",
            "196/196 - 18s - loss: 0.4963 - sparse_categorical_accuracy: 0.8250 - val_loss: 0.8615 - val_sparse_categorical_accuracy: 0.7735\n",
            "Epoch 38/50\n",
            "196/196 - 18s - loss: 0.4909 - sparse_categorical_accuracy: 0.8283 - val_loss: 0.8319 - val_sparse_categorical_accuracy: 0.7697\n",
            "Epoch 39/50\n",
            "196/196 - 18s - loss: 0.4856 - sparse_categorical_accuracy: 0.8303 - val_loss: 0.7033 - val_sparse_categorical_accuracy: 0.7801\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 40/50\n",
            "196/196 - 18s - loss: 0.4844 - sparse_categorical_accuracy: 0.8284 - val_loss: 0.7535 - val_sparse_categorical_accuracy: 0.7729\n",
            "Epoch 41/50\n",
            "196/196 - 18s - loss: 0.4686 - sparse_categorical_accuracy: 0.8349 - val_loss: 0.7765 - val_sparse_categorical_accuracy: 0.7751\n",
            "Epoch 42/50\n",
            "196/196 - 18s - loss: 0.4627 - sparse_categorical_accuracy: 0.8357 - val_loss: 0.7588 - val_sparse_categorical_accuracy: 0.7723\n",
            "Epoch 43/50\n",
            "196/196 - 18s - loss: 0.4771 - sparse_categorical_accuracy: 0.8331 - val_loss: 0.6839 - val_sparse_categorical_accuracy: 0.7871\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_and_return_conditional_losses, conv2d_156_layer_call_fn, conv2d_157_layer_call_and_return_conditional_losses, conv2d_157_layer_call_fn, conv2d_158_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_4kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 44/50\n",
            "196/196 - 18s - loss: 0.4531 - sparse_categorical_accuracy: 0.8376 - val_loss: 0.8482 - val_sparse_categorical_accuracy: 0.7715\n",
            "Epoch 45/50\n",
            "196/196 - 18s - loss: 0.4591 - sparse_categorical_accuracy: 0.8358 - val_loss: 0.9094 - val_sparse_categorical_accuracy: 0.7723\n",
            "Epoch 46/50\n",
            "196/196 - 18s - loss: 0.4531 - sparse_categorical_accuracy: 0.8400 - val_loss: 0.7894 - val_sparse_categorical_accuracy: 0.7738\n",
            "Epoch 47/50\n",
            "196/196 - 18s - loss: 0.4521 - sparse_categorical_accuracy: 0.8422 - val_loss: 0.7298 - val_sparse_categorical_accuracy: 0.7865\n",
            "Epoch 48/50\n",
            "196/196 - 18s - loss: 0.4417 - sparse_categorical_accuracy: 0.8458 - val_loss: 0.7374 - val_sparse_categorical_accuracy: 0.7829\n",
            "Epoch 49/50\n",
            "196/196 - 18s - loss: 0.4411 - sparse_categorical_accuracy: 0.8449 - val_loss: 0.7964 - val_sparse_categorical_accuracy: 0.7854\n",
            "Epoch 50/50\n",
            "196/196 - 18s - loss: 0.4286 - sparse_categorical_accuracy: 0.8490 - val_loss: 0.8608 - val_sparse_categorical_accuracy: 0.7778\n",
            "Total training time 953.341961145401 seconds\n",
            "Model: \"model_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_28 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        57408     \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        68160     \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,321,002\n",
            "Trainable params: 1,321,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 29s - loss: 2.0270 - sparse_categorical_accuracy: 0.2397 - val_loss: 1.7946 - val_sparse_categorical_accuracy: 0.3226\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 27s - loss: 1.5735 - sparse_categorical_accuracy: 0.4283 - val_loss: 2.4827 - val_sparse_categorical_accuracy: 0.2924\n",
            "Epoch 3/50\n",
            "196/196 - 27s - loss: 1.3035 - sparse_categorical_accuracy: 0.5363 - val_loss: 2.0251 - val_sparse_categorical_accuracy: 0.4093\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 27s - loss: 1.1592 - sparse_categorical_accuracy: 0.5916 - val_loss: 1.0915 - val_sparse_categorical_accuracy: 0.6150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "196/196 - 27s - loss: 1.0629 - sparse_categorical_accuracy: 0.6268 - val_loss: 1.2271 - val_sparse_categorical_accuracy: 0.5895\n",
            "Epoch 6/50\n",
            "196/196 - 27s - loss: 0.9821 - sparse_categorical_accuracy: 0.6534 - val_loss: 1.0482 - val_sparse_categorical_accuracy: 0.6470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "196/196 - 27s - loss: 0.9177 - sparse_categorical_accuracy: 0.6779 - val_loss: 1.0837 - val_sparse_categorical_accuracy: 0.6488\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/50\n",
            "196/196 - 27s - loss: 0.8758 - sparse_categorical_accuracy: 0.6925 - val_loss: 0.9255 - val_sparse_categorical_accuracy: 0.6824\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/50\n",
            "196/196 - 26s - loss: 0.8377 - sparse_categorical_accuracy: 0.7067 - val_loss: 0.8739 - val_sparse_categorical_accuracy: 0.7081\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/50\n",
            "196/196 - 27s - loss: 0.8039 - sparse_categorical_accuracy: 0.7183 - val_loss: 0.8545 - val_sparse_categorical_accuracy: 0.7077\n",
            "Epoch 11/50\n",
            "196/196 - 27s - loss: 0.7797 - sparse_categorical_accuracy: 0.7299 - val_loss: 0.8320 - val_sparse_categorical_accuracy: 0.7231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/50\n",
            "196/196 - 26s - loss: 0.7425 - sparse_categorical_accuracy: 0.7390 - val_loss: 1.0819 - val_sparse_categorical_accuracy: 0.6849\n",
            "Epoch 13/50\n",
            "196/196 - 27s - loss: 0.7268 - sparse_categorical_accuracy: 0.7470 - val_loss: 0.8247 - val_sparse_categorical_accuracy: 0.7169\n",
            "Epoch 14/50\n",
            "196/196 - 27s - loss: 0.7019 - sparse_categorical_accuracy: 0.7551 - val_loss: 0.7834 - val_sparse_categorical_accuracy: 0.7371\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15/50\n",
            "196/196 - 27s - loss: 0.6743 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.8371 - val_sparse_categorical_accuracy: 0.7336\n",
            "Epoch 16/50\n",
            "196/196 - 27s - loss: 0.6659 - sparse_categorical_accuracy: 0.7662 - val_loss: 0.8332 - val_sparse_categorical_accuracy: 0.7369\n",
            "Epoch 17/50\n",
            "196/196 - 27s - loss: 0.6503 - sparse_categorical_accuracy: 0.7715 - val_loss: 0.9344 - val_sparse_categorical_accuracy: 0.7226\n",
            "Epoch 18/50\n",
            "196/196 - 27s - loss: 0.6325 - sparse_categorical_accuracy: 0.7772 - val_loss: 0.7859 - val_sparse_categorical_accuracy: 0.7445\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 19/50\n",
            "196/196 - 27s - loss: 0.6175 - sparse_categorical_accuracy: 0.7823 - val_loss: 0.8447 - val_sparse_categorical_accuracy: 0.7470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20/50\n",
            "196/196 - 27s - loss: 0.6098 - sparse_categorical_accuracy: 0.7868 - val_loss: 0.8634 - val_sparse_categorical_accuracy: 0.7403\n",
            "Epoch 21/50\n",
            "196/196 - 27s - loss: 0.5938 - sparse_categorical_accuracy: 0.7921 - val_loss: 0.8359 - val_sparse_categorical_accuracy: 0.7492\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 22/50\n",
            "196/196 - 26s - loss: 0.5867 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.7143 - val_sparse_categorical_accuracy: 0.7712\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 23/50\n",
            "196/196 - 27s - loss: 0.5776 - sparse_categorical_accuracy: 0.7987 - val_loss: 0.8563 - val_sparse_categorical_accuracy: 0.7408\n",
            "Epoch 24/50\n",
            "196/196 - 27s - loss: 0.5549 - sparse_categorical_accuracy: 0.8057 - val_loss: 0.7975 - val_sparse_categorical_accuracy: 0.7690\n",
            "Epoch 25/50\n",
            "196/196 - 27s - loss: 0.5451 - sparse_categorical_accuracy: 0.8089 - val_loss: 0.8559 - val_sparse_categorical_accuracy: 0.7529\n",
            "Epoch 26/50\n",
            "196/196 - 27s - loss: 0.5409 - sparse_categorical_accuracy: 0.8102 - val_loss: 0.7560 - val_sparse_categorical_accuracy: 0.7603\n",
            "Epoch 27/50\n",
            "196/196 - 27s - loss: 0.5272 - sparse_categorical_accuracy: 0.8145 - val_loss: 0.9873 - val_sparse_categorical_accuracy: 0.7378\n",
            "Epoch 28/50\n",
            "196/196 - 27s - loss: 0.5207 - sparse_categorical_accuracy: 0.8187 - val_loss: 0.9368 - val_sparse_categorical_accuracy: 0.7533\n",
            "Epoch 29/50\n",
            "196/196 - 27s - loss: 0.5089 - sparse_categorical_accuracy: 0.8222 - val_loss: 0.7997 - val_sparse_categorical_accuracy: 0.7704\n",
            "Epoch 30/50\n",
            "196/196 - 27s - loss: 0.5087 - sparse_categorical_accuracy: 0.8219 - val_loss: 0.7123 - val_sparse_categorical_accuracy: 0.7713\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 31/50\n",
            "196/196 - 27s - loss: 0.4986 - sparse_categorical_accuracy: 0.8236 - val_loss: 0.8330 - val_sparse_categorical_accuracy: 0.7634\n",
            "Epoch 32/50\n",
            "196/196 - 27s - loss: 0.4946 - sparse_categorical_accuracy: 0.8274 - val_loss: 0.7714 - val_sparse_categorical_accuracy: 0.7714\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 33/50\n",
            "196/196 - 27s - loss: 0.4829 - sparse_categorical_accuracy: 0.8289 - val_loss: 0.7535 - val_sparse_categorical_accuracy: 0.7771\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 34/50\n",
            "196/196 - 27s - loss: 0.4798 - sparse_categorical_accuracy: 0.8307 - val_loss: 0.8957 - val_sparse_categorical_accuracy: 0.7704\n",
            "Epoch 35/50\n",
            "196/196 - 27s - loss: 0.4722 - sparse_categorical_accuracy: 0.8343 - val_loss: 0.7944 - val_sparse_categorical_accuracy: 0.7655\n",
            "Epoch 36/50\n",
            "196/196 - 26s - loss: 0.4648 - sparse_categorical_accuracy: 0.8364 - val_loss: 0.9284 - val_sparse_categorical_accuracy: 0.7641\n",
            "Epoch 37/50\n",
            "196/196 - 26s - loss: 0.4571 - sparse_categorical_accuracy: 0.8385 - val_loss: 1.0209 - val_sparse_categorical_accuracy: 0.7655\n",
            "Epoch 38/50\n",
            "196/196 - 27s - loss: 0.4533 - sparse_categorical_accuracy: 0.8415 - val_loss: 0.8243 - val_sparse_categorical_accuracy: 0.7798\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 39/50\n",
            "196/196 - 27s - loss: 0.4544 - sparse_categorical_accuracy: 0.8395 - val_loss: 0.8014 - val_sparse_categorical_accuracy: 0.7776\n",
            "Epoch 40/50\n",
            "196/196 - 27s - loss: 0.4453 - sparse_categorical_accuracy: 0.8437 - val_loss: 0.8425 - val_sparse_categorical_accuracy: 0.7782\n",
            "Epoch 41/50\n",
            "196/196 - 27s - loss: 0.4446 - sparse_categorical_accuracy: 0.8423 - val_loss: 0.8785 - val_sparse_categorical_accuracy: 0.7755\n",
            "Epoch 42/50\n",
            "196/196 - 27s - loss: 0.4341 - sparse_categorical_accuracy: 0.8480 - val_loss: 0.8209 - val_sparse_categorical_accuracy: 0.7818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 43/50\n",
            "196/196 - 27s - loss: 0.4290 - sparse_categorical_accuracy: 0.8484 - val_loss: 0.8380 - val_sparse_categorical_accuracy: 0.7838\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 44/50\n",
            "196/196 - 27s - loss: 0.4326 - sparse_categorical_accuracy: 0.8454 - val_loss: 0.7711 - val_sparse_categorical_accuracy: 0.7854\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 45/50\n",
            "196/196 - 27s - loss: 0.4192 - sparse_categorical_accuracy: 0.8523 - val_loss: 0.9179 - val_sparse_categorical_accuracy: 0.7873\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 46/50\n",
            "196/196 - 27s - loss: 0.4153 - sparse_categorical_accuracy: 0.8535 - val_loss: 0.8434 - val_sparse_categorical_accuracy: 0.7822\n",
            "Epoch 47/50\n",
            "196/196 - 27s - loss: 0.4130 - sparse_categorical_accuracy: 0.8555 - val_loss: 0.8803 - val_sparse_categorical_accuracy: 0.7891\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_162_layer_call_and_return_conditional_losses, conv2d_162_layer_call_fn, conv2d_163_layer_call_and_return_conditional_losses, conv2d_163_layer_call_fn, conv2d_164_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_8kdim_8udim_2hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 48/50\n",
            "196/196 - 27s - loss: 0.4142 - sparse_categorical_accuracy: 0.8545 - val_loss: 0.9189 - val_sparse_categorical_accuracy: 0.7850\n",
            "Epoch 49/50\n",
            "196/196 - 27s - loss: 0.4091 - sparse_categorical_accuracy: 0.8570 - val_loss: 0.8126 - val_sparse_categorical_accuracy: 0.7876\n",
            "Epoch 50/50\n",
            "196/196 - 27s - loss: 0.3902 - sparse_categorical_accuracy: 0.8604 - val_loss: 0.8046 - val_sparse_categorical_accuracy: 0.7782\n",
            "Total training time 1401.036985874176 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTM9xv0V-NYT"
      },
      "source": [
        "##Exp 5 - 1 Heads, 1 u dim, Y Key dim\n",
        "Model : LAMBDA  \n",
        "Preprocessing : False  \n",
        "Batch size : 256  \n",
        "Key dim : 16,32,64,128  \n",
        "u dim : 1  \n",
        "Heads : 1  \n",
        "Pos. emb. size : 14  \n",
        "LambdaConv : False  \n",
        "\n",
        "---\n",
        "<pre>\n",
        "Q = k * hd       = 16,32,64,128 \n",
        "K = k * u        = 16,32,64,128\n",
        "V = 64 // hd * u = 64,64,64, 64\n",
        "</pre>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYYOiFFQ_MXi",
        "outputId": "78830e1f-9045-4b96-f7f7-d904e1bfb825",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "hds = 1\n",
        "u_dim = 1\n",
        "for k_dim in [16,32]:\n",
        "  model = LambdaNetwork(num_classes=num_classes, \n",
        "                        image_height=image_height, \n",
        "                        image_width=image_width,\n",
        "                        k_dim=k_dim,\n",
        "                        u_dim=u_dim,\n",
        "                        num_heads=hds,\n",
        "                        n_r_size=14,\n",
        "                        local_contexts=False,\n",
        "                        preprocess=False).model()\n",
        "  model.summary()\n",
        "  if 'LAMBDA' not in history:\n",
        "    history['LAMBDA'] = dict()\n",
        "  if hds not in history['LAMBDA']:\n",
        "    history['LAMBDA'][hds] = dict()\n",
        "  if u_dim not in history['LAMBDA'][hds]:\n",
        "    history['LAMBDA'][hds][u_dim] = dict()\n",
        "  history['LAMBDA'][hds][u_dim][k_dim]= train_and_eval(model, SAVE_PATH + f'_LAMBDA_{k_dim}kdim_{u_dim}udim_{hds}hds', verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_28\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_29 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        14736     \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        17808     \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,227,978\n",
            "Trainable params: 1,227,978\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 22s - loss: 2.0203 - sparse_categorical_accuracy: 0.2541 - val_loss: 1.7614 - val_sparse_categorical_accuracy: 0.3489\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 20s - loss: 1.6009 - sparse_categorical_accuracy: 0.4201 - val_loss: 1.5118 - val_sparse_categorical_accuracy: 0.4603\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "196/196 - 20s - loss: 1.4242 - sparse_categorical_accuracy: 0.4864 - val_loss: 1.3123 - val_sparse_categorical_accuracy: 0.5369\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 19s - loss: 1.3267 - sparse_categorical_accuracy: 0.5263 - val_loss: 1.2120 - val_sparse_categorical_accuracy: 0.5740\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "196/196 - 20s - loss: 1.2503 - sparse_categorical_accuracy: 0.5548 - val_loss: 1.1247 - val_sparse_categorical_accuracy: 0.6102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/50\n",
            "196/196 - 20s - loss: 1.1854 - sparse_categorical_accuracy: 0.5813 - val_loss: 1.0922 - val_sparse_categorical_accuracy: 0.6118\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "196/196 - 19s - loss: 1.1356 - sparse_categorical_accuracy: 0.5968 - val_loss: 1.0562 - val_sparse_categorical_accuracy: 0.6287\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/50\n",
            "196/196 - 19s - loss: 1.0987 - sparse_categorical_accuracy: 0.6135 - val_loss: 1.0128 - val_sparse_categorical_accuracy: 0.6389\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/50\n",
            "196/196 - 19s - loss: 1.0597 - sparse_categorical_accuracy: 0.6253 - val_loss: 0.9593 - val_sparse_categorical_accuracy: 0.6654\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/50\n",
            "196/196 - 19s - loss: 1.0321 - sparse_categorical_accuracy: 0.6376 - val_loss: 0.9113 - val_sparse_categorical_accuracy: 0.6797\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/50\n",
            "196/196 - 19s - loss: 1.0064 - sparse_categorical_accuracy: 0.6446 - val_loss: 0.9405 - val_sparse_categorical_accuracy: 0.6745\n",
            "Epoch 12/50\n",
            "196/196 - 19s - loss: 0.9868 - sparse_categorical_accuracy: 0.6515 - val_loss: 0.8895 - val_sparse_categorical_accuracy: 0.6891\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13/50\n",
            "196/196 - 19s - loss: 0.9652 - sparse_categorical_accuracy: 0.6611 - val_loss: 0.9003 - val_sparse_categorical_accuracy: 0.6859\n",
            "Epoch 14/50\n",
            "196/196 - 19s - loss: 0.9469 - sparse_categorical_accuracy: 0.6665 - val_loss: 0.8592 - val_sparse_categorical_accuracy: 0.6988\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15/50\n",
            "196/196 - 19s - loss: 0.9372 - sparse_categorical_accuracy: 0.6696 - val_loss: 0.8485 - val_sparse_categorical_accuracy: 0.7029\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16/50\n",
            "196/196 - 19s - loss: 0.9257 - sparse_categorical_accuracy: 0.6754 - val_loss: 0.8495 - val_sparse_categorical_accuracy: 0.6988\n",
            "Epoch 17/50\n",
            "196/196 - 19s - loss: 0.9129 - sparse_categorical_accuracy: 0.6788 - val_loss: 0.8185 - val_sparse_categorical_accuracy: 0.7152\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18/50\n",
            "196/196 - 19s - loss: 0.9037 - sparse_categorical_accuracy: 0.6833 - val_loss: 0.8128 - val_sparse_categorical_accuracy: 0.7175\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 19/50\n",
            "196/196 - 19s - loss: 0.8915 - sparse_categorical_accuracy: 0.6868 - val_loss: 0.7965 - val_sparse_categorical_accuracy: 0.7188\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20/50\n",
            "196/196 - 19s - loss: 0.8728 - sparse_categorical_accuracy: 0.6935 - val_loss: 0.8011 - val_sparse_categorical_accuracy: 0.7211\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 21/50\n",
            "196/196 - 19s - loss: 0.8762 - sparse_categorical_accuracy: 0.6904 - val_loss: 0.7845 - val_sparse_categorical_accuracy: 0.7217\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 22/50\n",
            "196/196 - 19s - loss: 0.8635 - sparse_categorical_accuracy: 0.6948 - val_loss: 0.7948 - val_sparse_categorical_accuracy: 0.7281\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 23/50\n",
            "196/196 - 19s - loss: 0.8498 - sparse_categorical_accuracy: 0.7011 - val_loss: 0.7918 - val_sparse_categorical_accuracy: 0.7224\n",
            "Epoch 24/50\n",
            "196/196 - 19s - loss: 0.8526 - sparse_categorical_accuracy: 0.6983 - val_loss: 0.7746 - val_sparse_categorical_accuracy: 0.7325\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 25/50\n",
            "196/196 - 19s - loss: 0.8405 - sparse_categorical_accuracy: 0.7027 - val_loss: 0.7707 - val_sparse_categorical_accuracy: 0.7344\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 26/50\n",
            "196/196 - 19s - loss: 0.8379 - sparse_categorical_accuracy: 0.7024 - val_loss: 0.7673 - val_sparse_categorical_accuracy: 0.7366\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 27/50\n",
            "196/196 - 19s - loss: 0.8269 - sparse_categorical_accuracy: 0.7093 - val_loss: 0.7572 - val_sparse_categorical_accuracy: 0.7356\n",
            "Epoch 28/50\n",
            "196/196 - 19s - loss: 0.8267 - sparse_categorical_accuracy: 0.7092 - val_loss: 0.7827 - val_sparse_categorical_accuracy: 0.7252\n",
            "Epoch 29/50\n",
            "196/196 - 19s - loss: 0.8134 - sparse_categorical_accuracy: 0.7128 - val_loss: 0.7640 - val_sparse_categorical_accuracy: 0.7349\n",
            "Epoch 30/50\n",
            "196/196 - 19s - loss: 0.8109 - sparse_categorical_accuracy: 0.7130 - val_loss: 0.7626 - val_sparse_categorical_accuracy: 0.7410\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 31/50\n",
            "196/196 - 19s - loss: 0.8095 - sparse_categorical_accuracy: 0.7157 - val_loss: 0.7962 - val_sparse_categorical_accuracy: 0.7212\n",
            "Epoch 32/50\n",
            "196/196 - 19s - loss: 0.8054 - sparse_categorical_accuracy: 0.7161 - val_loss: 0.7742 - val_sparse_categorical_accuracy: 0.7323\n",
            "Epoch 33/50\n",
            "196/196 - 19s - loss: 0.7948 - sparse_categorical_accuracy: 0.7209 - val_loss: 0.7543 - val_sparse_categorical_accuracy: 0.7375\n",
            "Epoch 34/50\n",
            "196/196 - 19s - loss: 0.7969 - sparse_categorical_accuracy: 0.7188 - val_loss: 0.7462 - val_sparse_categorical_accuracy: 0.7366\n",
            "Epoch 35/50\n",
            "196/196 - 19s - loss: 0.7908 - sparse_categorical_accuracy: 0.7216 - val_loss: 0.7779 - val_sparse_categorical_accuracy: 0.7314\n",
            "Epoch 36/50\n",
            "196/196 - 19s - loss: 0.7801 - sparse_categorical_accuracy: 0.7259 - val_loss: 0.7389 - val_sparse_categorical_accuracy: 0.7517\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 37/50\n",
            "196/196 - 19s - loss: 0.7770 - sparse_categorical_accuracy: 0.7245 - val_loss: 0.7499 - val_sparse_categorical_accuracy: 0.7454\n",
            "Epoch 38/50\n",
            "196/196 - 19s - loss: 0.7797 - sparse_categorical_accuracy: 0.7242 - val_loss: 0.7338 - val_sparse_categorical_accuracy: 0.7530\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 39/50\n",
            "196/196 - 19s - loss: 0.7677 - sparse_categorical_accuracy: 0.7269 - val_loss: 0.7264 - val_sparse_categorical_accuracy: 0.7497\n",
            "Epoch 40/50\n",
            "196/196 - 19s - loss: 0.7714 - sparse_categorical_accuracy: 0.7271 - val_loss: 0.7191 - val_sparse_categorical_accuracy: 0.7529\n",
            "Epoch 41/50\n",
            "196/196 - 19s - loss: 0.7598 - sparse_categorical_accuracy: 0.7321 - val_loss: 0.7293 - val_sparse_categorical_accuracy: 0.7518\n",
            "Epoch 42/50\n",
            "196/196 - 19s - loss: 0.7466 - sparse_categorical_accuracy: 0.7365 - val_loss: 0.7322 - val_sparse_categorical_accuracy: 0.7421\n",
            "Epoch 43/50\n",
            "196/196 - 19s - loss: 0.7547 - sparse_categorical_accuracy: 0.7347 - val_loss: 0.7263 - val_sparse_categorical_accuracy: 0.7452\n",
            "Epoch 44/50\n",
            "196/196 - 19s - loss: 0.7501 - sparse_categorical_accuracy: 0.7375 - val_loss: 0.7219 - val_sparse_categorical_accuracy: 0.7508\n",
            "Epoch 45/50\n",
            "196/196 - 19s - loss: 0.7472 - sparse_categorical_accuracy: 0.7364 - val_loss: 0.7225 - val_sparse_categorical_accuracy: 0.7572\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_168_layer_call_and_return_conditional_losses, conv2d_168_layer_call_fn, conv2d_169_layer_call_and_return_conditional_losses, conv2d_169_layer_call_fn, conv2d_170_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_16kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 46/50\n",
            "196/196 - 19s - loss: 0.7401 - sparse_categorical_accuracy: 0.7386 - val_loss: 0.7398 - val_sparse_categorical_accuracy: 0.7510\n",
            "Epoch 47/50\n",
            "196/196 - 19s - loss: 0.7386 - sparse_categorical_accuracy: 0.7404 - val_loss: 0.7212 - val_sparse_categorical_accuracy: 0.7474\n",
            "Epoch 48/50\n",
            "196/196 - 19s - loss: 0.7354 - sparse_categorical_accuracy: 0.7413 - val_loss: 0.7131 - val_sparse_categorical_accuracy: 0.7544\n",
            "Epoch 49/50\n",
            "196/196 - 19s - loss: 0.7254 - sparse_categorical_accuracy: 0.7438 - val_loss: 0.7233 - val_sparse_categorical_accuracy: 0.7462\n",
            "Epoch 50/50\n",
            "196/196 - 19s - loss: 0.7246 - sparse_categorical_accuracy: 0.7456 - val_loss: 0.7235 - val_sparse_categorical_accuracy: 0.7543\n",
            "Total training time 1041.8598687648773 seconds\n",
            "Model: \"model_29\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_30 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        27424     \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        31520     \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,254,378\n",
            "Trainable params: 1,254,378\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 34s - loss: 1.9597 - sparse_categorical_accuracy: 0.2710 - val_loss: 1.7351 - val_sparse_categorical_accuracy: 0.3519\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 31s - loss: 1.5611 - sparse_categorical_accuracy: 0.4345 - val_loss: 1.4223 - val_sparse_categorical_accuracy: 0.4916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "196/196 - 31s - loss: 1.3823 - sparse_categorical_accuracy: 0.5018 - val_loss: 1.2796 - val_sparse_categorical_accuracy: 0.5461\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 31s - loss: 1.2626 - sparse_categorical_accuracy: 0.5487 - val_loss: 1.2418 - val_sparse_categorical_accuracy: 0.5481\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "196/196 - 31s - loss: 1.1881 - sparse_categorical_accuracy: 0.5780 - val_loss: 1.0918 - val_sparse_categorical_accuracy: 0.6111\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/50\n",
            "196/196 - 31s - loss: 1.1252 - sparse_categorical_accuracy: 0.5992 - val_loss: 1.0519 - val_sparse_categorical_accuracy: 0.6242\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "196/196 - 31s - loss: 1.0695 - sparse_categorical_accuracy: 0.6216 - val_loss: 1.0094 - val_sparse_categorical_accuracy: 0.6405\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/50\n",
            "196/196 - 31s - loss: 1.0430 - sparse_categorical_accuracy: 0.6325 - val_loss: 0.9667 - val_sparse_categorical_accuracy: 0.6561\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/50\n",
            "196/196 - 31s - loss: 1.0087 - sparse_categorical_accuracy: 0.6406 - val_loss: 0.9876 - val_sparse_categorical_accuracy: 0.6484\n",
            "Epoch 10/50\n",
            "196/196 - 31s - loss: 0.9847 - sparse_categorical_accuracy: 0.6474 - val_loss: 0.9426 - val_sparse_categorical_accuracy: 0.6623\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/50\n",
            "196/196 - 31s - loss: 0.9658 - sparse_categorical_accuracy: 0.6571 - val_loss: 0.8723 - val_sparse_categorical_accuracy: 0.6957\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/50\n",
            "196/196 - 33s - loss: 0.9411 - sparse_categorical_accuracy: 0.6650 - val_loss: 0.8880 - val_sparse_categorical_accuracy: 0.6874\n",
            "Epoch 13/50\n",
            "196/196 - 32s - loss: 0.9219 - sparse_categorical_accuracy: 0.6739 - val_loss: 0.8526 - val_sparse_categorical_accuracy: 0.7056\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/50\n",
            "196/196 - 32s - loss: 0.9073 - sparse_categorical_accuracy: 0.6782 - val_loss: 0.8531 - val_sparse_categorical_accuracy: 0.7006\n",
            "Epoch 15/50\n",
            "196/196 - 32s - loss: 0.8932 - sparse_categorical_accuracy: 0.6848 - val_loss: 0.8800 - val_sparse_categorical_accuracy: 0.6902\n",
            "Epoch 16/50\n",
            "196/196 - 32s - loss: 0.8828 - sparse_categorical_accuracy: 0.6874 - val_loss: 0.8268 - val_sparse_categorical_accuracy: 0.7140\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 17/50\n",
            "196/196 - 32s - loss: 0.8632 - sparse_categorical_accuracy: 0.6967 - val_loss: 0.7990 - val_sparse_categorical_accuracy: 0.7190\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18/50\n",
            "196/196 - 32s - loss: 0.8606 - sparse_categorical_accuracy: 0.6964 - val_loss: 0.8142 - val_sparse_categorical_accuracy: 0.7163\n",
            "Epoch 19/50\n",
            "196/196 - 32s - loss: 0.8411 - sparse_categorical_accuracy: 0.7043 - val_loss: 0.7844 - val_sparse_categorical_accuracy: 0.7253\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20/50\n",
            "196/196 - 32s - loss: 0.8358 - sparse_categorical_accuracy: 0.7053 - val_loss: 0.7590 - val_sparse_categorical_accuracy: 0.7360\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 21/50\n",
            "196/196 - 32s - loss: 0.8321 - sparse_categorical_accuracy: 0.7084 - val_loss: 0.7966 - val_sparse_categorical_accuracy: 0.7228\n",
            "Epoch 22/50\n",
            "196/196 - 32s - loss: 0.8128 - sparse_categorical_accuracy: 0.7118 - val_loss: 0.7725 - val_sparse_categorical_accuracy: 0.7294\n",
            "Epoch 23/50\n",
            "196/196 - 32s - loss: 0.8085 - sparse_categorical_accuracy: 0.7141 - val_loss: 0.8174 - val_sparse_categorical_accuracy: 0.7204\n",
            "Epoch 24/50\n",
            "196/196 - 32s - loss: 0.8009 - sparse_categorical_accuracy: 0.7169 - val_loss: 0.7938 - val_sparse_categorical_accuracy: 0.7249\n",
            "Epoch 25/50\n",
            "196/196 - 32s - loss: 0.7986 - sparse_categorical_accuracy: 0.7158 - val_loss: 0.7798 - val_sparse_categorical_accuracy: 0.7275\n",
            "Epoch 26/50\n",
            "196/196 - 32s - loss: 0.7815 - sparse_categorical_accuracy: 0.7231 - val_loss: 0.7553 - val_sparse_categorical_accuracy: 0.7386\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 27/50\n",
            "196/196 - 32s - loss: 0.7763 - sparse_categorical_accuracy: 0.7254 - val_loss: 0.7177 - val_sparse_categorical_accuracy: 0.7491\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 28/50\n",
            "196/196 - 32s - loss: 0.7728 - sparse_categorical_accuracy: 0.7270 - val_loss: 0.7503 - val_sparse_categorical_accuracy: 0.7380\n",
            "Epoch 29/50\n",
            "196/196 - 32s - loss: 0.7592 - sparse_categorical_accuracy: 0.7341 - val_loss: 0.7436 - val_sparse_categorical_accuracy: 0.7417\n",
            "Epoch 30/50\n",
            "196/196 - 32s - loss: 0.7582 - sparse_categorical_accuracy: 0.7322 - val_loss: 0.7446 - val_sparse_categorical_accuracy: 0.7414\n",
            "Epoch 31/50\n",
            "196/196 - 32s - loss: 0.7578 - sparse_categorical_accuracy: 0.7321 - val_loss: 0.7258 - val_sparse_categorical_accuracy: 0.7539\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 32/50\n",
            "196/196 - 32s - loss: 0.7506 - sparse_categorical_accuracy: 0.7342 - val_loss: 0.8082 - val_sparse_categorical_accuracy: 0.7256\n",
            "Epoch 33/50\n",
            "196/196 - 32s - loss: 0.7470 - sparse_categorical_accuracy: 0.7364 - val_loss: 0.7787 - val_sparse_categorical_accuracy: 0.7318\n",
            "Epoch 34/50\n",
            "196/196 - 32s - loss: 0.7336 - sparse_categorical_accuracy: 0.7386 - val_loss: 0.7259 - val_sparse_categorical_accuracy: 0.7458\n",
            "Epoch 35/50\n",
            "196/196 - 32s - loss: 0.7280 - sparse_categorical_accuracy: 0.7411 - val_loss: 0.7388 - val_sparse_categorical_accuracy: 0.7420\n",
            "Epoch 36/50\n",
            "196/196 - 32s - loss: 0.7273 - sparse_categorical_accuracy: 0.7454 - val_loss: 0.7051 - val_sparse_categorical_accuracy: 0.7569\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 37/50\n",
            "196/196 - 32s - loss: 0.7242 - sparse_categorical_accuracy: 0.7449 - val_loss: 0.7034 - val_sparse_categorical_accuracy: 0.7549\n",
            "Epoch 38/50\n",
            "196/196 - 32s - loss: 0.7185 - sparse_categorical_accuracy: 0.7464 - val_loss: 0.7345 - val_sparse_categorical_accuracy: 0.7495\n",
            "Epoch 39/50\n",
            "196/196 - 32s - loss: 0.7150 - sparse_categorical_accuracy: 0.7486 - val_loss: 0.7036 - val_sparse_categorical_accuracy: 0.7581\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 40/50\n",
            "196/196 - 32s - loss: 0.7124 - sparse_categorical_accuracy: 0.7490 - val_loss: 0.7014 - val_sparse_categorical_accuracy: 0.7589\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 41/50\n",
            "196/196 - 32s - loss: 0.7028 - sparse_categorical_accuracy: 0.7514 - val_loss: 0.6942 - val_sparse_categorical_accuracy: 0.7597\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 42/50\n",
            "196/196 - 32s - loss: 0.7022 - sparse_categorical_accuracy: 0.7506 - val_loss: 0.7158 - val_sparse_categorical_accuracy: 0.7653\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 43/50\n",
            "196/196 - 32s - loss: 0.7010 - sparse_categorical_accuracy: 0.7539 - val_loss: 0.6952 - val_sparse_categorical_accuracy: 0.7627\n",
            "Epoch 44/50\n",
            "196/196 - 32s - loss: 0.6952 - sparse_categorical_accuracy: 0.7556 - val_loss: 0.7412 - val_sparse_categorical_accuracy: 0.7495\n",
            "Epoch 45/50\n",
            "196/196 - 32s - loss: 0.6938 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.7409 - val_sparse_categorical_accuracy: 0.7509\n",
            "Epoch 46/50\n",
            "196/196 - 32s - loss: 0.6917 - sparse_categorical_accuracy: 0.7556 - val_loss: 0.7005 - val_sparse_categorical_accuracy: 0.7550\n",
            "Epoch 47/50\n",
            "196/196 - 32s - loss: 0.6836 - sparse_categorical_accuracy: 0.7605 - val_loss: 0.7395 - val_sparse_categorical_accuracy: 0.7570\n",
            "Epoch 48/50\n",
            "196/196 - 32s - loss: 0.6826 - sparse_categorical_accuracy: 0.7593 - val_loss: 0.7122 - val_sparse_categorical_accuracy: 0.7510\n",
            "Epoch 49/50\n",
            "196/196 - 32s - loss: 0.6763 - sparse_categorical_accuracy: 0.7593 - val_loss: 0.6856 - val_sparse_categorical_accuracy: 0.7694\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_174_layer_call_and_return_conditional_losses, conv2d_174_layer_call_fn, conv2d_175_layer_call_and_return_conditional_losses, conv2d_175_layer_call_fn, conv2d_176_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_32kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 50/50\n",
            "196/196 - 32s - loss: 0.6774 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.7265 - val_sparse_categorical_accuracy: 0.7536\n",
            "Total training time 1669.4727947711945 seconds\n",
            "Model: \"model_30\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_31 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        52800     \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        58944     \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,307,178\n",
            "Trainable params: 1,307,178\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 62s - loss: 2.1343 - sparse_categorical_accuracy: 0.1960 - val_loss: 1.8591 - val_sparse_categorical_accuracy: 0.2831\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_180_layer_call_and_return_conditional_losses, conv2d_180_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses, conv2d_181_layer_call_fn, conv2d_182_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_180_layer_call_and_return_conditional_losses, conv2d_180_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses, conv2d_181_layer_call_fn, conv2d_182_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 60s - loss: 1.6935 - sparse_categorical_accuracy: 0.3756 - val_loss: 1.8358 - val_sparse_categorical_accuracy: 0.3316\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_180_layer_call_and_return_conditional_losses, conv2d_180_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses, conv2d_181_layer_call_fn, conv2d_182_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_180_layer_call_and_return_conditional_losses, conv2d_180_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses, conv2d_181_layer_call_fn, conv2d_182_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "196/196 - 60s - loss: 1.5264 - sparse_categorical_accuracy: 0.4459 - val_loss: 1.5605 - val_sparse_categorical_accuracy: 0.4387\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_180_layer_call_and_return_conditional_losses, conv2d_180_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses, conv2d_181_layer_call_fn, conv2d_182_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_180_layer_call_and_return_conditional_losses, conv2d_180_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses, conv2d_181_layer_call_fn, conv2d_182_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 60s - loss: 1.4102 - sparse_categorical_accuracy: 0.4922 - val_loss: 1.4006 - val_sparse_categorical_accuracy: 0.4891\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_180_layer_call_and_return_conditional_losses, conv2d_180_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses, conv2d_181_layer_call_fn, conv2d_182_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_180_layer_call_and_return_conditional_losses, conv2d_180_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses, conv2d_181_layer_call_fn, conv2d_182_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "196/196 - 60s - loss: 1.3136 - sparse_categorical_accuracy: 0.5271 - val_loss: 1.4636 - val_sparse_categorical_accuracy: 0.5056\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_180_layer_call_and_return_conditional_losses, conv2d_180_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses, conv2d_181_layer_call_fn, conv2d_182_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_180_layer_call_and_return_conditional_losses, conv2d_180_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses, conv2d_181_layer_call_fn, conv2d_182_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/50\n",
            "196/196 - 60s - loss: 1.2414 - sparse_categorical_accuracy: 0.5555 - val_loss: 1.3472 - val_sparse_categorical_accuracy: 0.5341\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_180_layer_call_and_return_conditional_losses, conv2d_180_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses, conv2d_181_layer_call_fn, conv2d_182_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_180_layer_call_and_return_conditional_losses, conv2d_180_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses, conv2d_181_layer_call_fn, conv2d_182_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "196/196 - 60s - loss: 1.1779 - sparse_categorical_accuracy: 0.5810 - val_loss: 1.1512 - val_sparse_categorical_accuracy: 0.5882\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_180_layer_call_and_return_conditional_losses, conv2d_180_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses, conv2d_181_layer_call_fn, conv2d_182_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_180_layer_call_and_return_conditional_losses, conv2d_180_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses, conv2d_181_layer_call_fn, conv2d_182_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/50\n",
            "196/196 - 60s - loss: 1.1342 - sparse_categorical_accuracy: 0.5971 - val_loss: 1.0636 - val_sparse_categorical_accuracy: 0.6212\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_180_layer_call_and_return_conditional_losses, conv2d_180_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses, conv2d_181_layer_call_fn, conv2d_182_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_180_layer_call_and_return_conditional_losses, conv2d_180_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses, conv2d_181_layer_call_fn, conv2d_182_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/50\n",
            "196/196 - 60s - loss: 1.0976 - sparse_categorical_accuracy: 0.6061 - val_loss: 1.0980 - val_sparse_categorical_accuracy: 0.6130\n",
            "Epoch 10/50\n",
            "196/196 - 60s - loss: 1.0706 - sparse_categorical_accuracy: 0.6175 - val_loss: 1.0466 - val_sparse_categorical_accuracy: 0.6309\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_180_layer_call_and_return_conditional_losses, conv2d_180_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses, conv2d_181_layer_call_fn, conv2d_182_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_180_layer_call_and_return_conditional_losses, conv2d_180_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses, conv2d_181_layer_call_fn, conv2d_182_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/50\n",
            "196/196 - 60s - loss: 1.0482 - sparse_categorical_accuracy: 0.6260 - val_loss: 1.0136 - val_sparse_categorical_accuracy: 0.6343\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_180_layer_call_and_return_conditional_losses, conv2d_180_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses, conv2d_181_layer_call_fn, conv2d_182_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_180_layer_call_and_return_conditional_losses, conv2d_180_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses, conv2d_181_layer_call_fn, conv2d_182_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/50\n",
            "196/196 - 60s - loss: 1.0241 - sparse_categorical_accuracy: 0.6377 - val_loss: 0.9692 - val_sparse_categorical_accuracy: 0.6580\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_180_layer_call_and_return_conditional_losses, conv2d_180_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses, conv2d_181_layer_call_fn, conv2d_182_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_180_layer_call_and_return_conditional_losses, conv2d_180_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses, conv2d_181_layer_call_fn, conv2d_182_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13/50\n",
            "196/196 - 60s - loss: 1.0060 - sparse_categorical_accuracy: 0.6408 - val_loss: 0.9966 - val_sparse_categorical_accuracy: 0.6482\n",
            "Epoch 14/50\n",
            "196/196 - 60s - loss: 0.9866 - sparse_categorical_accuracy: 0.6493 - val_loss: 1.0030 - val_sparse_categorical_accuracy: 0.6454\n",
            "Epoch 15/50\n",
            "196/196 - 60s - loss: 0.9762 - sparse_categorical_accuracy: 0.6531 - val_loss: 0.9210 - val_sparse_categorical_accuracy: 0.6706\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_180_layer_call_and_return_conditional_losses, conv2d_180_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses, conv2d_181_layer_call_fn, conv2d_182_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_180_layer_call_and_return_conditional_losses, conv2d_180_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses, conv2d_181_layer_call_fn, conv2d_182_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16/50\n",
            "196/196 - 60s - loss: 0.9622 - sparse_categorical_accuracy: 0.6571 - val_loss: 0.9557 - val_sparse_categorical_accuracy: 0.6707\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_180_layer_call_and_return_conditional_losses, conv2d_180_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses, conv2d_181_layer_call_fn, conv2d_182_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_180_layer_call_and_return_conditional_losses, conv2d_180_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses, conv2d_181_layer_call_fn, conv2d_182_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 17/50\n",
            "196/196 - 60s - loss: 0.9488 - sparse_categorical_accuracy: 0.6637 - val_loss: 0.9182 - val_sparse_categorical_accuracy: 0.6782\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_180_layer_call_and_return_conditional_losses, conv2d_180_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses, conv2d_181_layer_call_fn, conv2d_182_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_180_layer_call_and_return_conditional_losses, conv2d_180_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses, conv2d_181_layer_call_fn, conv2d_182_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18/50\n",
            "196/196 - 60s - loss: 0.9343 - sparse_categorical_accuracy: 0.6682 - val_loss: 0.9935 - val_sparse_categorical_accuracy: 0.6471\n",
            "Epoch 19/50\n",
            "196/196 - 60s - loss: 0.9260 - sparse_categorical_accuracy: 0.6719 - val_loss: 0.8591 - val_sparse_categorical_accuracy: 0.6985\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_180_layer_call_and_return_conditional_losses, conv2d_180_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses, conv2d_181_layer_call_fn, conv2d_182_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_180_layer_call_and_return_conditional_losses, conv2d_180_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses, conv2d_181_layer_call_fn, conv2d_182_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20/50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkQPhaA7Mxg7",
        "outputId": "df768c5b-f3f3-4620-82b1-b6741bdd84ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "hds = 1\n",
        "u_dim = 1\n",
        "for k_dim in [64,128]:\n",
        "  model = LambdaNetwork(num_classes=num_classes, \n",
        "                        image_height=image_height, \n",
        "                        image_width=image_width,\n",
        "                        k_dim=k_dim,\n",
        "                        u_dim=u_dim,\n",
        "                        num_heads=hds,\n",
        "                        n_r_size=14,\n",
        "                        local_contexts=False,\n",
        "                        preprocess=False).model()\n",
        "  model.summary()\n",
        "  if 'LAMBDA' not in history:\n",
        "    history['LAMBDA'] = dict()\n",
        "  if hds not in history['LAMBDA']:\n",
        "    history['LAMBDA'][hds] = dict()\n",
        "  if u_dim not in history['LAMBDA'][hds]:\n",
        "    history['LAMBDA'][hds][u_dim] = dict()\n",
        "  history['LAMBDA'][hds][u_dim][k_dim]= train_and_eval(model, SAVE_PATH + f'_LAMBDA_{k_dim}kdim_{u_dim}udim_{hds}hds', verbose=2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        52800     \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        58944     \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,307,178\n",
            "Trainable params: 1,307,178\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 97s - loss: 1.9801 - sparse_categorical_accuracy: 0.2679 - val_loss: 1.7215 - val_sparse_categorical_accuracy: 0.3665\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 61s - loss: 1.5527 - sparse_categorical_accuracy: 0.4368 - val_loss: 1.4360 - val_sparse_categorical_accuracy: 0.4788\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "196/196 - 61s - loss: 1.3782 - sparse_categorical_accuracy: 0.5016 - val_loss: 1.3360 - val_sparse_categorical_accuracy: 0.5265\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "196/196 - 62s - loss: 1.2716 - sparse_categorical_accuracy: 0.5459 - val_loss: 1.2015 - val_sparse_categorical_accuracy: 0.5680\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "196/196 - 62s - loss: 1.2018 - sparse_categorical_accuracy: 0.5708 - val_loss: 1.1282 - val_sparse_categorical_accuracy: 0.6059\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/50\n",
            "196/196 - 62s - loss: 1.1483 - sparse_categorical_accuracy: 0.5919 - val_loss: 1.1045 - val_sparse_categorical_accuracy: 0.6177\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "196/196 - 62s - loss: 1.1042 - sparse_categorical_accuracy: 0.6079 - val_loss: 1.0144 - val_sparse_categorical_accuracy: 0.6426\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/50\n",
            "196/196 - 62s - loss: 1.0666 - sparse_categorical_accuracy: 0.6210 - val_loss: 0.9889 - val_sparse_categorical_accuracy: 0.6565\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/50\n",
            "196/196 - 62s - loss: 1.0396 - sparse_categorical_accuracy: 0.6315 - val_loss: 0.9678 - val_sparse_categorical_accuracy: 0.6619\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/50\n",
            "196/196 - 61s - loss: 1.0114 - sparse_categorical_accuracy: 0.6404 - val_loss: 0.9055 - val_sparse_categorical_accuracy: 0.6808\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/50\n",
            "196/196 - 62s - loss: 0.9966 - sparse_categorical_accuracy: 0.6476 - val_loss: 0.8953 - val_sparse_categorical_accuracy: 0.6863\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/50\n",
            "196/196 - 62s - loss: 0.9763 - sparse_categorical_accuracy: 0.6557 - val_loss: 0.9053 - val_sparse_categorical_accuracy: 0.6827\n",
            "Epoch 13/50\n",
            "196/196 - 61s - loss: 0.9513 - sparse_categorical_accuracy: 0.6639 - val_loss: 0.8333 - val_sparse_categorical_accuracy: 0.7070\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/50\n",
            "196/196 - 61s - loss: 0.9350 - sparse_categorical_accuracy: 0.6717 - val_loss: 0.8436 - val_sparse_categorical_accuracy: 0.7030\n",
            "Epoch 15/50\n",
            "196/196 - 61s - loss: 0.9214 - sparse_categorical_accuracy: 0.6758 - val_loss: 0.8179 - val_sparse_categorical_accuracy: 0.7135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16/50\n",
            "196/196 - 62s - loss: 0.9015 - sparse_categorical_accuracy: 0.6838 - val_loss: 0.8701 - val_sparse_categorical_accuracy: 0.6979\n",
            "Epoch 17/50\n",
            "196/196 - 61s - loss: 0.8926 - sparse_categorical_accuracy: 0.6850 - val_loss: 0.8404 - val_sparse_categorical_accuracy: 0.7087\n",
            "Epoch 18/50\n",
            "196/196 - 61s - loss: 0.8815 - sparse_categorical_accuracy: 0.6910 - val_loss: 0.7947 - val_sparse_categorical_accuracy: 0.7220\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 19/50\n",
            "196/196 - 62s - loss: 0.8673 - sparse_categorical_accuracy: 0.6935 - val_loss: 0.7868 - val_sparse_categorical_accuracy: 0.7303\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20/50\n",
            "196/196 - 62s - loss: 0.8616 - sparse_categorical_accuracy: 0.6984 - val_loss: 0.7698 - val_sparse_categorical_accuracy: 0.7297\n",
            "Epoch 21/50\n",
            "196/196 - 61s - loss: 0.8554 - sparse_categorical_accuracy: 0.6985 - val_loss: 0.7975 - val_sparse_categorical_accuracy: 0.7209\n",
            "Epoch 22/50\n",
            "196/196 - 61s - loss: 0.8349 - sparse_categorical_accuracy: 0.7045 - val_loss: 0.7888 - val_sparse_categorical_accuracy: 0.7243\n",
            "Epoch 23/50\n",
            "196/196 - 62s - loss: 0.8308 - sparse_categorical_accuracy: 0.7048 - val_loss: 0.8119 - val_sparse_categorical_accuracy: 0.7195\n",
            "Epoch 24/50\n",
            "196/196 - 61s - loss: 0.8388 - sparse_categorical_accuracy: 0.7068 - val_loss: 0.7511 - val_sparse_categorical_accuracy: 0.7418\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 25/50\n",
            "196/196 - 62s - loss: 0.8244 - sparse_categorical_accuracy: 0.7088 - val_loss: 0.7536 - val_sparse_categorical_accuracy: 0.7407\n",
            "Epoch 26/50\n",
            "196/196 - 61s - loss: 0.8081 - sparse_categorical_accuracy: 0.7148 - val_loss: 0.7532 - val_sparse_categorical_accuracy: 0.7414\n",
            "Epoch 27/50\n",
            "196/196 - 62s - loss: 0.8154 - sparse_categorical_accuracy: 0.7134 - val_loss: 0.7592 - val_sparse_categorical_accuracy: 0.7445\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 28/50\n",
            "196/196 - 62s - loss: 0.7998 - sparse_categorical_accuracy: 0.7151 - val_loss: 0.7595 - val_sparse_categorical_accuracy: 0.7420\n",
            "Epoch 29/50\n",
            "196/196 - 61s - loss: 0.7939 - sparse_categorical_accuracy: 0.7205 - val_loss: 0.7408 - val_sparse_categorical_accuracy: 0.7406\n",
            "Epoch 30/50\n",
            "196/196 - 62s - loss: 0.7893 - sparse_categorical_accuracy: 0.7217 - val_loss: 0.7433 - val_sparse_categorical_accuracy: 0.7457\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 31/50\n",
            "196/196 - 62s - loss: 0.7800 - sparse_categorical_accuracy: 0.7235 - val_loss: 0.7437 - val_sparse_categorical_accuracy: 0.7427\n",
            "Epoch 32/50\n",
            "196/196 - 62s - loss: 0.7739 - sparse_categorical_accuracy: 0.7275 - val_loss: 0.7336 - val_sparse_categorical_accuracy: 0.7514\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 33/50\n",
            "196/196 - 62s - loss: 0.7702 - sparse_categorical_accuracy: 0.7273 - val_loss: 0.7309 - val_sparse_categorical_accuracy: 0.7525\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 34/50\n",
            "196/196 - 62s - loss: 0.7686 - sparse_categorical_accuracy: 0.7279 - val_loss: 0.7265 - val_sparse_categorical_accuracy: 0.7492\n",
            "Epoch 35/50\n",
            "196/196 - 61s - loss: 0.7654 - sparse_categorical_accuracy: 0.7299 - val_loss: 0.7251 - val_sparse_categorical_accuracy: 0.7525\n",
            "Epoch 36/50\n",
            "196/196 - 61s - loss: 0.7621 - sparse_categorical_accuracy: 0.7308 - val_loss: 0.7285 - val_sparse_categorical_accuracy: 0.7511\n",
            "Epoch 37/50\n",
            "196/196 - 62s - loss: 0.7589 - sparse_categorical_accuracy: 0.7303 - val_loss: 0.7396 - val_sparse_categorical_accuracy: 0.7403\n",
            "Epoch 38/50\n",
            "196/196 - 61s - loss: 0.7489 - sparse_categorical_accuracy: 0.7351 - val_loss: 0.7077 - val_sparse_categorical_accuracy: 0.7553\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 39/50\n",
            "196/196 - 62s - loss: 0.7416 - sparse_categorical_accuracy: 0.7383 - val_loss: 0.7285 - val_sparse_categorical_accuracy: 0.7583\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 40/50\n",
            "196/196 - 62s - loss: 0.7377 - sparse_categorical_accuracy: 0.7424 - val_loss: 0.7097 - val_sparse_categorical_accuracy: 0.7579\n",
            "Epoch 41/50\n",
            "196/196 - 61s - loss: 0.7338 - sparse_categorical_accuracy: 0.7396 - val_loss: 0.7428 - val_sparse_categorical_accuracy: 0.7527\n",
            "Epoch 42/50\n",
            "196/196 - 61s - loss: 0.7317 - sparse_categorical_accuracy: 0.7431 - val_loss: 0.7020 - val_sparse_categorical_accuracy: 0.7630\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 43/50\n",
            "196/196 - 62s - loss: 0.7301 - sparse_categorical_accuracy: 0.7427 - val_loss: 0.7344 - val_sparse_categorical_accuracy: 0.7514\n",
            "Epoch 44/50\n",
            "196/196 - 61s - loss: 0.7289 - sparse_categorical_accuracy: 0.7441 - val_loss: 0.6844 - val_sparse_categorical_accuracy: 0.7640\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 45/50\n",
            "196/196 - 62s - loss: 0.7222 - sparse_categorical_accuracy: 0.7444 - val_loss: 0.7008 - val_sparse_categorical_accuracy: 0.7638\n",
            "Epoch 46/50\n",
            "196/196 - 61s - loss: 0.7234 - sparse_categorical_accuracy: 0.7440 - val_loss: 0.7249 - val_sparse_categorical_accuracy: 0.7643\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 47/50\n",
            "196/196 - 62s - loss: 0.7151 - sparse_categorical_accuracy: 0.7484 - val_loss: 0.7484 - val_sparse_categorical_accuracy: 0.7487\n",
            "Epoch 48/50\n",
            "196/196 - 61s - loss: 0.7143 - sparse_categorical_accuracy: 0.7479 - val_loss: 0.7193 - val_sparse_categorical_accuracy: 0.7662\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_64kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 49/50\n",
            "196/196 - 62s - loss: 0.7051 - sparse_categorical_accuracy: 0.7505 - val_loss: 0.7173 - val_sparse_categorical_accuracy: 0.7559\n",
            "Epoch 50/50\n",
            "196/196 - 61s - loss: 0.7061 - sparse_categorical_accuracy: 0.7512 - val_loss: 0.7103 - val_sparse_categorical_accuracy: 0.7595\n",
            "Total training time 3177.044181585312 seconds\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "rescale (Rescaling)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resize (Resizing)            (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "lamb3 (Lambda)               (None, 14, 14, 64)        103552    \n",
            "_________________________________________________________________\n",
            "lamb4 (Lambda)               (None, 14, 14, 64)        113792    \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop4 (Dropout)              (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flat5 (Flatten)              (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dens5 (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "drop5 (Dropout)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,412,778\n",
            "Trainable params: 1,412,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 - 115s - loss: 2.3144 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_fn, conv2d_6_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_8_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_fn, conv2d_6_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, conv2d_8_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_128kdim_1udim_1hds/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_LAMBDA/210323_LAMBDA_128kdim_1udim_1hds/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "196/196 - 112s - loss: 2.3027 - sparse_categorical_accuracy: 0.0958 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 3/50\n",
            "196/196 - 112s - loss: 2.3027 - sparse_categorical_accuracy: 0.0973 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 4/50\n",
            "196/196 - 112s - loss: 2.3027 - sparse_categorical_accuracy: 0.0979 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 5/50\n",
            "196/196 - 113s - loss: 2.3027 - sparse_categorical_accuracy: 0.0977 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 6/50\n",
            "196/196 - 113s - loss: 2.3027 - sparse_categorical_accuracy: 0.0989 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 7/50\n",
            "196/196 - 113s - loss: 2.3027 - sparse_categorical_accuracy: 0.0972 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 8/50\n",
            "196/196 - 112s - loss: 2.3027 - sparse_categorical_accuracy: 0.0979 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 9/50\n",
            "196/196 - 112s - loss: 2.3027 - sparse_categorical_accuracy: 0.0988 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 10/50\n",
            "196/196 - 111s - loss: 2.3027 - sparse_categorical_accuracy: 0.0974 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 11/50\n",
            "196/196 - 111s - loss: 2.3027 - sparse_categorical_accuracy: 0.0977 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 12/50\n",
            "196/196 - 112s - loss: 2.3027 - sparse_categorical_accuracy: 0.0975 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 13/50\n",
            "196/196 - 109s - loss: 2.3028 - sparse_categorical_accuracy: 0.0990 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 14/50\n",
            "196/196 - 107s - loss: 2.3027 - sparse_categorical_accuracy: 0.0983 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 15/50\n",
            "196/196 - 107s - loss: 2.3027 - sparse_categorical_accuracy: 0.0981 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 16/50\n",
            "196/196 - 106s - loss: 2.3027 - sparse_categorical_accuracy: 0.0979 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 17/50\n",
            "196/196 - 105s - loss: 2.3027 - sparse_categorical_accuracy: 0.0977 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 18/50\n",
            "196/196 - 105s - loss: 2.3027 - sparse_categorical_accuracy: 0.0972 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 19/50\n",
            "196/196 - 105s - loss: 2.3027 - sparse_categorical_accuracy: 0.0970 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 20/50\n",
            "196/196 - 105s - loss: 2.3027 - sparse_categorical_accuracy: 0.0986 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 21/50\n",
            "196/196 - 106s - loss: 2.3027 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 22/50\n",
            "196/196 - 106s - loss: 2.3027 - sparse_categorical_accuracy: 0.0983 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 23/50\n",
            "196/196 - 111s - loss: 2.3029 - sparse_categorical_accuracy: 0.1014 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 24/50\n",
            "196/196 - 110s - loss: 2.3027 - sparse_categorical_accuracy: 0.0978 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 25/50\n",
            "196/196 - 102s - loss: 2.3157 - sparse_categorical_accuracy: 0.0997 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 26/50\n",
            "196/196 - 98s - loss: 2.3027 - sparse_categorical_accuracy: 0.0986 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 27/50\n",
            "196/196 - 98s - loss: 2.3027 - sparse_categorical_accuracy: 0.0979 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 28/50\n",
            "196/196 - 98s - loss: 2.3027 - sparse_categorical_accuracy: 0.1005 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 29/50\n",
            "196/196 - 97s - loss: 2.3027 - sparse_categorical_accuracy: 0.0961 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 30/50\n",
            "196/196 - 97s - loss: 2.3027 - sparse_categorical_accuracy: 0.0996 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 31/50\n",
            "196/196 - 97s - loss: 2.3027 - sparse_categorical_accuracy: 0.0979 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 32/50\n",
            "196/196 - 97s - loss: 2.3027 - sparse_categorical_accuracy: 0.0974 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 33/50\n",
            "196/196 - 97s - loss: 2.3027 - sparse_categorical_accuracy: 0.0977 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 34/50\n",
            "196/196 - 98s - loss: 2.3027 - sparse_categorical_accuracy: 0.0965 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 35/50\n",
            "196/196 - 97s - loss: 2.3027 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 36/50\n",
            "196/196 - 97s - loss: 2.3026 - sparse_categorical_accuracy: 0.0969 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 37/50\n",
            "196/196 - 97s - loss: 2.3027 - sparse_categorical_accuracy: 0.0978 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 38/50\n",
            "196/196 - 97s - loss: 2.3027 - sparse_categorical_accuracy: 0.0983 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 39/50\n",
            "196/196 - 97s - loss: 2.3027 - sparse_categorical_accuracy: 0.0968 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 40/50\n",
            "196/196 - 97s - loss: 2.3027 - sparse_categorical_accuracy: 0.0991 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 41/50\n",
            "196/196 - 97s - loss: 2.3027 - sparse_categorical_accuracy: 0.0972 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 42/50\n",
            "196/196 - 97s - loss: 2.3027 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 43/50\n",
            "196/196 - 97s - loss: 2.3027 - sparse_categorical_accuracy: 0.0971 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 44/50\n",
            "196/196 - 97s - loss: 2.3027 - sparse_categorical_accuracy: 0.0968 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 45/50\n",
            "196/196 - 97s - loss: 2.3027 - sparse_categorical_accuracy: 0.0962 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 46/50\n",
            "196/196 - 97s - loss: 2.3027 - sparse_categorical_accuracy: 0.0966 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 47/50\n",
            "196/196 - 97s - loss: 2.3027 - sparse_categorical_accuracy: 0.0978 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 48/50\n",
            "196/196 - 97s - loss: 2.3026 - sparse_categorical_accuracy: 0.0970 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 49/50\n",
            "196/196 - 97s - loss: 2.3027 - sparse_categorical_accuracy: 0.1002 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Epoch 50/50\n",
            "196/196 - 97s - loss: 2.3027 - sparse_categorical_accuracy: 0.0983 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1000\n",
            "Total training time 5170.899382352829 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwbScRfWNx23"
      },
      "source": [
        "#Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVOzm-fhaYIQ"
      },
      "source": [
        "history['CNN'] = np.load('/content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_VIT/210318_CNN/history.npy', allow_pickle='TRUE').item()\n",
        "history['VIT'] = np.load('/content/drive/MyDrive/02_Work/05_Experiments/TF-Transformer/Cifar10_VIT/210318_VIT_4x4_2hd/history.npy', allow_pickle='TRUE').item()\n",
        "\n",
        "# EXP3\n",
        "u_dim = 1\n",
        "for hds in [1,2,4,8]:\n",
        "  for k_dim in [1,2,4,8]:\n",
        "    if 'LAMBDA' not in history:\n",
        "      history['LAMBDA'] = dict()\n",
        "    if hds not in history['LAMBDA']:\n",
        "      history['LAMBDA'][hds] = dict()\n",
        "    if u_dim not in history['LAMBDA'][hds]:\n",
        "      history['LAMBDA'][hds][u_dim] = dict()\n",
        "    history['LAMBDA'][hds][u_dim][k_dim]= np.load(SAVE_PATH + f'_LAMBDA_{k_dim}kdim_{u_dim}udim_{hds}hds' + '/history.npy', allow_pickle='TRUE').item()\n",
        "\n",
        "# EXP4\n",
        "hds = 2\n",
        "for u_dim in [2,4,8]:\n",
        "  for k_dim in [1,2,4,8]:\n",
        "    if 'LAMBDA' not in history:\n",
        "      history['LAMBDA'] = dict()\n",
        "    if hds not in history['LAMBDA']:\n",
        "      history['LAMBDA'][hds] = dict()\n",
        "    if u_dim not in history['LAMBDA'][hds]:\n",
        "      history['LAMBDA'][hds][u_dim] = dict()\n",
        "    history['LAMBDA'][hds][u_dim][k_dim]= np.load(SAVE_PATH + f'_LAMBDA_{k_dim}kdim_{u_dim}udim_{hds}hds' + '/history.npy', allow_pickle='TRUE').item()\n",
        "\n",
        "# EXP5\n",
        "hds = 1\n",
        "u_dim = 1\n",
        "for k_dim in [16,32,64,128]:\n",
        "  if 'LAMBDA' not in history:\n",
        "    history['LAMBDA'] = dict()\n",
        "  if hds not in history['LAMBDA']:\n",
        "    history['LAMBDA'][hds] = dict()\n",
        "  if u_dim not in history['LAMBDA'][hds]:\n",
        "    history['LAMBDA'][hds][u_dim] = dict()\n",
        "  history['LAMBDA'][hds][u_dim][k_dim]= np.load(SAVE_PATH + f'_LAMBDA_{k_dim}kdim_{u_dim}udim_{hds}hds' + '/history.npy', allow_pickle='TRUE').item()\n",
        "    "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAZclOphR1JM"
      },
      "source": [
        "Between Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJzxy5waI03G",
        "outputId": "2b4b9f05-5f81-4dda-c652-dd9ba5847653",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "legends = ['CNN', 'VIT', 'LAMBDA_2hds_1u_8k']\n",
        "histories = [history['CNN'], history['VIT'], history['LAMBDA'][2][1][8]]\n",
        "\n",
        "plot([(i['loss'], i['val_loss']) for i in histories], \n",
        "     [(i['sparse_categorical_accuracy'],\n",
        "       i['val_sparse_categorical_accuracy']) for i in histories],\n",
        "     legends,\n",
        "     subplot_title=['Loss', 'Accuracy'])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_AqYR4cR2k3"
      },
      "source": [
        "X heads, 1 udim, Y kdim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xkdndjf4RQ2m",
        "outputId": "9a228bf0-008b-4a05-9a3e-b90c2e4438c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "for hds in [1,2,4,8]:\n",
        "  legends = [f'LAMBDA_{hds}hds_1u_{i}k' for i in [1,2,4,8]]\n",
        "  histories = [history['LAMBDA'][hds][1][i] for i in [1,2,4,8]]\n",
        "\n",
        "plot([(i['loss'], i['val_loss']) for i in histories], \n",
        "     [(i['sparse_categorical_accuracy'],\n",
        "       i['val_sparse_categorical_accuracy']) for i in histories],\n",
        "     legends,\n",
        "     subplot_title=['Loss', 'Accuracy'])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mh4Enoo2R6ws"
      },
      "source": [
        "2 heads, X udim, Y kdim\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8pazwcvRzqA",
        "outputId": "85b97f59-038e-4734-87c9-f2d860c103de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "for u in [1,2,4,8]:\n",
        "  legends = [f'LAMBDA_2hds_{u}u_{i}k' for i in [1,2,4,8]]\n",
        "  histories = [history['LAMBDA'][2][u][i] for i in [1,2,4,8]]\n",
        "\n",
        "plot([(i['loss'], i['val_loss']) for i in histories], \n",
        "     [(i['sparse_categorical_accuracy'],\n",
        "       i['val_sparse_categorical_accuracy']) for i in histories],\n",
        "     legends,\n",
        "     subplot_title=['Loss', 'Accuracy'])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxuKL9WY9Wg8"
      },
      "source": [
        "1 heads, 1 udim, X kdim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqdVAZsW9WYK",
        "outputId": "c850a16d-8150-4b97-f6ed-d56ccd1269e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "u = 1\n",
        "hds = 1\n",
        "legends = [f'LAMBDA_{hds}hds_{u}u_{i}k' for i in [1,2,4,8,16,32,64]]\n",
        "histories = [history['LAMBDA'][hds][u][i] for i in [1,2,4,8,16,32,64]]\n",
        "\n",
        "plot([(i['loss'], i['val_loss']) for i in histories], \n",
        "     [(i['sparse_categorical_accuracy'],\n",
        "       i['val_sparse_categorical_accuracy']) for i in histories],\n",
        "     legends,\n",
        "     subplot_title=['Loss', 'Accuracy'])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}